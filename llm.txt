TITLE: Generating Text Responses with Mastra Agent
DESCRIPTION: This example shows how to use the `.generate()` method of a Mastra agent to produce a single text response. It takes an array of message objects (e.g., user input) and logs the agent's generated text output.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_4

LANGUAGE: ts
CODE:
```
const response = await myAgent.generate([
  { role: "user", content: "Hello, how can you assist me today?" },
]);

console.log("Agent:", response.text);
```

----------------------------------------

TITLE: Defining a Workflow Step in TypeScript
DESCRIPTION: This TypeScript example illustrates the creation of a `Step` using the `createStep` function. It defines the step's unique ID, specifies input, output, resume, and suspend data schemas using Zod, and provides an asynchronous `execute` function to handle the step's core logic, processing `inputData` and returning a structured result.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/step.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { createStep } from "@mastra/core/workflows";
import { z } from "zod";

const processOrder = createStep({
  id: "processOrder",
  inputSchema: z.object({
    orderId: z.string(),
    userId: z.string()
  }),
  outputSchema: z.object({
    status: z.string(),
    orderId: z.string()
  }),
  resumeSchema: z.object({
    orderId: z.string()
  }),
  suspendSchema: z.object({}),
  execute: async ({
    inputData,
    mastra,
    getStepResult,
    getInitData,
    suspend
  }) => {
    return {
      status: "processed",
      orderId: inputData.orderId
    };
  }
});
```

----------------------------------------

TITLE: Initializing and Running a Mastra Workflow
DESCRIPTION: This snippet demonstrates the creation and initialization of a Mastra workflow using `createWorkflow`, defining its ID, input/output schemas, and sequential steps. It then shows how to register the workflow with a `Mastra` instance and initiate a new workflow run using `createRun()`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/workflow.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
const myWorkflow = createWorkflow({
  id: "my-workflow",
  inputSchema: z.object({
    startValue: z.string(),
  }),
  outputSchema: z.object({
    result: z.string(),
  }),
  steps: [step1, step2, step3], // Declare steps used in this workflow
})
  .then(step1)
  .then(step2)
  .then(step3)
  .commit();

const mastra = new Mastra({
  workflows: {
    myWorkflow,
  },
});

const run = mastra.getWorkflow("myWorkflow").createRun();
```

----------------------------------------

TITLE: Creating a Basic Weather Tool with Mastra and Zod (TypeScript)
DESCRIPTION: This example demonstrates the basic usage of the `createTool` function to define a custom tool in Mastra. It shows how to import necessary modules, define a unique ID, specify an input schema using Zod, provide a description, and implement the tool's logic within the `execute` function. The tool is designed to fetch weather information for a given city.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/create-tool.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { createTool } from "@mastra/core/tools";
import { z } from "zod";

export const weatherInfo = createTool({
  id: "Get Weather Information",
  inputSchema: z.object({
    city: z.string(),
  }),
  description: `Fetches the current weather information for a given city`,
  execute: async ({ context: { city } }) => {
    // Tool logic here (e.g., API call)
    console.log("Using tool to fetch weather information for", city);
    return { temperature: 20, conditions: "Sunny" }; // Example return
  },
});
```

----------------------------------------

TITLE: Initializing Mastra and Executing Agent (TypeScript)
DESCRIPTION: This final snippet initializes the main `Mastra` instance, registering the `weatherWorkflow` and `activityPlannerAgent`. It then demonstrates how to invoke the `activityPlannerAgent` with a query, 'What activities do you recommend for a visit to Tokyo?', and prints the agent's generated response to the console. This showcases the end-to-end execution of the defined system.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/using-with-agents-and-tools.mdx#_snippet_8

LANGUAGE: TypeScript
CODE:
```
const mastra = new Mastra({
  workflows: {
    weatherWorkflow
  },
  agents: {
    activityPlannerAgent
  }
});

const response = await activityPlannerAgent.generate("What activities do you recommend for a visit to Tokyo?");

console.log("\nAgent response:");
console.log(response.text);
```

----------------------------------------

TITLE: Filtering Retrieval Results with Multiple Metadata Conditions (TypeScript)
DESCRIPTION: This snippet illustrates combining multiple metadata conditions (equality and numeric comparison) to refine search results. It retrieves chunks that belong to the 'electronics' category, have a price less than 1000, and are explicitly marked as 'inStock' true, allowing for precise multi-attribute filtering.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/retrieval.mdx#_snippet_4

LANGUAGE: ts
CODE:
```
// Multiple conditions
const results = await pgVector.query({
  indexName: "embeddings",
  queryVector: embedding,
  topK: 10,
  filter: {
    category: "electronics",
    price: { $lt: 1000 },
    inStock: true
  }
});
```

----------------------------------------

TITLE: Initializing Voice Agent with OpenAI TTS in Mastra (TypeScript)
DESCRIPTION: This snippet demonstrates how to initialize a Mastra `Agent` with OpenAI voice capabilities for Text-to-Speech (TTS). It imports necessary modules, sets up the agent's name and instructions, specifies the `gpt-4o` model, and integrates `OpenAIVoice` for voice interactions. This setup enables the agent to function as a voice assistant.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";
import { OpenAIVoice } from "@mastra/voice-openai";

// Initialize OpenAI voice for TTS

const voiceAgent = new Agent({
  name: "Voice Agent",
  instructions:
    "You are a voice assistant that can help users with their tasks.",
  model: openai("gpt-4o"),
  voice: new OpenAIVoice()
});
```

----------------------------------------

TITLE: Defining a Suspendable Human-in-the-Loop Travel Workflow in TypeScript
DESCRIPTION: This snippet defines a `travelAgentWorkflow` using `@mastra/core/workflows` that orchestrates a travel planning process. It includes three steps: `generateSuggestionsStep` (AI-driven suggestions), `humanInputStep` (pauses for user selection), and `travelPlannerStep` (AI-driven detailed plan). The `humanInputStep` demonstrates Mastra's suspend/resume mechanism for interactive workflows.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#_snippet_2

LANGUAGE: TypeScript
CODE:
```
import { createWorkflow, createStep } from '@mastra/core/workflows'
import { z } from 'zod'
 
// Step that generates multiple holiday options based on user's vacation description
// Uses the summaryTravelAgent to create diverse travel suggestions
const generateSuggestionsStep = createStep({
  id: "generate-suggestions",
  inputSchema: z.object({
    vacationDescription: z.string().describe("The description of the vacation"),
  }),
  outputSchema: z.object({
    suggestions: z.array(z.string()),
    vacationDescription: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    if (!mastra) {
      throw new Error("Mastra is not initialized");
    }
 
    const { vacationDescription } = inputData
    const result = await mastra.getAgent('summaryTravelAgent').generate([
      {
        role: "user",
        content: vacationDescription,
      },
    ]);
    console.log(result.text);
    return { suggestions: JSON.parse(result.text), vacationDescription };
  },
})
 
// Step that pauses the workflow to get user input
// Allows the user to select their preferred holiday option from the suggestions
// Uses suspend/resume mechanism to handle the interaction
const humanInputStep = createStep({
  id: "human-input",
  inputSchema: z.object({
    suggestions: z.array(z.string()),
    vacationDescription: z.string(),
  }),
  outputSchema: z.object({
    selection: z.string().describe("The selection of the user"),
    vacationDescription: z.string(),
  }),
  resumeSchema: z.object({
    selection: z.string().describe("The selection of the user"),
  }),
  suspendSchema: z.object({
    suggestions: z.array(z.string()),
  }),
  execute: async ({ inputData, resumeData, suspend, getInitData }) => {
    if (!resumeData?.selection) {
      await suspend({ suggestions: inputData?.suggestions });
      return {
        selection: "",
        vacationDescription: inputData?.vacationDescription,
      };
    }
 
    return {
      selection: resumeData?.selection,
      vacationDescription: inputData?.vacationDescription,
    };
  },
})
 
// Step that creates a detailed travel plan based on the user's selection
// Uses the travelAgent to generate comprehensive holiday details
const travelPlannerStep = createStep({
  id: "travel-planner",
  inputSchema: z.object({
    selection: z.string().describe("The selection of the user"),
    vacationDescription: z.string(),
  }),
  outputSchema: z.object({
    travelPlan: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    const travelAgent = mastra?.getAgent("travelAgent");
    if (!travelAgent) {
      throw new Error("Travel agent is not initialized");
    }
 
    const { selection, vacationDescription } = inputData
    const result = await travelAgent.generate([
      { role: "assistant", content: vacationDescription },
      { role: "user", content: selection || "" },
    ]);
    console.log(result.text);
    return { travelPlan: result.text };
  },
})
 
// Main workflow that orchestrates the holiday planning process:
// 1. Generates multiple options
// 2. Gets user input
// 3. Creates detailed plan
const travelAgentWorkflow = createWorkflow({
  id: "travel-agent-workflow",
  inputSchema: z.object({
    vacationDescription: z.string().describe("The description of the vacation"),
  }),
  outputSchema: z.object({
    travelPlan: z.string(),
  }),
})
  .then(generateSuggestionsStep)
  .then(humanInputStep)
  .then(travelPlannerStep)
 
travelAgentWorkflow.commit()
 
export { travelAgentWorkflow, humanInputStep }
```

----------------------------------------

TITLE: Setting OpenAI API Key in .env (Bash)
DESCRIPTION: This snippet shows how to add the `OPENAI_API_KEY` to the `.env` file. This environment variable is crucial for authenticating with the OpenAI API, which is used by the Mastra agent for LLM interactions.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/ai-recruiter.mdx#_snippet_1

LANGUAGE: Bash
CODE:
```
OPENAI_API_KEY=<your-openai-key>
```

----------------------------------------

TITLE: Configuring Anthropic and OpenAI API Keys (Environment)
DESCRIPTION: This snippet shows how to set the `ANTHROPIC_API_KEY` and `OPENAI_API_KEY` in the `.env` file. These keys are essential for the agents to authenticate with the respective AI services.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/hierarchical-multi-agent/README.md#_snippet_2

LANGUAGE: env
CODE:
```
ANTHROPIC_API_KEY=sk-your-api-key-here
OPENAI_API_KEY=sk-your-api-key-here
```

----------------------------------------

TITLE: Configuring Environment Variables - ENV
DESCRIPTION: This snippet illustrates the content of the `.env` file, showing placeholders for the OpenAI API key and PostgreSQL connection string. These variables are essential for the application to authenticate with OpenAI and connect to the database.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cot-workflow-rag/README.md#_snippet_2

LANGUAGE: env
CODE:
```
OPENAI_API_KEY=sk-your-api-key-here
POSTGRES_CONNECTION_STRING=your-postgres-connection-string-here
```

----------------------------------------

TITLE: Streaming Agent Response with Working Memory (TypeScript)
DESCRIPTION: This snippet illustrates how to interact with the configured agent using `stream` to get a response. It generates unique `threadId` and `resourceId` for the interaction, sends a message, and then processes the streamed text chunks, demonstrating how the agent remembers details like the user's name.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/streaming-working-memory.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
import { randomUUID } from "crypto";

const threadId = randomUUID();
const resourceId = "SOME_USER_ID";

const response = await agent.stream("Hello, my name is Jane", {
  threadId,
  resourceId,
});

for await (const chunk of response.textStream) {
  process.stdout.write(chunk);
}
```

----------------------------------------

TITLE: Configuring and Executing Multi-Agent Workflow (TypeScript)
DESCRIPTION: This snippet configures the main workflow using `createWorkflow`, defining its overall input (`topic`) and output (`finalCopy`) schemas. It then chains the `copywriterStep` and `editorStep` sequentially using `.then()` and `commit()`. Finally, it creates and starts a workflow run with a sample topic, demonstrating the end-to-end execution of the multi-agent process.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/multi-agent-workflow.mdx#_snippet_5

LANGUAGE: typescript
CODE:
```
const myWorkflow = createWorkflow({
  id: 'my-workflow',
  inputSchema: z.object({
    topic: z.string()
  }),
  outputSchema: z.object({
    finalCopy: z.string()
  })
});

// Run steps sequentially.
myWorkflow.then(copywriterStep).then(editorStep).commit();

const run = myWorkflow.createRun();

const res = await run.start({ inputData: { topic: 'React JavaScript frameworks' } });
console.log('Response: ', res);
```

----------------------------------------

TITLE: Initializing a Mastra Agent in TypeScript
DESCRIPTION: This snippet demonstrates how to create a new agent instance in Mastra using the `Agent` class. It defines the agent's name, initial instructions, and the language model to be used, such as OpenAI's `gpt-4o-mini`. This requires the `@mastra/core` package and a configured OpenAI API key.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_0

LANGUAGE: ts
CODE:
```
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";

export const myAgent = new Agent({
  name: "My Agent",
  instructions: "You are a helpful assistant.",
  model: openai("gpt-4o-mini"),
});
```

----------------------------------------

TITLE: Generating and Storing Embeddings in PgVector (TypeScript)
DESCRIPTION: This snippet generates vector embeddings for each text chunk using OpenAI's `text-embedding-3-small` model. It then retrieves the `pgVector` store instance from Mastra, creates a new index named 'papers' with a dimension of 1536, and finally upserts the generated embeddings along with their original text and source metadata into the vector database for efficient semantic search.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/research-assistant.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
// Generate embeddings
const { embeddings } = await embedMany({
  model: openai.embedding("text-embedding-3-small"),
  values: chunks.map((chunk) => chunk.text),
});

// Get the vector store instance from Mastra
const vectorStore = mastra.getVector("pgVector");

// Create an index for our paper chunks
await vectorStore.createIndex({
  indexName: "papers",
  dimension: 1536,
});

// Store embeddings
await vectorStore.upsert({
  indexName: "papers",
  vectors: embeddings,
  metadata: chunks.map((chunk) => ({
    text: chunk.text,
    source: "transformer-paper",
  })),
});
```

----------------------------------------

TITLE: Defining a Weather-Based Planning Agent (TypeScript)
DESCRIPTION: This TypeScript snippet defines `planningAgent`, an AI agent utilizing `@mastra/core` and the `gpt-4o` model from `@ai-sdk/openai`. Its primary function is to act as a weather-based travel expert, providing structured activity recommendations (morning, afternoon, indoor alternatives) based on weather conditions, adhering to a strict output format.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/parallel-steps.mdx#_snippet_1

LANGUAGE: ts
CODE:
```
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";

const llm = openai("gpt-4o");

// Define the planning agent with specific instructions for formatting
// and structuring weather-based activity recommendations
const planningAgent = new Agent({
  name: "planningAgent",
  model: llm,
  instructions: `
        You are a local activities and travel expert who excels at weather-based planning. Analyze the weather data and provide practical activity recommendations.

        📅 [Day, Month Date, Year]
        ═══════════════════════════

        🌡️ WEATHER SUMMARY
        • Conditions: [brief description]
        • Temperature: [X°C/Y°F to A°C/B°F]
        • Precipitation: [X% chance]

        🌅 MORNING ACTIVITIES
        Outdoor:
        • [Activity Name] - [Brief description including specific location/route]
          Best timing: [specific time range]
          Note: [relevant weather consideration]

        🌞 AFTERNOON ACTIVITIES
        Outdoor:
        • [Activity Name] - [Brief description including specific location/route]
          Best timing: [specific time range]
          Note: [relevant weather consideration]

        🏠 INDOOR ALTERNATIVES
        • [Activity Name] - [Brief description including specific venue]
          Ideal for: [weather condition that would trigger this alternative]

        ⚠️ SPECIAL CONSIDERATIONS
        • [Any relevant weather warnings, UV index, wind conditions, etc.]

        Guidelines:
        - Suggest 2-3 time-specific outdoor activities per day
        - Include 1-2 indoor backup options
        - For precipitation >50%, lead with indoor activities
        - All activities must be specific to the location
        - Include specific venues, trails, or locations
        - Consider activity intensity based on temperature
        - Keep descriptions concise but informative

        Maintain this exact formatting for consistency, using the emoji and section headers as shown.
      `,
});

export { planningAgent };
```

----------------------------------------

TITLE: Configuring Dynamic Toolsets with MCPClient in TypeScript
DESCRIPTION: This snippet demonstrates how to create an `Agent` without initial tools and then dynamically configure `MCPClient` with user-specific server settings (e.g., API keys, authorization tokens). It shows how to pass the dynamically obtained toolsets from `mcp.getToolsets()` to the `agent.stream()` method, enabling the agent to use user-specific tools for tasks like checking stock prices and weather.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-client.mdx#_snippet_20

LANGUAGE: typescript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { MCPClient } from "@mastra/mcp";
import { openai } from "@ai-sdk/openai";

// Create the agent first, without any tools
const agent = new Agent({
  name: "Multi-tool Agent",
  instructions: "You help users check stocks and weather.",
  model: openai("gpt-4"),
});

// Later, configure MCP with user-specific settings
const mcp = new MCPClient({
  servers: {
    stockPrice: {
      command: "npx",
      args: ["tsx", "stock-price.ts"],
      env: {
        API_KEY: "user-123-api-key",
      },
      timeout: 20000, // Server-specific timeout
    },
    weather: {
      url: new URL("http://localhost:8080/sse"),
      requestInit: {
        headers: {
          Authorization: `Bearer user-123-token`,
        },
      },
    },
  },
});

// Pass all toolsets to stream() or generate()
const response = await agent.stream(
  "How is AAPL doing and what is the weather?",
  {
    toolsets: await mcp.getToolsets(),
  },
);
```

----------------------------------------

TITLE: Upserting Embeddings into Qdrant (TypeScript)
DESCRIPTION: This snippet demonstrates how to use the `QdrantVector` class to create collections and insert embeddings into Qdrant, a high-performance vector database. It involves chunking text, generating embeddings with OpenAI (including a `maxRetries` option), and then upserting these vectors and their metadata into a specified Qdrant collection. Both `url` and `apiKey` are required for Qdrant connection.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/upsert/upsert-embeddings.mdx#_snippet_2

LANGUAGE: tsx
CODE:
```
import { openai } from '@ai-sdk/openai';
import { QdrantVector } from '@mastra/qdrant';
import { MDocument } from '@mastra/rag';
import { embedMany } from 'ai';

const doc = MDocument.fromText('Your text content...');

const chunks = await doc.chunk();

const { embeddings } = await embedMany({
  values: chunks.map(chunk => chunk.text),
  model: openai.embedding('text-embedding-3-small'),
  maxRetries: 3,
});

const qdrant = new QdrantVector({
  url: process.env.QDRANT_URL,
  apiKey: process.env.QDRANT_API_KEY,
});

await qdrant.createIndex({
  indexName: 'test_collection',
  dimension: 1536,
});

await qdrant.upsert({
  indexName: 'test_collection',
  vectors: embeddings,
  metadata: chunks?.map(chunk => ({ text: chunk.text })),
});
```

----------------------------------------

TITLE: Implementing RAG Workflow with Mastra and TypeScript
DESCRIPTION: This snippet demonstrates a complete RAG workflow in TypeScript using Mastra components. It covers initializing a document, chunking its content, generating embeddings using OpenAI's `text-embedding-3-small` model, storing these embeddings in a PgVector database, and finally querying for similar content. Key dependencies include `@mastra/rag`, `@mastra/pg`, and `@ai-sdk/openai`. The `queryVector` would typically be the embedding of the user's query.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/overview.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { embedMany } from "ai";
import { openai } from "@ai-sdk/openai";
import { PgVector } from "@mastra/pg";
import { MDocument } from "@mastra/rag";
import { z } from "zod";

// 1. Initialize document
const doc = MDocument.fromText(`Your document text here...`);

// 2. Create chunks
const chunks = await doc.chunk({
  strategy: "recursive",
  size: 512,
  overlap: 50,
});

// 3. Generate embeddings; we need to pass the text of each chunk
const { embeddings } = await embedMany({
  values: chunks.map((chunk) => chunk.text),
  model: openai.embedding("text-embedding-3-small"),
});

// 4. Store in vector database
const pgVector = new PgVector({ connectionString: process.env.POSTGRES_CONNECTION_STRING });
await pgVector.upsert({
  indexName: "embeddings",
  vectors: embeddings,
}); // using an index name of 'embeddings'

// 5. Query similar chunks
const results = await pgVector.query({
  indexName: "embeddings",
  queryVector: queryVector,
  topK: 3,
}); // queryVector is the embedding of the query

console.log("Similar chunks:", results);
```

----------------------------------------

TITLE: Configuring Dynamic Support Agent with Runtime Context in Mastra
DESCRIPTION: This code defines a `supportAgent` using Mastra's `Agent` class. It dynamically sets `instructions`, `model`, and `tools` based on the `runtimeContext`. Instructions adapt to user tier and language, the model switches between `gpt-4` and `gpt-3.5-turbo` based on tier, and tools are added conditionally for 'pro' and 'enterprise' users.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/dynamic-agents.mdx#_snippet_1

LANGUAGE: TypeScript
CODE:
```
const supportAgent = new Agent({
  name: "Dynamic Support Agent",
  
  instructions: async ({ runtimeContext }) => {
    const userTier = runtimeContext.get("user-tier");
    const language = runtimeContext.get("language");
    
    return `You are a customer support agent for our SaaS platform.
    The current user is on the ${userTier} tier and prefers ${language} language.
    
    For ${userTier} tier users:
    ${userTier === "free" ? "- Provide basic support and documentation links" : ""}
    ${userTier === "pro" ? "- Offer detailed technical support and best practices" : ""}
    ${userTier === "enterprise" ? "- Provide priority support with custom solutions" : ""}
    
    Always respond in ${language} language.`;
  },

  model: ({ runtimeContext }) => {
    const userTier = runtimeContext.get("user-tier");
    return userTier === "enterprise" 
      ? openai("gpt-4") 
      : openai("gpt-3.5-turbo");
  },

  tools: ({ runtimeContext }) => {
    const userTier = runtimeContext.get("user-tier");
    const baseTools = [knowledgeBase, ticketSystem];
    
    if (userTier === "pro" || userTier === "enterprise") {
      baseTools.push(advancedAnalytics);
    }
    
    if (userTier === "enterprise") {
      baseTools.push(customIntegration);
    }
    
    return baseTools;
  }
});
```

----------------------------------------

TITLE: Creating a User Interaction Step with Suspend/Resume (TypeScript)
DESCRIPTION: Defines a `createStep` that handles user interaction by suspending the workflow until input is provided. It uses `resumeSchema` for expected resume data and `suspendSchema` for context during suspension.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_16

LANGUAGE: typescript
CODE:
```
const userInputStep = createStep({
  id: 'get-user-input',
  inputSchema: z.object({}),
  resumeSchema: z.object({
    userSelection: z.string(),
  }),
  suspendSchema: z.object({
    suspendContext: z.string(),
  }),
  outputSchema: z.object({
    userSelection: z.string(),
  }),
  execute: async ({ resumeData, suspend }) => {
    if (!resumeData?.userSelection) {
      // Suspend the workflow until user provides input
      await suspend({
        suspendContext: 'Waiting for user selection',
      });
      return { userSelection: '' }; // This return is not used when suspended
    }
    // If userSelection exists, continue with it
    return { userSelection: resumeData.userSelection };
  },
});
```

----------------------------------------

TITLE: Executing and Resuming Human-in-the-Loop Workflow (TypeScript)
DESCRIPTION: This TypeScript file demonstrates how to execute and resume the human-in-the-loop workflow. It retrieves the `travelAgentWorkflow` from the Mastra instance, starts a new run with an initial vacation description, and then pauses. After the `generate-suggestions` step completes, it uses `@inquirer/prompts` to collect user input for selecting a holiday destination. Finally, it resumes the workflow at the `humanInputStep` with the user's selection, allowing the process to continue.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows_vNext/human-in-the-loop.mdx#_snippet_4

LANGUAGE: ts
CODE:
```
import { mastra } from "./"
import { select } from '@inquirer/prompts'
import { humanInputStep } from './workflows/human-in-the-loop-workflow'
 

const workflow = mastra.vnext_getWorkflow('travelAgentWorkflow')
const run = workflow.createRun({})

// Start the workflow with initial vacation description
const result = await run.start({
  inputData: { vacationDescription: 'I want to go to the beach' }
})
 
console.log('result', result)
 
const suggStep = result?.steps?.['generate-suggestions']
 
// If suggestions were generated successfully, proceed with user interaction
if (suggStep.status === 'success') {
  const suggestions = suggStep.output?.suggestions
  
  // Present options to user and get their selection
  const userInput = await select<string>({
    message: "Choose your holiday destination",
    choices: suggestions.map(({ location, description }: { location: string, description: string }) => `- ${location}: ${description}`)
  })
 
  console.log('Selected:', userInput)
 
  // Prepare to resume the workflow with user's selection
  console.log('resuming from', result, 'with', {
    inputData: {
      selection: userInput,
      vacationDescription: "I want to go to the beach",
      suggestions: suggStep?.output?.suggestions
    },
    step: humanInputStep
  })

  const result2 = await run.resume({
    resumeData: {
      selection: userInput
    },
    step: humanInputStep
  })
 
  console.dir(result2, { depth: null })
}
```

----------------------------------------

TITLE: Creating a Human Input Step with Suspend/Resume in Mastra (TypeScript)
DESCRIPTION: This snippet demonstrates how to define a workflow step using `createStep` that can suspend execution, waiting for human input before resuming. It specifies the `inputSchema`, `resumeSchema` (for data needed to resume), and `suspendSchema`. The `execute` function checks for `resumeData`; if absent, it calls `suspend({})` to pause the workflow, otherwise it processes the `resumeData`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/suspend-and-resume.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
// Create a step that handles human input with suspend/resume capabilities
const humanInputStep = createStep({
  id: "human-input",
  inputSchema: z.object({
    suggestions: z.array(z.string()),
    vacationDescription: z.string(),
  }),
  // Define the structure of data needed to resume the step
  resumeSchema: z.object({
    selection: z.string(),
  }),
  // Define the structure of data when suspending (empty in this case)
  suspendSchema: z.object({}),
  outputSchema: z.object({
    selection: z.string().describe("The selection of the user"),
    vacationDescription: z.string(),
  }),
  execute: async ({ inputData, resumeData, suspend }) => {
    // If no resume data is provided, suspend the step and wait for user input
    if (!resumeData?.selection) {
      await suspend({});
      return {
        selection: "",
        vacationDescription: inputData?.vacationDescription,
      };
    }
    return {
      selection: resumeData.selection,
      vacationDescription: inputData?.vacationDescription,
    };
  },
});
```

----------------------------------------

TITLE: Implementing Conditional Branching - vNext vs. Original Mastra API (TypeScript)
DESCRIPTION: Compares conditional logic. vNext uses an array-based `branch` method with predicate functions, offering a clearer and more explicit decision path than the original API's `when` conditions within `then`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_32

LANGUAGE: typescript
CODE:
```
// vNext - array-based branching
workflow.branch([
  [async ({ inputData }) => inputData.value > 50, highValueStep],
  [async ({ inputData }) => inputData.value <= 50, lowValueStep],
]);
```

LANGUAGE: typescript
CODE:
```
// Original Mastra API - when-based conditions
workflow
  .then(step2, {
    id: 'step2',
    when: {
      ref: { step: step1, path: 'status' },
      query: { $eq: 'success' },
    },
  })
  .then(step3, {
    id: 'step3',
    when: {
      ref: { step: step1, path: 'status' },
      query: { $eq: 'failed' },
    },
  });
```

----------------------------------------

TITLE: Mapping Variables Between Workflow Steps (TypeScript)
DESCRIPTION: Demonstrates the use of `.map()` to explicitly transform and pass data between steps. It shows how to map values from a previous step's output, runtime context, constant values, and initial workflow data.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_15

LANGUAGE: typescript
CODE:
```
myWorkflow
  .then(step1)
  .map({
    transformedValue: {
      step: step1,
      path: 'nestedValue',
    },
    runtimeContextValue: {
      runtimeContextPath: 'runtimeContextValue',
      schema: z.number(),
    },
    constantValue: {
      value: 42,
      schema: z.number(),
    },
    initDataValue: {
      initData: myWorkflow,
      path: 'startValue',
    },
  })
  .then(step2)
  .commit();
```

----------------------------------------

TITLE: Initializing an AI Agent with Mastra Core
DESCRIPTION: This snippet shows how to create an `Agent` instance using `@mastra/core/agent`. Agents are autonomous AI entities that can understand instructions, use tools, and complete tasks. It requires a name, instructions, and a model (e.g., OpenAI's gpt-4o-mini).
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/README.md#_snippet_1

LANGUAGE: typescript
CODE:
```
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';

const agent = new Agent({
  name: 'my-agent',
  instructions: 'Your task-specific instructions',
  model: openai('gpt-4o-mini'),
  tools: {}, // Optional tools
});
```

----------------------------------------

TITLE: Performing Metadata-Based Queries with the RAG Agent (TypeScript)
DESCRIPTION: This snippet provides examples of how to query the RAG system using the configured agent. It demonstrates various types of queries, including semantic search, filtering by a nested ID field using a 'greater than' operator, and searching the 'text' field using a regex operator, showcasing the agent's ability to apply metadata filters effectively.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/filter-rag.mdx#_snippet_8

LANGUAGE: typescript
CODE:
```
const queryOne = "What are the adaptation strategies mentioned?";
const answerOne = await agent.generate(queryOne);
console.log("\nQuery:", queryOne);
console.log("Response:", answerOne.text);

const queryTwo =
  'Show me recent sections. Check the "nested.id" field and return values that are greater than 2.';
const answerTwo = await agent.generate(queryTwo);
console.log("\nQuery:", queryTwo);
console.log("Response:", answerTwo.text);

const queryThree =
  'Search the "text" field using regex operator to find sections containing "temperature".';
const answerThree = await agent.generate(queryThree);
console.log("\nQuery:", queryThree);
console.log("Response:", answerThree.text);
```

----------------------------------------

TITLE: Initializing VectorQueryTool with Filtering Enabled (TypeScript)
DESCRIPTION: This snippet initializes a `createVectorQueryTool` configured to enable metadata filtering. It connects to a Pinecone vector store, uses a specified index and embedding model, and sets `enableFilter` to `true` to allow agent-driven construction of metadata filters from natural language queries.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/vector-query-tool.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
  enableFilter: true,
});
```

----------------------------------------

TITLE: Creating Custom Tools with Mastra Core (TypeScript)
DESCRIPTION: This snippet demonstrates how to define a custom tool using `@mastra/core/tools`. It shows the `createTool` function, specifying an `id`, an `inputSchema` using `zod` for input validation, a `description`, and an `execute` function containing the tool's logic. The `execute` function receives a `context` object with input parameters.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/using-tools-and-mcp.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { createTool } from "@mastra/core/tools";
import { z } from "zod";

export const weatherInfo = createTool({
  id: "Get Weather Information",
  inputSchema: z.object({
    city: z.string(),
  }),
  description: `Fetches the current weather information for a given city`,
  execute: async ({ context: { city } }) => {
    // Tool logic here (e.g., API call)
    console.log("Using tool to fetch weather information for", city);
    return { temperature: 20, conditions: "Sunny" }; // Example return
  },
});
```

----------------------------------------

TITLE: Initializing Mastra Project with pnpm - Bash
DESCRIPTION: This command sequence initializes a new Node.js project using pnpm, installs essential development dependencies like TypeScript and tsx, and then adds core Mastra packages along with zod and @ai-sdk/openai for AI functionalities. This sets up the project structure and required libraries efficiently.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_5

LANGUAGE: bash
CODE:
```
pnpm init

pnpm add typescript tsx @types/node mastra@latest --save-dev

pnpm add @mastra/core@latest zod @ai-sdk/openai
```

----------------------------------------

TITLE: Defining Prompt Intent in TypeScript
DESCRIPTION: Illustrates the importance of clear and specific intent when creating prompts using `createPrompt`. It contrasts a vague prompt with a clear one, emphasizing that the primary instruction should be precise for better model performance.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/prompt-template.md#_snippet_0

LANGUAGE: typescript
CODE:
```
// ❌ Vague intent
createPrompt('fix this');

// ✅ Clear intent
createPrompt('Add type checking to this function');
```

----------------------------------------

TITLE: Creating and Running a Tool-Based Workflow in Mastra (TypeScript)
DESCRIPTION: This snippet illustrates how to build and execute a Mastra workflow that utilizes a custom tool as a step. It involves defining a `createTool` instance for weather information, creating custom steps for input formatting and output formatting, integrating the tool using `createStep(tool)`, defining the workflow's structure, and running it with example input.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/using-with-agents-and-tools.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { createTool, Mastra } from "@mastra/core";
import { createWorkflow, createStep } from "@mastra/core/workflows";
import { z } from "zod";

// Create a weather tool
const weatherTool = createTool({
  id: "weather-tool",
  description: "Get weather information for a location",
  inputSchema: z.object({
      location: z.string().describe("The city name")
  }),
  outputSchema: z.object({
      temperature: z.number(),
      conditions: z.string()
  }),
  execute: async ({ context: {location} }) => {
      return { 
          temperature: 22, 
          conditions: "Sunny" 
      };
  },
});

// Create a step that formats the input
const locationStep = createStep({
  id: "location-formatter",
  inputSchema: z.object({
      city: z.string()
  }),
  outputSchema: z.object({
      location: z.string()
  }),
  execute: async ({ inputData }) => {
      return {
          location: inputData.city
      };
  }
});

// Create a step that formats the output
const formatResultStep = createStep({
  id: "format-result",
  inputSchema: z.object({
      temperature: z.number(),
      conditions: z.string()
  }),
  outputSchema: z.object({
      weatherReport: z.string()
  }),
  execute: async ({ inputData }) => {
      return {
          weatherReport: `Current weather: ${inputData.temperature}°C and ${inputData.conditions}`
      };
  }
});

const weatherToolStep = createStep(weatherTool)

// Create the workflow
const weatherWorkflow = createWorkflow({
  id: "weather-workflow",
  inputSchema: z.object({
      city: z.string()
  }),
  outputSchema: z.object({
      weatherReport: z.string()
  }),
  steps: [locationStep, weatherToolStep, formatResultStep]
});

// Define workflow sequence
weatherWorkflow
  .then(locationStep)
  .then(weatherToolStep)
  .then(formatResultStep)
  .commit();

// Create Mastra instance
const mastra = new Mastra({
  workflows: {
      weatherWorkflow
  }
});


const workflow = mastra.getWorkflow("weatherWorkflow");
const run = workflow.createRun();

// Run the workflow
const result = await run.start({
  inputData: {
      city: "Tokyo"
  }
});

if (result.status === "success") {
  console.log(result.result.weatherReport);
} else if (result.status === "failed") {
  console.error("Workflow failed:", result.error);
}
```

----------------------------------------

TITLE: Defining Activity Planning Step and Workflow in Mastra AI (TypeScript)
DESCRIPTION: This section defines two key components: the 'planActivities' step and the 'activityPlanningWorkflow'. The 'planActivities' step leverages a Mastra AI agent ('planningAgent') to generate activity recommendations based on the weather forecast provided as input. The 'activityPlanningWorkflow' orchestrates the execution, chaining 'fetchWeather' and 'planActivities' to provide a complete solution from city input to activity suggestions. It also includes the 'commit()' call to finalize the workflow definition.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/calling-agent.mdx#_snippet_4

LANGUAGE: TypeScript
CODE:
```
const planActivities = createStep({
  id: "plan-activities",
  description: "Suggests activities based on weather conditions",
  inputSchema: forecastSchema,
  outputSchema: z.object({
    activities: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    const forecast = inputData
 
    if (!forecast) {
      throw new Error("Forecast data not found");
    }
 
    const prompt = `Based on the following weather forecast for ${forecast.location}, suggest appropriate activities:
      ${JSON.stringify(forecast, null, 2)}
      `
 
    const agent = mastra?.getAgent('planningAgent')
    if (!agent) {
      throw new Error("Planning agent not found");
    }
 
    const response = await agent.stream([
      {
        role: "user",
        content: prompt,
      },
    ])
 
    let activitiesText = ''
    for await (const chunk of response.textStream) {
      process.stdout.write(chunk);
      activitiesText += chunk;
    }
 
    return {
      activities: activitiesText,
    };
  },
})
 
const activityPlanningWorkflow = createWorkflow({
  steps: [fetchWeather, planActivities],
  id: 'activity-planning-step1-single-day',
  inputSchema: z.object({
    city: z.string().describe("The city to get the weather for"),
  }),
  outputSchema: z.object({
    activities: z.string(),
  }),
})
  .then(fetchWeather)
  .then(planActivities)
 
activityPlanningWorkflow.commit()
 
export { activityPlanningWorkflow }
```

----------------------------------------

TITLE: Using Mastra Agent Stream with Memory Context (TypeScript)
DESCRIPTION: This example illustrates how to interact with a Mastra agent's `stream()` method while leveraging its memory. By providing `resourceId` (identifying the user) and `threadId` (identifying the conversation), the agent can store and recall information, as shown by remembering and later recalling a user's favorite color within the same thread.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/agent-memory.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
// Example agent call using memory
await agent.stream("Remember my favorite color is blue.", {
  resourceId: "user_alice",
  threadId: "preferences_thread"
});

// Later in the same thread...
const response = await agent.stream("What's my favorite color?", {
  resourceId: "user_alice",
  threadId: "preferences_thread"
});
// Agent will use memory to recall the favorite color.
```

----------------------------------------

TITLE: Instantiating PgVector and Mastra Core Components
DESCRIPTION: This code initializes the `PgVector` instance using the provided PostgreSQL connection string. It then creates the main `Mastra` instance, registering the `ragAgent`, `pgVector` store, and `ragWorkflow` to ensure all components are available and integrated within the Mastra ecosystem.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#_snippet_11

LANGUAGE: typescript
CODE:
```
const pgVector = new PgVector({ connectionString: process.env.POSTGRES_CONNECTION_STRING! });

export const mastra = new Mastra({
  agents: { ragAgent },
  vectors: { pgVector },
  workflows: { ragWorkflow }
});
```

----------------------------------------

TITLE: Merging Parallel Branches with Multiple Dependencies in Mastra Workflow (TypeScript)
DESCRIPTION: This snippet demonstrates merging multiple parallel execution paths using the '.after([])' syntax. 'fetchUserData' and 'fetchProductData' run in parallel with their respective validation steps, and 'processOrder' only executes after both 'validateUserData' and 'validateProductData' have successfully completed, ensuring synchronization.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_3

LANGUAGE: TypeScript
CODE:
```
myWorkflow
  .step(fetchUserData)
  .then(validateUserData)
  .step(fetchProductData)
  .then(validateProductData)
  // This step will only run after BOTH validateUserData AND validateProductData have completed
  .after([validateUserData, validateProductData])
  .step(processOrder);
```

----------------------------------------

TITLE: Defining Conditional Workflow with Mastra (TypeScript)
DESCRIPTION: This snippet defines `activityPlanningWorkflow` using `createWorkflow`, specifying input/output schemas. It uses `.then(fetchWeather)` for a sequential step and `.branch` for conditional execution, directing to `planIndoorActivities` or `planActivities` based on `precipitationChance`. The workflow is then committed and exported for use.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/conditional-branching.mdx#_snippet_6

LANGUAGE: TypeScript
CODE:
```
const activityPlanningWorkflow = createWorkflow({
  id: 'activity-planning-workflow-step2-if-else',
  inputSchema: z.object({
    city: z.string().describe("The city to get the weather for")
  }),
  outputSchema: z.object({
    activities: z.string()
  })
})
  .then(fetchWeather)
  .branch([
    // Branch for high precipitation (indoor activities)
    [
      async ({ inputData }) => {
        return inputData?.precipitationChance > 50;
      },
      planIndoorActivities
    ],
    // Branch for low precipitation (outdoor activities)
    [
      async ({ inputData }) => {
        return inputData?.precipitationChance <= 50;
      },
      planActivities
    ]
  ]);

activityPlanningWorkflow.commit()

export { activityPlanningWorkflow }
```

----------------------------------------

TITLE: Complete Document Processing and Embedding Pipeline | Mastra & AI SDK | TypeScript
DESCRIPTION: Illustrates the end-to-end process of loading text into a MDocument, chunking it, generating embeddings using either OpenAI or Cohere via `embedMany`, and preparing them for storage in a vector database. Shows necessary imports and sequential steps.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/chunking-and-embedding.mdx#_snippet_6

LANGUAGE: TypeScript
CODE:
```
import { embedMany } from "ai";
import { openai } from "@ai-sdk/openai";
import { cohere } from "@ai-sdk/cohere";

import { MDocument } from "@mastra/rag";

// Initialize document
const doc = MDocument.fromText(`
  Climate change poses significant challenges to global agriculture.
  Rising temperatures and changing precipitation patterns affect crop yields.
`);

// Create chunks
const chunks = await doc.chunk({
  strategy: "recursive",
  size: 256,
  overlap: 50,
});

// Generate embeddings with OpenAI
const { embeddings: openAIEmbeddings } = await embedMany({
  model: openai.embedding("text-embedding-3-small"),
  values: chunks.map((chunk) => chunk.text),
});

// OR

// Generate embeddings with Cohere
const { embeddings: cohereEmbeddings } = await embedMany({
  model: cohere.embedding("embed-english-v3.0"),
  values: chunks.map((chunk) => chunk.text),
});

// Store embeddings in your vector database
await vectorStore.upsert({
  indexName: "embeddings",
  vectors: embeddings,
});
```

----------------------------------------

TITLE: Defining a Custom Tool for Mastra Agents
DESCRIPTION: This snippet shows how to create a custom tool using `createTool` from `@mastra/core/tools`. Tools allow agents to interact with external systems. Each tool requires an ID, an input schema (using Zod), a description, and an `execute` function for its implementation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/README.md#_snippet_4

LANGUAGE: typescript
CODE:
```
import { createTool } from '@mastra/core/tools';
import { z } from 'zod';

const weatherInfo = createTool({
  id: 'Get Weather Information',
  inputSchema: z.object({
    city: z.string(),
  }),
  description: 'Fetches the current weather information for a given city',
  execute: async ({ context: { city } }) => {
    // Tool implementation
  },
});
```

----------------------------------------

TITLE: Creating a Thread with Memory (TypeScript)
DESCRIPTION: This snippet demonstrates how to initialize the Memory class and use the `createThread` method to create a new conversation thread, providing a resource ID, title, and optional metadata.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/createThread.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { Memory } from "@mastra/memory";

const memory = new Memory({
  /* config */
});
const thread = await memory.createThread({
  resourceId: "user-123",
  title: "Support Conversation",
  metadata: {
    category: "support",
    priority: "high",
  },
});
```

----------------------------------------

TITLE: Initializing MCPServer with Tools and Agents (TypeScript)
DESCRIPTION: This snippet demonstrates how to instantiate an `MCPServer` to expose Mastra tools, agents, and workflows. It shows the creation of a custom agent and a tool, then registers them along with a workflow to the server. Agents and workflows are automatically converted into callable tools for MCP clients.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-server.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { createTool } from "@mastra/core/tools";
import { MCPServer } from "@mastra/mcp";
import { z } from "zod";
import { dataProcessingWorkflow } from "../workflows/dataProcessingWorkflow";

const myAgent = new Agent({
  name: "MyExampleAgent",
  description: "A generalist to help with basic questions."
  instructions: "You are a helpful assistant.",
  model: openai("gpt-4o-mini"),
});

const weatherTool = createTool({
  id: "getWeather",
  description: "Gets the current weather for a location.",
  inputSchema: z.object({ location: z.string() }),
  execute: async ({ context }) => `Weather in ${context.location} is sunny.`,
});

const server = new MCPServer({
  name: "My Custom Server",
  version: "1.0.0",
  tools: { weatherTool },
  agents: { myAgent }, // this agent will become tool "ask_myAgent"
  workflows: {
    dataProcessingWorkflow, // this workflow will become tool "run_dataProcessingWorkflow"
  }
});
```

----------------------------------------

TITLE: Generating Structured Output with Zod Schema in Mastra
DESCRIPTION: This snippet demonstrates how to use Zod to define a type-safe schema for structured output from a Mastra agent. The Zod schema is then passed to the `output` option of the agent's `.generate()` method, ensuring the response conforms to the defined structure and provides strong typing.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_8

LANGUAGE: ts
CODE:
```
import { z } from "zod";

// Define the Zod schema
const schema = z.object({
  summary: z.string(),
  keywords: z.array(z.string()),
});

// Use the schema with the agent
const response = await myAgent.generate(
  [
    {
      role: "user",
      content:
        "Please provide a summary and keywords for the following text: ...",
    },
  ],
  {
    output: schema,
  },
);

console.log("Structured Output:", response.object);
```

----------------------------------------

TITLE: Combining Multiple Branch Merges in Mastra Workflow (TypeScript)
DESCRIPTION: This snippet illustrates how to create highly complex dependency patterns by combining multiple '.after([])' calls. It shows three independent branches ('stepA'->'stepB'->'stepC', 'stepD'->'stepE', 'stepF'->'stepG') converging into a 'finalStep' which only executes after all three branch-ending steps ('stepC', 'stepE', 'stepG') have completed.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_4

LANGUAGE: TypeScript
CODE:
```
myWorkflow
  // First branch
  .step(stepA)
  .then(stepB)
  .then(stepC)

  // Second branch
  .step(stepD)
  .then(stepE)

  // Third branch
  .step(stepF)
  .then(stepG)

  // This step depends on the completion of multiple branches
  .after([stepC, stepE, stepG])
  .step(finalStep);
```

----------------------------------------

TITLE: Configuring and Committing the Mastra RAG Workflow Steps
DESCRIPTION: This snippet demonstrates how to sequentially chain all the defined workflow steps (`analyzeContext`, `breakdownThoughts`, `connectPieces`, `drawConclusions`, `finalAnswer`) using the `.step()` and `.then()` methods. Finally, `ragWorkflow.commit()` finalizes the workflow's configuration, making it ready for execution.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#_snippet_10

LANGUAGE: typescript
CODE:
```
ragWorkflow
  .step(analyzeContext)
  .then(breakdownThoughts)
  .then(connectPieces)
  .then(drawConclusions)
  .then(finalAnswer);

ragWorkflow.commit();
```

----------------------------------------

TITLE: Chunking and Embedding Initial Documents (TypeScript)
DESCRIPTION: This snippet demonstrates the process of chunking an initial document (`doc`) into smaller segments. It then generates embeddings for these chunks using OpenAI's 'text-embedding-3-small' model and upserts them into the 'embeddings' index of the PgVector store.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cleanup-rag.mdx#_snippet_6

LANGUAGE: TypeScript
CODE:
```
const chunks = await doc.chunk({
  strategy: "recursive",
  size: 256,
  overlap: 50,
  separator: "\n",
});

const { embeddings } = await embedMany({
  model: openai.embedding("text-embedding-3-small"),
  values: chunks.map((chunk) => chunk.text),
});

const vectorStore = mastra.getVector("pgVector");
await vectorStore.createIndex({
  indexName: "embeddings",
  dimension: 1536,
});

await vectorStore.upsert({
  indexName: "embeddings",
  vectors: embeddings,
  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),
});
```

----------------------------------------

TITLE: Defining `fetchWeather` Workflow Step (TypeScript)
DESCRIPTION: This step, `fetchWeather`, is responsible for simulating the retrieval of weather information for a given city. It uses `zod` to define its input schema (city: string) and output schema (temperature: number, conditions: string, city: string), and its `execute` function returns mock weather data. This step serves as the initial data source for the workflow.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/using-with-agents-and-tools.mdx#_snippet_3

LANGUAGE: TypeScript
CODE:
```
const fetchWeather = createStep({
  id: "fetch-weather",
  inputSchema: z.object({
    city: z.string().describe("The city to get the weather for")
  }),
  outputSchema: z.object({
    temperature: z.number(),
    conditions: z.string(),
    city: z.string()
  }),
  execute: async ({ inputData }) => {
    return {
      temperature: 25,
      conditions: "Sunny",
      city: inputData.city
    };
  }
});
```

----------------------------------------

TITLE: Integrating Mastra Agents as Workflow Steps (TypeScript)
DESCRIPTION: This snippet demonstrates how to directly use a Mastra Agent as a step within a vNext workflow. It sets up an agent, defines a data preparation step, and then orchestrates them into a simple Q&A workflow, showcasing input mapping and execution.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows-vnext/using-with-agents-and-tools.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { Mastra } from "@mastra/core";
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { createWorkflow, createStep } from "@mastra/core/workflows/vNext";
import { z } from "zod";

const myAgent = new Agent({
  name: "myAgent",
  instructions: "You are a helpful assistant that answers questions concisely.",
  model: openai("gpt-4o"),
});

// Input preparation step
const preparationStep = createStep({
  id: "preparation",
  inputSchema: z.object({
      question: z.string()
  }),
  outputSchema: z.object({
      formattedPrompt: z.string()
  }),
  execute: async ({ inputData }) => {
      return {
          formattedPrompt: `Answer this question briefly: ${inputData.question}`
      };
  }
});

const agentStep = createStep(myAgent)

// Create a simple workflow
const myWorkflow = createWorkflow({
  id: "simple-qa-workflow",
  inputSchema: z.object({
      question: z.string()
  }),
  outputSchema: z.string(),
  steps: [preparationStep, agentStep]
});

// Define workflow sequence
myWorkflow
  .then(preparationStep)
  .map({
    prompt: {
        step: preparationStep,
        path: "formattedPrompt",
    },
  })
  .then(agentStep)
  .commit();

// Create Mastra instance
const mastra = new Mastra({
  agents: {
      myAgent,
  },
  vnext_workflows: {
      myWorkflow,
  },
});

const workflow = mastra.vnext_getWorkflow("myWorkflow");
const run = workflow.createRun();

// Run the workflow with a question
const res = await run.start({
  inputData: {
      question: "What is machine learning?"
  }
});

if (res.status === "success") {
  console.log("Answer:", res.result);
} else if (res.status === "failed") {
  console.error("Workflow failed:", res.error);
}
```

----------------------------------------

TITLE: Executing Parallel Nested Workflows in Mastra (TypeScript)
DESCRIPTION: This example illustrates how to run entire nested workflows in parallel. The outputs from these parallel workflows are collected into a single object, where keys correspond to the workflow IDs and values are their respective outputs, which then serve as input for the subsequent step.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows-vnext/flow-control.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
myWorkflow
  .parallel([nestedWorkflow1, nestedWorkflow2])
  .then(finalStep)
  .commit();
```

----------------------------------------

TITLE: Defining and Initializing a Mastra Workflow - TypeScript
DESCRIPTION: This snippet shows how to define a workflow using `createWorkflow`, specifying its ID, input/output schemas, and an array of declared steps for type safety. It then demonstrates how to register this workflow with a `Mastra` instance and create a new run for execution.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_2

LANGUAGE: typescript
CODE:
```
const myWorkflow = createWorkflow({
  id: 'my-workflow',
  inputSchema: z.object({
    startValue: z.string(),
  }),
  outputSchema: z.object({
    result: z.string(),
  }),
  steps: [step1, step2, step3], // Declare steps used in this workflow
});

const mastra = new Mastra({
  vnext_workflows: {
    myWorkflow,
  },
});

const run = mastra.vnext_getWorkflow('myWorkflow').createRun();
```

----------------------------------------

TITLE: Re-ranking Results with Mastra RAG and OpenAI (TypeScript)
DESCRIPTION: This snippet demonstrates how to re-rank initial vector search results using the `@mastra/rag` library and an OpenAI model. It takes `initialResults` and a `query` to apply more sophisticated relevance scoring, improving retrieval quality. Ensure `metadata.text` is present in results for semantic scoring.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/retrieval.mdx#_snippet_17

LANGUAGE: TypeScript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { rerank } from "@mastra/rag";

// Get initial results from vector search
const initialResults = await pgVector.query({
  indexName: "embeddings",
  queryVector: queryEmbedding,
  topK: 10,
});

// Re-rank the results
const rerankedResults = await rerank(
  initialResults,
  query,
  openai("gpt-4o-mini"),
);
```

----------------------------------------

TITLE: Nesting Workflows in Mastra for Modular Design (TypeScript)
DESCRIPTION: This example illustrates how to nest one workflow (`nestedWorkflow`) as a step within another (`mainWorkflow`). For proper integration, the `nestedWorkflow`'s input schema must match the `initialStep`'s output, and its output schema must match the `finalStep`'s input, promoting modular and reusable workflow components.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows-vnext/flow-control.mdx#_snippet_9

LANGUAGE: typescript
CODE:
```
const nestedWorkflow = createWorkflow({
  id: 'nested-workflow',
  inputSchema: z.object({...}),
  outputSchema: z.object({...})
})
  .then(step1)
  .then(step2)
  .commit();

const mainWorkflow = createWorkflow({
  id: 'main-workflow',
  inputSchema: z.object({...}),
  outputSchema: z.object({...})
})
  .then(initialStep)
  .then(nestedWorkflow)
  .then(finalStep)
  .commit();
```

----------------------------------------

TITLE: Implementing Foreach Loops in Mastra Workflows (TypeScript)
DESCRIPTION: This comprehensive example demonstrates the `foreach` step, which iterates over an array-typed input, executing a specified step for each item sequentially. It includes the definition of `mapStep` and `finalStep`, the `counterWorkflow` setup, and a full example of running the workflow and handling its results.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows-vnext/flow-control.mdx#_snippet_7

LANGUAGE: typescript
CODE:
```
const mapStep = createStep({
  id: "map",
  description: "Maps (+11) on the current value",
  inputSchema: z.object({
    value: z.number()
  }),
  outputSchema: z.object({
    value: z.number()
  }),
  execute: async ({ inputData }) => {
    return { value: inputData.value + 11 };
  }
});

const finalStep = createStep({
  id: "final",
  description: "Final step that prints the result",
  inputSchema: z.array(z.object({ value: z.number() })),
  outputSchema: z.object({
    finalValue: z.number()
  }),
  execute: async ({ inputData }) => {
    return { finalValue: inputData.reduce((acc, curr) => acc + curr.value, 0) };
  }
});

const counterWorkflow = createWorkflow({
  steps: [mapStep, finalStep],
  id: "counter-workflow",
  inputSchema: z.array(z.object({ value: z.number() })),
  outputSchema: z.object({
    finalValue: z.number()
  })
});

counterWorkflow.foreach(mapStep).then(finalStep).commit();

const run = counterWorkflow.createRun();
const result = await run.start({
  inputData: [{ value: 1 }, { value: 22 }, { value: 333 }]
});

if (result.status === "success") {
  console.log(result.result); // only exists if status is success
} else if (result.status === "failed") {
  console.error(result.error); // only exists if status is failed, this is an instance of Error
}
```

----------------------------------------

TITLE: Configuring MCPClient and Agent with Tools - TypeScript
DESCRIPTION: This comprehensive example demonstrates initializing `MCPClient` with multiple server configurations (e.g., 'stockPrice', 'weather') and then creating an `Agent` using `mcp.getTools()`. It also includes an asynchronous function `checkWeatherResource` to showcase fetching and reading weather resources, illustrating the integration of `resources.list()` and `resources.read()` within an application context.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-client.mdx#_snippet_19

LANGUAGE: typescript
CODE:
```
import { MCPClient } from "@mastra/mcp";
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";

const mcp = new MCPClient({
  servers: {
    stockPrice: {
      command: "npx",
      args: ["tsx", "stock-price.ts"],
      env: {
        API_KEY: "your-api-key"
      },
      log: (logMessage) => {
        console.log(`[${logMessage.level}] ${logMessage.message}`);
      }
    },
    weather: {
      url: new URL("http://localhost:8080/sse")
    }
  },
  timeout: 30000 // Global 30s timeout
});

// Create an agent with access to all tools
const agent = new Agent({
  name: "Multi-tool Agent",
  instructions: "You have access to multiple tool servers.",
  model: openai("gpt-4"),
  tools: await mcp.getTools()
});

// Example of using resource methods
async function checkWeatherResource() {
  try {
    const weatherResources = await mcp.resources.list();
    if (weatherResources.weather && weatherResources.weather.length > 0) {
      const currentWeatherURI = weatherResources.weather[0].uri;
      const weatherData = await mcp.resources.read('weather', currentWeatherURI);
      console.log('Weather data:', weatherData.contents[0].text);
    }
  } catch (error) {
    console.error("Error fetching weather resource:", error);
  }
}
checkWeatherResource();
```

----------------------------------------

TITLE: Retrieving Top-K Results from Pinecone using Mastra and OpenAI Embeddings (TypeScript)
DESCRIPTION: This snippet demonstrates the end-to-end process of embedding text content using OpenAI, upserting these embeddings into a Pinecone vector database, and then querying the database to retrieve the top-K most semantically similar results. It showcases the integration of text chunking, embedding generation, and vector database operations to find relevant information.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/query/retrieve-results.mdx#_snippet_0

LANGUAGE: tsx
CODE:
```
import { openai } from "@ai-sdk/openai";
import { PineconeVector } from "@mastra/pinecone";
import { MDocument } from "@mastra/rag";
import { embedMany } from "ai";

const doc = MDocument.fromText("Your text content...");

const chunks = await doc.chunk();

const { embeddings } = await embedMany({
  values: chunks.map((chunk) => chunk.text),
  model: openai.embedding("text-embedding-3-small"),
});

const pinecone = new PineconeVector({
  apiKey: "your-api-key",
});

await pinecone.createIndex({
  indexName: "test_index",
  dimension: 1536,
});

await pinecone.upsert({
  indexName: "test_index",
  vectors: embeddings,
  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),
});

const topK = 10;

const results = await pinecone.query({
  indexName: "test_index",
  queryVector: embeddings[0],
  topK,
});

console.log(results);
```

----------------------------------------

TITLE: Providing Runtime Context for Agent Generation (TypeScript)
DESCRIPTION: This example demonstrates how to create and populate a `RuntimeContext` object to dynamically supply parameters during agent execution. It sets various context variables such as vector store name, index name, `topK` results, a category filter, and graph traversal parameters, which are then passed to an agent's `generate` method to influence its behavior at runtime.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/graph-rag-tool.mdx#_snippet_5

LANGUAGE: TypeScript
CODE:
```
const runtimeContext = new RuntimeContext<{ vectorStoreName: string; indexName: string; topK: number; filter: any }>();
runtimeContext.set("vectorStoreName", "my-store");
runtimeContext.set("indexName", "my-index");
runtimeContext.set("topK", 5);
runtimeContext.set("filter", { "category": "docs" });
runtimeContext.set("randomWalkSteps", 100);
runtimeContext.set("restartProb", 0.15);

const response = await agent.generate("Find documentation from the knowledge base.", {
  runtimeContext,
});
```

----------------------------------------

TITLE: Configuring Memory with OpenAI API Embedder - TypeScript
DESCRIPTION: This example demonstrates how to configure the `Memory` class to use an OpenAI API-based embedding model for semantic recall. It imports `openai` from `@ai-sdk/openai` and sets the `embedder` property to an OpenAI embedding instance, specifying the desired model (`text-embedding-3-small`). This approach leverages cloud-based embedding services for scalability and ease of use.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/Memory.mdx#_snippet_5

LANGUAGE: typescript
CODE:
```
import { Memory } from "@mastra/memory";
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";

const agent = new Agent({
  memory: new Memory({
    embedder: openai.embedding("text-embedding-3-small"),
  }),
});
```

----------------------------------------

TITLE: Initializing Voice Agent with Murf Voice in TypeScript
DESCRIPTION: This snippet demonstrates how to initialize a Mastra AI voice agent using the Murf Voice provider. It configures the agent with a GPT-4o model, generates a text response, converts the text to an audio stream using Murf's TTS, and then plays the audio.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#_snippet_10

LANGUAGE: typescript
CODE:
```
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';
import { MurfVoice } from "@mastra/voice-murf";
import { playAudio } from "@mastra/node-audio";

const voiceAgent = new Agent({
  name: "Voice Agent",
  instructions: "You are a voice assistant that can help users with their tasks.",
  model: openai("gpt-4o"),
  voice: new MurfVoice(),
});

const { text } = await voiceAgent.generate('What color is the sky?');

// Convert text to speech to an Audio Stream
const audioStream = await voiceAgent.voice.speak(text, {
  speaker: "default" // Optional: specify a speaker
});

playAudio(audioStream);
```

----------------------------------------

TITLE: Defining a Branching Candidate Workflow in TypeScript
DESCRIPTION: This snippet defines a `candidateWorkflow` using `createWorkflow`, specifying its input and output schemas. It then implements branching logic using `.then()` and `.branch()` to conditionally execute `askAboutSpecialty` or `askAboutRole` based on the `isTechnical` property of the input data. The workflow is committed at the end.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/ai-recruiter.mdx#_snippet_5

LANGUAGE: TypeScript
CODE:
```
const candidateWorkflow = createWorkflow({
  id: "candidate-workflow",
  inputSchema: z.object({
    resumeText: z.string(),
  }),
  outputSchema: z.object({
    question: z.string(),
  }),
});

candidateWorkflow
  .then(gatherCandidateInfo)
  .branch([
    // Branch for technical candidates
    [
      async ({ inputData }) => {
        return inputData?.isTechnical;
      },
      askAboutSpecialty,
    ],
    // Branch for non-technical candidates
    [
      async ({ inputData }) => {
        return !inputData?.isTechnical;
      },
      askAboutRole,
    ],
  ]);

candidateWorkflow.commit();
```

----------------------------------------

TITLE: Initializing Mastra Memory with PostgreSQL and Agent in TypeScript
DESCRIPTION: This snippet demonstrates how to set up Mastra's memory system using PostgreSQL for storage and PgVector for vector search capabilities. It initializes a Memory instance with connection details and options for message history and semantic recall, then creates an Agent that leverages this memory for conversational context.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-with-pg.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { Memory } from "@mastra/memory";
import { PostgresStore, PgVector } from "@mastra/pg";
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";

// PostgreSQL connection details
const host = "localhost";
const port = 5432;
const user = "postgres";
const database = "postgres";
const password = "postgres";
const connectionString = `postgresql://${user}:${password}@${host}:${port}`;

// Initialize memory with PostgreSQL storage and vector search
const memory = new Memory({
  storage: new PostgresStore({
    host,
    port,
    user,
    database,
    password,
  }),
  vector: new PgVector({ connectionString }),
  options: {
    lastMessages: 10,
    semanticRecall: {
      topK: 3,
      messageRange: 2,
    },
  },
});

// Create an agent with memory capabilities
const chefAgent = new Agent({
  name: "chefAgent",
  instructions:
    "You are Michel, a practical and experienced home chef who helps people cook great meals with whatever ingredients they have available.",
  model: openai("gpt-4o-mini"),
  memory,
});
```

----------------------------------------

TITLE: Installing @mastra/core with npm
DESCRIPTION: This snippet demonstrates how to install the `@mastra/core` package using npm, the Node.js package manager. This is the first step to set up the Mastra framework in your project.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/README.md#_snippet_0

LANGUAGE: bash
CODE:
```
npm install @mastra/core
```

----------------------------------------

TITLE: Chunking Plain Text with Mastra RAG in TypeScript
DESCRIPTION: This snippet demonstrates how to use the `MDocument` class from the `@mastra/rag` library to split a plain text string into smaller chunks. It initializes a document from text content and then calls the `chunk()` method, which processes the text using default semantic chunking settings. The result is an array of text segments suitable for retrieval or analysis.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/chunking/chunk-text.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { MDocument } from "@mastra/rag";

const doc = MDocument.fromText("Your plain text content...");

const chunks = await doc.chunk();
```

----------------------------------------

TITLE: Implementing Self-Verification Prompting in Mastra (TypeScript)
DESCRIPTION: This snippet illustrates how to enable self-verification in Mastra prompts, allowing the model to validate its own outputs against specified criteria. It combines `thinking` steps for initial generation with `verificationSteps` and `constraints` to ensure the generated code meets requirements and handles various scenarios, including test cases.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/examples.md#_snippet_3

LANGUAGE: typescript
CODE:
```
type CodeGenerationVars = {
  requirements: string;
  language: 'typescript' | 'python' | 'javascript';
  testCases?: string[];
};

const codeGenPrompt = createPrompt<CodeGenerationVars>('Generate code with verification', {
  persona: 'Senior Software Engineer',
  outputFormat: 'markdown',
})
  .text('Generate {{language}} code that meets these requirements:\n\n{{requirements}}')
  .thinking({
    steps: [
      'Analyze requirements',
      'Plan implementation approach',
      'Write initial code',
      'Add error handling',
      'Implement input validation',
    ],
  })
  .verificationSteps([
    'Check if implementation meets all requirements',
    'Run test cases: {{testCases}}',
    'Verify edge case handling',
    'Validate error handling',
    'Check input validation',
    'Assess code quality',
    'Identify potential improvements',
  ])
  .constraints([
    'Must handle all edge cases',
    'Include input validation',
    'Add error handling',
    'Follow {{language}} best practices',
  ]);

// Usage example
const implementation = codeGenPrompt.toString({
  requirements: 'Create a function that validates email addresses',
  language: 'typescript',
  testCases: ['valid email', 'missing @', 'multiple @', 'invalid domain'],
});
```

----------------------------------------

TITLE: Configuring Mastra RAG Agent
DESCRIPTION: This code defines the `ragAgent`, an instance of `Agent`, responsible for generating responses. It sets a descriptive `name`, provides `instructions` to guide its behavior (emphasizing context-based answers), specifies `gpt-4o-mini` as its underlying language `model`, and integrates the previously created `vectorQueryTool` for retrieval capabilities.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank-rag.mdx#_snippet_3

LANGUAGE: typescript
CODE:
```
export const ragAgent = new Agent({
  name: "RAG Agent",
  instructions: `You are a helpful assistant that answers questions based on the provided context. Keep your answers concise and relevant.
    Important: When asked to answer a question, please base your answer only on the context provided in the tool. 
    If the context doesn't contain enough information to fully answer the question, please state that explicitly.`,
  model: openai("gpt-4o-mini"),
  tools: {
    vectorQueryTool,
  },
});
```

----------------------------------------

TITLE: Implementing Real-time Voice Interaction with OpenAIRealtimeVoice - TypeScript
DESCRIPTION: Demonstrates how to use the OpenAIRealtimeVoice class. It covers initializing the class with default or specific options, updating session configurations like VAD, connecting to the service, setting up event listeners for incoming audio and transcribed text, sending text for speech synthesis, streaming audio input for transcription, and disconnecting. Requires `@mastra/voice-openai-realtime` and `@mastra/node-audio`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/openai-realtime.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";
import { playAudio, getMicrophoneStream } from "@mastra/node-audio";

// Initialize with default configuration using environment variables
const voice = new OpenAIRealtimeVoice();

// Or initialize with specific configuration
const voiceWithConfig = new OpenAIRealtimeVoice({
  apiKey: "your-openai-api-key",
  model: "gpt-4o-mini-realtime-preview-2024-12-17",
  speaker: "alloy" // Default voice
});

voiceWithConfig.updateSession({
  turn_detection: {
    type: "server_vad",
    threshold: 0.6,
    silence_duration_ms: 1200
  }
});

// Establish connection
await voice.connect();

// Set up event listeners
voice.on("speaker", ({ audio }) => {
  // Handle audio data (Int16Array) pcm format by default
  playAudio(audio);
});

voice.on("writing", ({ text, role }) => {
  // Handle transcribed text
  console.log(`${role}: ${text}`);
});

// Convert text to speech
await voice.speak("Hello, how can I help you today?", {
  speaker: "echo" // Override default voice
});

// Process audio input
const microphoneStream = getMicrophoneStream();
await voice.send(microphoneStream);

// When done, disconnect
voice.connect();
```

----------------------------------------

TITLE: Configuring Mastra Instance with Inngest API Endpoint (TypeScript)
DESCRIPTION: This snippet configures the Mastra instance, registering 'incrementWorkflow' and setting up an Inngest API route. The 'inngestServe' function integrates Mastra workflows with Inngest, handling function creation, event handling, state persistence, and real-time monitoring via a publish-subscribe system. It requires '@mastra/core/mastra', '@mastra/inngest', and '@mastra/loggers' dependencies.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/inngest-workflow.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
import { Mastra } from '@mastra/core/mastra'
import { serve as inngestServe } from '@mastra/inngest'
import { incrementWorkflow } from './workflows'
import { inngest } from './inngest'
import { PinoLogger } from '@mastra/loggers'


// Configure Mastra with the workflow and Inngest API endpoint
export const mastra = new Mastra({
  workflows: {
    incrementWorkflow
  },
  server: {
    // The server configuration is required to allow local docker container can connect to the mastra server
    host: '0.0.0.0',
    apiRoutes: [
      // This API route is used to register the Mastra workflow (inngest function) on the inngest server
      {
        path: '/api/inngest',
        method: 'ALL',
        createHandler: async ({ mastra }) => inngestServe({ mastra, inngest }),
        // The inngestServe function integrates Mastra workflows with Inngest by:
        // 1. Creating Inngest functions for each workflow with unique IDs (workflow.${workflowId})
        // 2. Setting up event handlers that:
        //    - Generate unique run IDs for each workflow execution
        //    - Create an InngestExecutionEngine to manage step execution
        //    - Handle workflow state persistence and real-time updates
        // 3. Establishing a publish-subscribe system for real-time monitoring
        //    through the workflow:${workflowId}:${runId} channel
      },
    ],
  },
  logger: new PinoLogger({
    name: 'Mastra',
    level: 'info',
  }),
})
```

----------------------------------------

TITLE: Structured Output Streaming with Agent and Thread Context
DESCRIPTION: This example illustrates using `myAgent.stream()` to generate structured output based on a defined JSON schema. It also demonstrates maintaining conversation context via `threadId` and using an `onFinish` callback. The snippet shows how to consume both the `textStream` for real-time updates and await the `object` promise for the final structured result.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/stream.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
const schema = {
  type: "object",
  properties: {
    summary: { type: "string" },
    nextSteps: { type: "array", items: { type: "string" } },
  },
  required: ["summary", "nextSteps"],
};

const response = await myAgent.stream("What should we do next?", {
  output: schema,
  threadId: "project-123",
  onFinish: (text) => console.log("Finished:", text),
});

for await (const chunk of response.textStream) {
  console.log(chunk);
}

const result = await response.object;
console.log("Final structured result:", result);
```

----------------------------------------

TITLE: Defining Weather Agent - TypeScript
DESCRIPTION: This TypeScript code defines a `weatherAgent` using `@mastra/core/agent`. The agent is configured with specific instructions for providing accurate weather information, utilizes the `gpt-4o-mini` model from OpenAI, and integrates the previously defined `weatherTool` to fetch real-time weather data. Its instructions emphasize asking for a location if none is provided and translating non-English location names.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_14

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { weatherTool } from "../tools/weather-tool";

export const weatherAgent = new Agent({
  name: "Weather Agent",
  instructions: `You are a helpful weather assistant that provides accurate weather information.

Your primary function is to help users get weather details for specific locations. When responding:
- Always ask for a location if none is provided
- If the location name isn’t in English, please translate it
- Include relevant details like humidity, wind conditions, and precipitation
- Keep responses concise but informative`,
  model: openai("gpt-4o-mini"),
  tools: { weatherTool },
});
```

----------------------------------------

TITLE: Initialize Mastra Project with Example Code
DESCRIPTION: Create a new Mastra project using npx and include example code in the generated project structure to help get started.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/create-mastra/README.md#_snippet_6

LANGUAGE: bash
CODE:
```
npx create-mastra@latest --example
```

----------------------------------------

TITLE: Building and Running a Content Moderation Workflow with Mastra AI (TypeScript)
DESCRIPTION: This TypeScript snippet defines a content moderation workflow using Mastra AI, chaining steps for content analysis, moderation, and application of moderation rules. It includes a comprehensive demo function (`runModerationDemo`) that illustrates how to start a workflow, handle suspended steps for human review, collect moderator input using Inquirer.js, and resume the workflow with the collected data. It also shows how to retrieve final workflow results.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/human-in-the-loop.mdx#_snippet_2

LANGUAGE: TypeScript
CODE:
```
// Build the workflow
const contentModerationWorkflow = new Workflow({
  name: "content-moderation-workflow",
  triggerSchema: z.object({
    content: z.string(),
  }),
});

contentModerationWorkflow
  .step(analyzeContent)
  .then(moderateContent)
  .then(applyModeration)
  .commit();

// Register the workflow
const mastra = new Mastra({
  workflows: { contentModerationWorkflow },
});

// Example of using the workflow with Inquirer prompts
async function runModerationDemo() {
  const registeredWorkflow = mastra.getWorkflow("contentModerationWorkflow");
  const run = registeredWorkflow.createRun();

  // Start the workflow with content that needs review
  console.log("コンテンツモデレーションワークフローを開始します...");
  const result = await run.start({
    triggerData: {
      content: "これはモデレーションが必要なユーザー生成コンテンツです。",
    },
  });

  const isReviewStepSuspended =
    result.activePaths.get("moderateContent")?.status === "suspended";

  // Check if workflow is suspended
  if (isReviewStepSuspended) {
    const { content, aiScore, flaggedCategories, message } =
      result.activePaths.get("moderateContent")?.suspendPayload;

    console.log("\n===================================");
    console.log(message);
    console.log("===================================\n");

    console.log("レビュー対象のコンテンツ:");
    console.log(content);
    console.log(`\nAI分析スコア: ${aiScore}`);
    console.log(
      `フラグ付けされたカテゴリ: ${flaggedCategories?.join(", ") || "なし"}\n`,
    );

    // Collect moderator decision using Inquirer
    const moderatorDecision = await select({
      message: "モデレーションの判断を選択してください:",
      choices: [
        { name: "このままコンテンツを承認する", value: "approve" },
        { name: "コンテンツを完全に却下する", value: "reject" },
        { name: "公開前にコンテンツを修正する", value: "modify" },
      ],
    });

    // Collect additional information based on decision
    let moderatorNotes = "";
    let modifiedContent = "";

    moderatorNotes = await input({
      message: "判断に関するメモを入力してください:",
    });

    if (moderatorDecision === "modify") {
      modifiedContent = await input({
        message: "修正後のコンテンツを入力してください:",
        default: content,
      });
    }

    console.log("\nモデレーションの判断を送信しています...");

    // Resume the workflow with the moderator's input
    const resumeResult = await run.resume({
      stepId: "moderateContent",
      context: {
        moderatorDecision,
        moderatorNotes,
        modifiedContent,
      },
    });

    if (resumeResult?.results?.applyModeration?.status === "success") {
      console.log("\n===================================");
      console.log(
        `モデレーション完了: ${resumeResult?.results?.applyModeration?.output.finalStatus}`,
      );
      console.log("===================================\n");

      if (resumeResult?.results?.applyModeration?.output.content) {
        console.log("公開されたコンテンツ:");
        console.log(resumeResult.results.applyModeration.output.content);
      }
    }

    return resumeResult;
  }

  console.log(
    "人による介入なしでワークフローが完了しました:",
    result.results,
  );
  return result;
}

// Helper function for AI content analysis simulation
function simulateContentAnalysis(content: string): number {
  // In a real application, this would call an AI service
  // For the example, we're returning a random score
  return Math.random();
}

// Invoke the demo function
runModerationDemo().catch(console.error);
```

----------------------------------------

TITLE: Reusing and Nesting Workflows and Steps in Mastra AI (TypeScript)
DESCRIPTION: This example illustrates advanced workflow composition, showing how to import necessary utilities and define a parent workflow that incorporates both existing workflows (nested workflows) and cloned instances of workflows and steps. This allows for complex, modular workflow designs where components can be reused and adapted.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#_snippet_5

LANGUAGE: typescript
CODE:
```
import {
  createWorkflow,
  createStep,
  cloneStep,
  cloneWorkflow,
} from "@mastra/core/workflows";

const myWorkflow = createWorkflow({
  id: "my-workflow",
  steps: [step1, step2, step3],
});
myWorkflow.then(step1).then(step2).then(step3).commit();

const parentWorkflow = createWorkflow({
  id: "parent-workflow",
  steps: [myWorkflow, step4],
});
parentWorkflow
  .then(myWorkflow) // nested workflow
  .then(step4)
  .then(cloneWorkflow(myWorkflow, { id: "cloned-workflow" })) // cloned workflow
  .then(cloneStep(step4, { id: "cloned-step-4" })) // cloned step
  .commit();
```

----------------------------------------

TITLE: Setting OpenAI API Key (Environment Variable)
DESCRIPTION: This snippet shows the format for setting the `OPENAI_API_KEY` in the `.env` file. Users need to replace `sk-your-api-key-here` with their actual OpenAI API key to authenticate requests to the OpenAI API.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-chunk/README.md#_snippet_2

LANGUAGE: env
CODE:
```
OPENAI_API_KEY=sk-your-api-key-here
```

----------------------------------------

TITLE: Configuring OpenAI API Key (Environment Variable)
DESCRIPTION: This line represents the configuration of the OpenAI API key within the `.env` file. Replace `sk-your-api-key-here` with your actual OpenAI API key to allow the application to authenticate with the OpenAI services.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/system-prompt/README.md#_snippet_2

LANGUAGE: env
CODE:
```
OPENAI_API_KEY=sk-your-api-key-here
```

----------------------------------------

TITLE: Set Up OpenAI API Key | .env
DESCRIPTION: Creates or updates the `.env` file at the project root to store the OpenAI API key required by the `@ai-sdk/openai` package. Replace `your_openai_api_key` with your actual key.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/stock-agent.mdx#_snippet_2

LANGUAGE: Bash
CODE:
```
OPENAI_API_KEY=your_openai_api_key
```

----------------------------------------

TITLE: Setting OpenAI API Key in Environment File (Env)
DESCRIPTION: This snippet shows how to set the `OPENAI_API_KEY` in the `.env` file. Replace `sk-your-api-key-here` with your actual OpenAI API key to authenticate API requests for the LLM evaluations.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/toxicity/README.md#_snippet_2

LANGUAGE: env
CODE:
```
OPENAI_API_KEY=sk-your-api-key-here
```

----------------------------------------

TITLE: Setting OpenAI API Key in Environment File (Env)
DESCRIPTION: This line demonstrates how to set the `OPENAI_API_KEY` within the `.env` file. Users must replace `sk-your-api-key-here` with their actual OpenAI API key to authenticate requests to the OpenAI API.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-chunk-array/README.md#_snippet_2

LANGUAGE: env
CODE:
```
OPENAI_API_KEY=sk-your-api-key-here
```

----------------------------------------

TITLE: Environment Setup | Bash
DESCRIPTION: Sets up the necessary environment variable for the OpenAI API key in a .env file.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/answer-relevancy.mdx#_snippet_0

LANGUAGE: bash
CODE:
```
OPENAI_API_KEY=your_api_key_here
```

----------------------------------------

TITLE: Defining Travel Agents for Summary and Detailed Planning (TypeScript)
DESCRIPTION: This TypeScript file defines two Mastra `Agent` instances: `summaryTravelAgent` and `travelAgent`. `summaryTravelAgent` generates three distinct holiday options as a JSON array, while `travelAgent` creates a detailed travel plan based on a selected option. Both agents use the `gpt-4o` model from `@ai-sdk/openai` and are configured with specific instructions for their respective tasks.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows_vNext/human-in-the-loop.mdx#_snippet_1

LANGUAGE: ts
CODE:
```
import { Agent } from '@mastra/core/agent'
import { openai } from '@ai-sdk/openai'
 
const llm = openai('gpt-4o')
 
// Agent that generates multiple holiday options
// Returns a JSON array of locations and descriptions
export const summaryTravelAgent = new Agent({
  name: "summaryTravelAgent",
  model: llm,
  instructions: `
  You are a travel agent who is given a user prompt about what kind of holiday they want to go on.
  You then generate 3 different options for the holiday. Return the suggestions as a JSON array {"location": "string", "description": "string"}[]. Don't format as markdown.
  Make the options as different as possible from each other.
  Also make the plan very short and summarized.
  `,
})

// Agent that creates detailed travel plans
// Takes the selected option and generates a comprehensive itinerary
export const travelAgent = new Agent({
  name: "travelAgent",
  model: llm,
  instructions: `
  You are a travel agent who is given a user prompt about what kind of holiday they want to go on. A summary of the plan is provided as well as the location.
  You then generate a detailed travel plan for the holiday.
  `,
});
```

----------------------------------------

TITLE: Upserting Embeddings into Pinecone (TypeScript)
DESCRIPTION: This snippet illustrates how to use the `PineconeVector` class to create indexes and insert embeddings into Pinecone, a managed vector database service. It processes text content into chunks, generates embeddings using OpenAI, and then upserts these embeddings with associated metadata into a Pinecone index. An API key for Pinecone is required for authentication.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/upsert/upsert-embeddings.mdx#_snippet_1

LANGUAGE: tsx
CODE:
```
import { openai } from '@ai-sdk/openai';
import { PineconeVector } from '@mastra/pinecone';
import { MDocument } from '@mastra/rag';
import { embedMany } from 'ai';

const doc = MDocument.fromText('Your text content...');

const chunks = await doc.chunk();

const { embeddings } = await embedMany({
  values: chunks.map(chunk => chunk.text),
  model: openai.embedding('text-embedding-3-small'),
});

const pinecone = new PineconeVector({
  apiKey: process.env.PINECONE_API_KEY!,
});

await pinecone.createIndex({
  indexName: 'testindex',
  dimension: 1536,
});

await pinecone.upsert({
  indexName: 'testindex',
  vectors: embeddings,
  metadata: chunks?.map(chunk => ({ text: chunk.text })),
});
```

----------------------------------------

TITLE: Defining Human-in-the-Loop Travel Workflow (TypeScript)
DESCRIPTION: This TypeScript file defines a Mastra workflow (`travelAgentWorkflow`) that incorporates human intervention. It consists of three steps: `generateSuggestionsStep` (generates holiday options), `humanInputStep` (pauses for user selection), and `travelPlannerStep` (creates a detailed plan). The `humanInputStep` utilizes Mastra's suspend/resume mechanism to allow for external user interaction before the workflow continues.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows_vNext/human-in-the-loop.mdx#_snippet_2

LANGUAGE: ts
CODE:
```
import { createWorkflow, createStep } from '@mastra/core/workflows/vNext'
import { z } from 'zod'
 
// Step that generates multiple holiday options based on user's vacation description
// Uses the summaryTravelAgent to create diverse travel suggestions
const generateSuggestionsStep = createStep({
  id: "generate-suggestions",
  inputSchema: z.object({
    vacationDescription: z.string().describe("The description of the vacation")
  }),
  outputSchema: z.object({
    suggestions: z.array(z.string()),
    vacationDescription: z.string()
  }),
  execute: async ({ inputData, mastra }) => {
    if (!mastra) {
      throw new Error("Mastra is not initialized");
    }
 
    const { vacationDescription } = inputData
    const result = await mastra.getAgent('summaryTravelAgent').generate([
      {
        role: "user",
        content: vacationDescription
      }
    ]);
    console.log(result.text);
    return { suggestions: JSON.parse(result.text), vacationDescription };
  }
})
 
// Step that pauses the workflow to get user input
// Allows the user to select their preferred holiday option from the suggestions
// Uses suspend/resume mechanism to handle the interaction
const humanInputStep = createStep({
  id: "human-input",
  inputSchema: z.object({
    suggestions: z.array(z.string()),
    vacationDescription: z.string()
  }),
  outputSchema: z.object({
    selection: z.string().describe("The selection of the user"),
    vacationDescription: z.string()
  }),
  resumeSchema: z.object({
    selection: z.string().describe("The selection of the user")
  }),
  suspendSchema: z.object({
    suggestions: z.array(z.string())
  }),
  execute: async ({ inputData, resumeData, suspend, getInitData }) => {
    if (!resumeData?.selection) {
      await suspend({ suggestions: inputData?.suggestions });
      return {
        selection: "",
        vacationDescription: inputData?.vacationDescription
      };
    }
 
    return {
      selection: resumeData?.selection,
      vacationDescription: inputData?.vacationDescription
    };
  }
})
 
// Step that creates a detailed travel plan based on the user's selection
// Uses the travelAgent to generate comprehensive holiday details
const travelPlannerStep = createStep({
  id: "travel-planner",
  inputSchema: z.object({
    selection: z.string().describe("The selection of the user"),
    vacationDescription: z.string()
  }),
  outputSchema: z.object({
    travelPlan: z.string()
  }),
  execute: async ({ inputData, mastra }) => {
    const travelAgent = mastra?.getAgent("travelAgent");
    if (!travelAgent) {
      throw new Error("Travel agent is not initialized");
    }
 
    const { selection, vacationDescription } = inputData
    const result = await travelAgent.generate([
      { role: "assistant", content: vacationDescription },
      { role: "user", content: selection || "" }
    ]);
    console.log(result.text);
    return { travelPlan: result.text };
  }
})
 
// Main workflow that orchestrates the holiday planning process:
// 1. Generates multiple options
// 2. Gets user input
// 3. Creates detailed plan
const travelAgentWorkflow = createWorkflow({
  id: "travel-agent-workflow",
  inputSchema: z.object({
    vacationDescription: z.string().describe("The description of the vacation")
  }),
  outputSchema: z.object({
    travelPlan: z.string()
  })
})
  .then(generateSuggestionsStep)
  .then(humanInputStep)
  .then(travelPlannerStep)
 
travelAgentWorkflow.commit()
 
export { travelAgentWorkflow, humanInputStep }
```

----------------------------------------

TITLE: Creating a Weather Tool using createTool in TypeScript
DESCRIPTION: This snippet demonstrates how to define a custom tool in Mastra using the `createTool` function. It shows the structure for defining input and output schemas using Zod and implementing the tool's core logic within the `execute` function. This tool fetches mock weather information for a given city.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/tools-mcp/overview.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { createTool } from "@mastra/core/tools";
import { z } from "zod";

const getWeatherInfo = async (city: string) => {
  // Replace with an actual API call to a weather service
  console.log(`Fetching weather for ${city}...`);
  // Example data structure
  return { temperature: 20, conditions: "Sunny" };
};

export const weatherTool = createTool({
  id: "Get Weather Information",
  description: `Fetches the current weather information for a given city`,
  inputSchema: z.object({
    city: z.string().describe("City name")
  }),
  outputSchema: z.object({
    temperature: z.number(),
    conditions: z.string()
  }),
  execute: async ({ context: { city } }) => {
    console.log("Using tool to fetch weather information for", city);
    return await getWeatherInfo(city);
  }
});
```

----------------------------------------

TITLE: Implementing Error Handling with Mastra Client in TypeScript
DESCRIPTION: This example demonstrates best practices for error handling when using the Mastra Client. It wraps the agent interaction in a `try-catch` block to gracefully manage potential errors during response generation and logs both successful responses and errors to the console.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/client.mdx#_snippet_6

LANGUAGE: typescript
CODE:
```
// Example with error handling and logging
try {
  const agent = client.getAgent("dev-agent-id");
  const response = await agent.generate({
    messages: [{ role: "user", content: "Test message" }]
  });
  console.log("Response:", response);
} catch (error) {
  console.error("Development error:", error);
}
```

----------------------------------------

TITLE: Executing Parallel Steps in Mastra Workflow (TypeScript)
DESCRIPTION: This snippet demonstrates how to execute multiple independent steps concurrently within a Mastra workflow. It improves processing speed by allowing 'fetchUserData' and 'fetchOrderData' to run in parallel, as they do not depend on each other's output.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
myWorkflow.step(fetchUserData).step(fetchOrderData);
```

----------------------------------------

TITLE: Running and Managing Workflow Execution Results (TypeScript)
DESCRIPTION: Provides a comprehensive example of creating, starting, and handling the results of a workflow run. It demonstrates how to access step outputs, the final workflow result, and how to resume a suspended workflow or handle failures.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_20

LANGUAGE: typescript
CODE:
```
const run = myWorkflow.createRun();

const result = await run.start({
  inputData: {
    startValue: 'initial data',
  },
});

console.log(result.steps); // All step results
console.log(result.steps['step-id'].output); // Output from a specific step

if (result.status === 'success') {
  console.log(result.result); // The final result of the workflow, result of the last step (or `.map()` output, if used as last step)
} else if (result.status === 'suspended') {
  const resumeResult = await run.resume({
    step: result.suspended[0], // there is always at least one step id in the suspended array, in this case we resume the first suspended execution path
    resumeData: {
      /* user input */
    },
  });
} else if (result.status === 'failed') {
  console.error(result.error); // only exists if status is failed, this is an instance of Error
}
```

----------------------------------------

TITLE: Using Speech-to-Speech with Mastra Agent (TypeScript)
DESCRIPTION: This example demonstrates how to integrate the OpenAIRealtimeVoice provider with a Mastra Agent. It covers connecting the voice service, listening for and playing agent audio responses, initiating a conversation with the agent's voice, and sending continuous audio input from the microphone to the agent.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/speech-to-speech.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";
import { playAudio, getMicrophoneStream } from "@mastra/node-audio";

const agent = new Agent({
  name: "Agent",
  instructions: `You are a helpful assistant with real-time voice capabilities.`,
  model: openai("gpt-4o"),
  voice: new OpenAIRealtimeVoice(),
});

// Connect to the voice service
await agent.voice.connect();

// Listen for agent audio responses
agent.voice.on("speaker", ({ audio }) => {
  playAudio(audio);
});

// Initiate the conversation
await agent.voice.speak("How can I help you today?");

// Send continuous audio from the microphone
const micStream = getMicrophoneStream();
await agent.voice.send(micStream);
```

----------------------------------------

TITLE: Defining Weather Tool in TypeScript
DESCRIPTION: This TypeScript code defines `weatherTool` using `@mastra/core/tools` and `zod` for schema validation. It fetches detailed weather information for a given location by integrating with external geocoding and weather APIs. The tool's `execute` method calls a helper function `getWeather` which handles API calls and data processing, including converting weather codes to human-readable descriptions.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/agent-and-tool-interop.mdx#_snippet_2

LANGUAGE: ts
CODE:
```
import { createTool } from '@mastra/core/tools'
import { z } from 'zod'

interface GeocodingResponse {
  results: {
    latitude: number
    longitude: number
    name: string
  }[]
}
interface WeatherResponse {
  current: {
    time: string
    temperature_2m: number
    apparent_temperature: number
    relative_humidity_2m: number
    wind_speed_10m: number
    wind_gusts_10m: number
    weather_code: number
  }
}

// Create a tool to fetch weather data
export const weatherTool = createTool({
  id: 'get-weather',
  description: 'Get current weather for a location',
  inputSchema: z.object({
    location: z.string().describe('City name'),
  }),
  outputSchema: z.object({
    temperature: z.number(),
    feelsLike: z.number(),
    humidity: z.number(),
    windSpeed: z.number(),
    windGust: z.number(),
    conditions: z.string(),
    location: z.string(),
  }),
  execute: async ({ context }) => {
    return await getWeather(context.location)
  }
})

// Helper function to fetch weather data from external APIs
const getWeather = async (location: string) => {
  const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(location)}&count=1`
  const geocodingResponse = await fetch(geocodingUrl)
  const geocodingData = (await geocodingResponse.json()) as GeocodingResponse

  if (!geocodingData.results?.[0]) {
    throw new Error(`Location '${location}' not found`)
  }

  const { latitude, longitude, name } = geocodingData.results[0]

  const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,apparent_temperature,relative_humidity_2m,wind_speed_10m,wind_gusts_10m,weather_code`

  const response = await fetch(weatherUrl)
  const data = (await response.json()) as WeatherResponse

  return {
    temperature: data.current.temperature_2m,
    feelsLike: data.current.apparent_temperature,
    humidity: data.current.relative_humidity_2m,
    windSpeed: data.current.wind_speed_10m,
    windGust: data.current.wind_gusts_10m,
    conditions: getWeatherCondition(data.current.weather_code),
    location: name
  }
}

// Helper function to convert numeric weather codes to human-readable descriptions
function getWeatherCondition(code: number): string {
  const conditions: Record<number, string> = {
    0: 'Clear sky',
    1: 'Mainly clear',
    2: 'Partly cloudy',
    3: 'Overcast',
    45: 'Foggy',
    48: 'Depositing rime fog',
    51: 'Light drizzle',
    53: 'Moderate drizzle',
    55: 'Dense drizzle',
    56: 'Light freezing drizzle',
    57: 'Dense freezing drizzle',
    61: 'Slight rain',
    63: 'Moderate rain',
    65: 'Heavy rain',
    66: 'Light freezing rain',
    67: 'Heavy freezing rain',
    71: 'Slight snow fall',
    73: 'Moderate snow fall',
    75: 'Heavy snow fall',
    77: 'Snow grains',
    80: 'Slight rain showers',
    81: 'Moderate rain showers',
    82: 'Violent rain showers',
    85: 'Slight snow showers',
    86: 'Heavy snow showers',
    95: 'Thunderstorm',
    96: 'Thunderstorm with slight hail',
    99: 'Thunderstorm with heavy hail'
  }
  return conditions[code] || 'Unknown'
}
```

----------------------------------------

TITLE: Initializing Mastra Class in TypeScript
DESCRIPTION: This snippet provides examples of initializing the `Mastra` class. It shows both a basic initialization with an empty configuration and a full initialization demonstrating how to configure various components like agents, workflows, logger, storage, tools, vectors, and MCP servers.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/core/mastra-class.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
import { Mastra } from "@mastra/core";
import { PinoLogger } from "@mastra/loggers";

// Basic initialization
export const mastra = new Mastra({});

// Full initialization with all options
export const mastra = new Mastra({
  agents: {},
  workflows: [],
  integrations: [],
  logger: new PinoLogger({
    name: "My Project",
    level: "info",
  }),
  storage: {},
  tools: {},
  vectors: {},
  mcpServers: {},
});
```

----------------------------------------

TITLE: Generating Structured Output with JSON Schema in Mastra
DESCRIPTION: This code illustrates how to configure a Mastra agent to return structured data by providing a JSON Schema to the `output` option of the `.generate()` method. The agent's response is then accessed as a typed object, ensuring the output adheres to the defined schema.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_6

LANGUAGE: typescript
CODE:
```
const schema = {
  type: "object",
  properties: {
    summary: { type: "string" },
    keywords: { type: "array", items: { type: "string" } },
  },
  additionalProperties: false,
  required: ["summary", "keywords"],
};

const response = await myAgent.generate(
  [
    {
      role: "user",
      content:
        "Please provide a summary and keywords for the following text: ...",
    },
  ],
  {
    output: schema,
  },
);

console.log("Structured Output:", response.object);
```

----------------------------------------

TITLE: Implementing Branching and Merging Paths in Mastra Workflow (TypeScript)
DESCRIPTION: This snippet shows how to create divergent paths after 'stepA' and then converge them later. 'stepA' triggers both 'stepB' (leading to 'stepD') and 'stepC' (leading to 'stepE'), with 'stepF' executing only after both 'stepD' and 'stepE' have completed, demonstrating complex control flow.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_2

LANGUAGE: TypeScript
CODE:
```
myWorkflow
  .step(stepA)
  .then(stepB)
  .then(stepD)
  .after(stepA)
  .step(stepC)
  .then(stepE)
  .after([stepD, stepE])
  .step(stepF);
```

----------------------------------------

TITLE: Creating a New Mastra Project Interactively (CLI)
DESCRIPTION: This section provides commands for interactively creating a new Mastra project using the `create-mastra@latest` CLI. It supports various package managers (npx, npm, yarn, pnpm, bun) and guides the user through the setup process, including dependency installation and component configuration.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_0

LANGUAGE: bash
CODE:
```
npx create-mastra@latest
```

LANGUAGE: bash
CODE:
```
npm create mastra@latest
```

LANGUAGE: bash
CODE:
```
yarn create mastra@latest
```

LANGUAGE: bash
CODE:
```
pnpm create mastra@latest
```

LANGUAGE: bash
CODE:
```
bun create mastra@latest
```

----------------------------------------

TITLE: Generating and Storing Embeddings in PGVector
DESCRIPTION: This code generates vector embeddings for the processed text chunks using OpenAI's `text-embedding-3-small` model. It then retrieves the `pgVector` store from Mastra, creates an index with a specified dimension if it doesn't exist, and finally upserts the generated embeddings along with their original text metadata into the vector store.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#_snippet_13

LANGUAGE: typescript
CODE:
```
const { embeddings } = await embedMany({
  model: openai.embedding("text-embedding-3-small"),
  values: chunks.map((chunk) => chunk.text),
});

const vectorStore = mastra.getVector("pgVector");
await vectorStore.createIndex({
  indexName: "embeddings",
  dimension: 1536,
});
await vectorStore.upsert({
  indexName: "embeddings",
  vectors: embeddings,
  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),
});
```

----------------------------------------

TITLE: Using TurbopufferVector for Vector Operations - TypeScript
DESCRIPTION: This comprehensive example demonstrates how to initialize `TurbopufferVector`, create an index, add vectors with metadata, and query vectors. It covers the essential operations for managing vector data within a Turbopuffer store, including filtering and specifying query parameters.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/turbopuffer/README.md#_snippet_1

LANGUAGE: typescript
CODE:
```
import { TurbopufferVector } from '@mastra/turbopuffer';

const vectorStore = new TurbopufferVector({
  apiKey: 'your-api-key',
  baseUrl: 'https://gcp-us-central1.turbopuffer.com',
});

// Create a new index
await vectorStore.createIndex({ indexName: 'my-index', dimension: 1536, metric: 'cosine' });

// Add vectors
const vectors = [[0.1, 0.2, ...], [0.3, 0.4, ...]];
const metadata = [{ text: 'doc1' }, { text: 'doc2' }];
const ids = await vectorStore.upsert({ indexName: 'my-index', vectors, metadata });

// Query vectors
const results = await vectorStore.query({
  indexName: 'my-index',
  queryVector: [0.1, 0.2, ...],
  topK: 10,
  filter: { text: { $eq: 'doc1' } },
  includeVector: false,
});
```

----------------------------------------

TITLE: Using OpenSearchVector for Vector Operations
DESCRIPTION: Demonstrates how to initialize the OpenSearchVector client, create an index, upsert vectors with metadata, and query for similar vectors with filtering.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/opensearch/README.md#_snippet_1

LANGUAGE: typescript
CODE:
```
import { OpenSearchVector } from '@mastra/opensearch';

const vectorStore = new OpenSearchVector('http://localhost:9200');

// Create an index
await vectorStore.createIndex({ indexName: 'my-collection', dimension: 1536, metric: 'cosine' });

// Add vectors with documents
const vectors = [[0.1, 0.2, ...], [0.3, 0.4, ...]];
const metadata = [{ text: 'doc1' }, { text: 'doc2' }];
const ids = await vectorStore.upsert({ indexName: 'my-collection', vectors, metadata });

// Query vectors with document filtering
const results = await vectorStore.query({
  indexName: 'my-collection',
  queryVector: [0.1, 0.2, ...],
  topK: 10, // topK
  filter: { text: { $eq: 'doc1' } }, // metadata filter
  includeVector: false, // includeVector
});
```

----------------------------------------

TITLE: Configuring Mastra with LibSQL Storage (TypeScript)
DESCRIPTION: This snippet demonstrates how to configure the Mastra instance to use `LibSQLStore` for persistent data storage. It imports `Mastra` and `LibSQLStore`, then initializes `Mastra` by passing a new `LibSQLStore` instance to the `storage` option, specifying a local file path (`file:./mastra.db`) for the database URL. This setup ensures data persistence across application restarts, unlike the default behavior which does not persist data.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/storage/overview.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { Mastra } from "@mastra/core/mastra";
import { LibSQLStore } from "@mastra/libsql";

const mastra = new Mastra({
  storage: new LibSQLStore({
    url: "file:./mastra.db"
  })
});
```

----------------------------------------

TITLE: Defining Readme Generator Workflow in TypeScript
DESCRIPTION: This is the main workflow definition, orchestrating the entire README generation process. It defines the sequence of steps: cloning the repository, selecting folders, generating summaries for each file (using `foreach` with `generateSummaryWorkflow`), and finally collating all documentation. It uses `createWorkflow` from `@mastra/core/workflows` and `zod` for overall input/output schema validation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/array-as-input.mdx#_snippet_6

LANGUAGE: TypeScript
CODE:
```
const readmeGeneratorWorkflow = createWorkflow({
  id: "readme-generator",
  inputSchema: z.object({
    repoUrl: z.string(),
  }),
  outputSchema: z.object({
    success: z.boolean(),
    message: z.string(),
    data: z.object({
      repoUrl: z.string(),
    }),
  }),
  steps: [cloneRepositoryStep, selectFolderStep, generateSummaryWorkflow, collateDocumentationStep],
})
  .then(cloneRepositoryStep)
  .then(selectFolderStep)
  .foreach(generateSummaryWorkflow)
  .then(collateDocumentationStep)
  .commit();

export { readmeGeneratorWorkflow };
```

----------------------------------------

TITLE: Example: Get Dynamic Instructions with RuntimeContext (TypeScript)
DESCRIPTION: Illustrates how to configure an agent with instructions defined by a function that accepts and uses a `runtimeContext`. It shows creating a `RuntimeContext`, setting values, and passing it to `getInstructions()` to obtain context-dependent instructions.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/getInstructions.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { RuntimeContext } from "@mastra/core/runtime-context";
import { openai } from "@ai-sdk/openai";

// Create an agent with dynamic instructions
const agent = new Agent({
  name: "contextual-assistant",
  instructions: ({ runtimeContext }) => {
    // Dynamic instructions based on runtime context
    const userPreference = runtimeContext.get("userPreference");
    const expertise = runtimeContext.get("expertise") || "general";

    if (userPreference === "technical") {
      return `You are a technical assistant specializing in ${expertise}. Provide detailed technical explanations.`;
    }

    return `You are a helpful assistant providing easy-to-understand information about ${expertise}.`;
  },
  model: openai("gpt-4o")
});

// Create a runtime context with user preferences
const context = new RuntimeContext();
context.set("userPreference", "technical");
context.set("expertise", "machine learning");

// Get the instructions using the runtime context
const instructions = await agent.getInstructions({ runtimeContext: context });
console.log(instructions); // "You are a technical assistant specializing in machine learning. Provide detailed technical explanations."
```

----------------------------------------

TITLE: Creating Mastra Agent Stream API Route - TypeScript
DESCRIPTION: This Next.js API route (`/api/use-object`) handles POST requests. It retrieves an agent named "weatherAgent" using the `mastra` library, streams a response from the agent based on the request body, and enforces a Zod schema for the output. The agent's stream is then converted into a text stream response suitable for client-side consumption.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/ai-sdk.mdx#_snippet_5

LANGUAGE: typescript
CODE:
```
import { mastra } from "@/src/mastra";

export async function POST(req: Request) {
  const body = await req.json();
  const myAgent = mastra.getAgent("weatherAgent");
  const stream = await myAgent.stream(body, {
    output: z.object({
      weather: z.string(),
    }),
  });

  return stream.toTextStreamResponse();
}
```

----------------------------------------

TITLE: Defining a Workflow Step with `createStep` in Mastra (TypeScript)
DESCRIPTION: This snippet demonstrates how to define a workflow step using `createStep` in Mastra. It configures input, output, resume, and suspend schemas using Zod, and implements the `execute` function to process `inputData`, access `initData`, and interact with the `runtimeContext` to produce an output value. It shows how to define a step's behavior and its data contracts.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/execute.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
const inputSchema = z.object({
  inputValue: z.string(),
});

const myStep = createStep({
  id: "my-step",
  description: "Does something useful",
  inputSchema,
  outputSchema: z.object({
    outputValue: z.string(),
  }),
  resumeSchema: z.object({
    resumeValue: z.string(),
  }),
  suspendSchema: z.object({
    suspendValue: z.string(),
  }),
  execute: async ({
    inputData,
    mastra,
    getStepResult,
    getInitData,
    runtimeContext,
  }) => {
    const otherStepOutput = getStepResult(step2);
    const initData = getInitData<typeof inputSchema>(); // typed as the input schema variable (zod schema)
    return {
      outputValue: `Processed: ${inputData.inputValue}, ${initData.startValue} (runtimeContextValue: ${runtimeContext.get("runtimeContextValue")})`,
    };
  },
});
```

----------------------------------------

TITLE: Generating Embeddings with OpenAI | AI SDK | TypeScript
DESCRIPTION: Uses the `embedMany` function from `ai` with the OpenAI `text-embedding-3-small` model to create embeddings for an array of text values (from chunks). Requires `@ai-sdk/openai` and `ai` packages.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/chunking-and-embedding.mdx#_snippet_2

LANGUAGE: TypeScript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { embedMany } from "ai";

const { embeddings } = await embedMany({
  model: openai.embedding("text-embedding-3-small"),
  values: chunks.map((chunk) => chunk.text),
});
```

----------------------------------------

TITLE: Implementing a Multi-Agent AI Workflow in TypeScript
DESCRIPTION: This comprehensive example demonstrates a complete AI workflow involving a copywriter and an editor agent. It shows how to define agents, create sequential steps, and execute a workflow with a specific trigger schema, illustrating an end-to-end process for generating and refining content.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/separate-long-code-block.md#_snippet_0

LANGUAGE: typescript
CODE:
```
import { anthropic } from "@ai-sdk/anthropic";
import { openai } from "@ai-sdk/openai";

const copywriterAgent = new Agent({
  name: "Copywriter",
  instructions: "You are a copywriter agent that writes blog post copy.",
  model: anthropic("claude-3-5-sonnet-20241022"),
});

const copywriterStep = new Step({
  id: "copywriterStep",
  execute: async ({ context }) => {
    if (!context?.triggerData?.topic) {
      throw new Error("Topic not found in trigger data");
    }
    const result = await copywriterAgent.generate(
      `Create a blog post about ${context.triggerData.topic}`,
    );
    console.log("copywriter result", result.text);
    return {
      copy: result.text,
    };
  },
});

const editorAgent = new Agent({
  name: "Editor",
  instructions: "You are an editor agent that edits blog post copy.",
  model: openai("gpt-4o-mini"),
});

const editorStep = new Step({
  id: "editorStep",
  execute: async ({ context }) => {
    const copy = context?.getStepResult<{ copy: number }>(
      "copywriterStep",
    )?.copy;

    const result = await editorAgent.generate(
      `Edit the following blog post only returning the edited copy: ${copy}`,
    );
    console.log("editor result", result.text);
    return {
      copy: result.text,
    };
  },
});

const myWorkflow = new Workflow({
  name: "my-workflow",
  triggerSchema: z.object({
    topic: z.string(),
  }),
});

// Run steps sequentially.
myWorkflow.step(copywriterStep).then(editorStep).commit();

const { runId, start } = myWorkflow.createRun();

const res = await start({
  triggerData: { topic: "React JavaScript frameworks" },
});
console.log("Results: ", res.results);
```

----------------------------------------

TITLE: Registering Mastra Agents and Workflows in TypeScript
DESCRIPTION: This code initializes the `Mastra` instance, registering the `activityPlanningWorkflow` and various AI agents (`planningAgent`, `synthesizeAgent`). This registration is crucial for making these components accessible and executable within the Mastra framework, enabling complex workflow orchestration.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows_vNext/parallel-steps.mdx#_snippet_1

LANGUAGE: TypeScript
CODE:
```
import { Mastra } from '@mastra/core/mastra'
import { PinoLogger } from "@mastra/loggers";
import { activityPlanningWorkflow } from './workflows/parallel-workflow'
import { planningAgent } from './agents/planning-agent'
import { synthesizeAgent } from './agents/synthesize-agent'

// Initialize Mastra with required agents and workflows
// This setup enables agent access within the workflow steps
const mastra = new Mastra({
  vnext_workflows: {
    activityPlanningWorkflow,
  },
  agents: {
    planningAgent,
    synthesizeAgent,
  },
  logger: new PinoLogger({
    name: "Mastra",
    level: "info",
  }),
})
 
export { mastra }
```

----------------------------------------

TITLE: Mastra Class Constructor Signature in TypeScript
DESCRIPTION: This snippet shows the constructor signature for the `Mastra` class, which accepts an optional `Config` object to customize its behavior and integrate various Mastra components.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/core/mastra-class.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
constructor(config?: Config);
```

----------------------------------------

TITLE: Managing Vector Store with MongoDBVector (TypeScript)
DESCRIPTION: This comprehensive snippet illustrates the full lifecycle of using `MongoDBVector` for Atlas Search. It covers connecting to MongoDB, creating a vector index, upserting vectors with associated metadata, querying for similar vectors with filtering, and disconnecting from the database. Prerequisites include a running MongoDB Atlas instance with Atlas Search enabled.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/mongodb/README.md#_snippet_1

LANGUAGE: typescript
CODE:
```
import { MongoDBVector } from '@mastra/mongodb';

const vectorDB = new MongoDBVector({
  uri: 'mongodb://mongodb:mongodb@localhost:27018/?authSource=admin&directConnection=true',
  dbName: 'vector_db',
});

// Connect to MongoDB
await vectorDB.connect();

// Create a new vector index (collection)
await vectorDB.createIndex({
  indexName: 'my_vectors',
  dimension: 1536,
  metric: 'cosine', // or 'euclidean', 'dotproduct'
});

// Upsert vectors
const ids = await vectorDB.upsert({
  indexName: 'my_vectors',
  vectors: [[0.1, 0.2, ...], [0.3, 0.4, ...]],
  metadata: [{ text: 'doc1' }, { text: 'doc2' }],
});

// Query vectors
const results = await vectorDB.query({
  indexName: 'my_vectors',
  queryVector: [0.1, 0.2, ...],
  topK: 10,
  filter: { text: 'doc1' },
  includeVector: false,
  minScore: 0.5,
});

// Clean up
await vectorDB.disconnect();
```

----------------------------------------

TITLE: Initializing Mastra Project with npm - Bash
DESCRIPTION: This command sequence initializes a new Node.js project using npm, installs essential development dependencies like TypeScript and tsx, and then adds core Mastra packages along with zod and @ai-sdk/openai for AI functionalities. This sets up the project structure and required libraries.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_4

LANGUAGE: bash
CODE:
```
npm init -y

npm install typescript tsx @types/node mastra@latest --save-dev

npm install @mastra/core@latest zod @ai-sdk/openai
```

----------------------------------------

TITLE: Configuring Memory Embedder with FastEmbed (TypeScript)
DESCRIPTION: This snippet shows how to configure Mastra Memory to use the local `fastembed` model as the embedder for generating vector embeddings for semantic recall.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/semantic-recall.mdx#_snippet_4

LANGUAGE: ts
CODE:
```
import { Memory } from "@mastra/memory";
import { Agent } from "@mastra/core/agent";
import { fastembed } from "@mastra/fastembed";

const agent = new Agent({
  memory: new Memory({
    // ... other memory options
    embedder: fastembed,
  }),
});
```

----------------------------------------

TITLE: Setting Environment Variables for Mastra RAG
DESCRIPTION: This snippet shows how to configure essential environment variables for the RAG system. `OPENAI_API_KEY` is required for OpenAI services like embeddings and models, while `POSTGRES_CONNECTION_STRING` specifies the connection details for the PGVector database.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank-rag.mdx#_snippet_0

LANGUAGE: bash
CODE:
```
OPENAI_API_KEY=your_openai_api_key_here
POSTGRES_CONNECTION_STRING=your_connection_string_here
```

----------------------------------------

TITLE: Configuring Environment Variables (Environment)
DESCRIPTION: These environment variables are crucial for the application's functionality. `OPENAI_API_KEY` is used for accessing OpenAI's embedding services, and `POSTGRES_CONNECTION_STRING` specifies the database connection for PGVector storage.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank-rag/README.md#_snippet_2

LANGUAGE: env
CODE:
```
OPENAI_API_KEY=sk-your-api-key-here
POSTGRES_CONNECTION_STRING=your-postgres-connection-string-here
```

----------------------------------------

TITLE: Running and Resuming a Mastra Workflow with Inquirer Prompts
DESCRIPTION: This asynchronous function demonstrates how to execute the `product-recommendation-workflow`. It starts a workflow run, checks if the `reviewRecommendations` step is suspended for human intervention, and if so, uses `Inquirer` prompts to collect user input (approved products, personal notes, discount offer). Finally, it resumes the workflow with the collected data, showcasing the interactive human-in-the-loop capability of Mastra.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/human-in-the-loop.mdx#_snippet_1

LANGUAGE: TypeScript
CODE:
```
// Example of using the workflow with Inquirer prompts
async function runRecommendationWorkflow() {
  const registeredWorkflow = mastra.getWorkflow("recommendationWorkflow");
  const run = registeredWorkflow.createRun();

  console.log("Starting product recommendation workflow...");
  const result = await run.start({
    triggerData: {
      customerName: "Jane Smith",
    },
  });

  const isReviewStepSuspended =
    result.activePaths.get("reviewRecommendations")?.status === "suspended";

  // Check if workflow is suspended for human review
  if (isReviewStepSuspended) {
    const { customerName, recommendations, message } = result.activePaths.get(
      "reviewRecommendations",
    )?.suspendPayload;

    console.log("\n===================================");
    console.log(message);
    console.log(`Customer: ${customerName}`);
    console.log("===================================\n");

    // Use Inquirer to collect input from the sales agent in the terminal
    console.log("Available product recommendations:");
    recommendations.forEach((product, index) => {
      console.log(
        `${index + 1}. ${product.productName} - $${product.price.toFixed(2)}`,
      );
      console.log(`   ${product.description}\n`);
    });

    // Let the agent select which products to recommend
    const approvedProducts = await checkbox({
      message: "Select products to recommend to the customer:",
      choices: recommendations.map((product) => ({
        name: `${product.productName} ($${product.price.toFixed(2)})`,
        value: product.productId,
      })),
    });

    // Let the agent add a personal note
    const includeNote = await confirm({
      message: "Would you like to add a personal note?",
      default: false,
    });

    let customerNote = "";
    if (includeNote) {
      customerNote = await input({
        message: "Enter your personalized note for the customer:",
      });
    }

    // Ask if a discount should be offered
    const offerDiscount = await confirm({
      message: "Offer a 10% discount to this customer?",
      default: false,
    });

    console.log("\nSubmitting your review...");

    // Resume the workflow with the agent's input
    const resumeResult = await run.resume({
      stepId: "reviewRecommendations",
      context: {
        approvedProducts,
        customerNote,
        offerDiscount,
      },
    });

    console.log("\n===================================");
    console.log("Workflow completed!");
    console.log("Email content:");
    console.log("===================================\n");
    console.log(
      resumeResult?.results?.sendRecommendations ||
        "No email content generated",
    );

    return resumeResult;
  }

  return result;
}

// Invoke the workflow with interactive terminal input
runRecommendationWorkflow().catch(console.error);
```

----------------------------------------

TITLE: Generating AI Responses with Mastra Client in TypeScript
DESCRIPTION: This snippet illustrates how to interact with a Mastra agent to generate AI responses. It first retrieves a specific agent by ID using `client.getAgent()` and then calls the `generate()` method with a user message to get a response.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/deployment/client.mdx#_snippet_5

LANGUAGE: typescript
CODE:
```
// Get a reference to your local agent
const agent = client.getAgent("dev-agent-id");

// Generate responses
const response = await agent.generate({
  messages: [
    {
      role: "user",
      content: "Hello, I'm testing the local development setup!"
    }
  ]
});
```

----------------------------------------

TITLE: Passing RuntimeContext to Agent Call | Mastra | TypeScript
DESCRIPTION: Demonstrates how to define a type for dynamic configuration, create a RuntimeContext instance, set values, and pass it as an option when calling agent.generate() or agent.stream().
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/tools-mcp/dynamic-context.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { RuntimeContext } from "@mastra/core/di";
// Assume 'agent' is an already defined Mastra Agent instance

// Define the context type
type WeatherRuntimeContext = {
  "temperature-scale": "celsius" | "fahrenheit";
};

// Instantiate RuntimeContext and set values
const runtimeContext = new RuntimeContext<WeatherRuntimeContext>();
runtimeContext.set("temperature-scale", "celsius");

// Pass to agent call
const response = await agent.generate("What's the weather like today?", {
  runtimeContext, // Pass the context here
});

console.log(response.text);
```

----------------------------------------

TITLE: Using MastraClient in a Next.js React Component
DESCRIPTION: Provides an example of using the `mastraClient` within a React component in Next.js. It demonstrates how to retrieve an agent, send a user message, and handle the AI's response for a simple weather query, including error handling.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#_snippet_9

LANGUAGE: typescript
CODE:
```
'use client'

import { mastraClient } from '@/lib/mastra'

export function SimpleWeather() {
  async function handleSubmit(formData: FormData) {
    const city = formData.get('city')
    const agent = mastraClient.getAgent('weatherAgent')

    try {
      const response = await agent.generate({
        messages: [{ role: 'user', content: `What's the weather like in ${city}?` }]
      })
      // Handle the response
      console.log(response.text)
    } catch (error) {
      console.error('Error:', error)
    }
  }

  return (
    <form action={handleSubmit}>
      <input name="city" placeholder="Enter city name" />
      <button type="submit">Get Weather</button>
    </form>
  )
}
```

----------------------------------------

TITLE: Processing Audio to Text and Generating Response with Mastra AI
DESCRIPTION: This snippet demonstrates the core functionality of converting an audio stream to text using a voice agent and then generating a text response based on the transcript. It shows the basic flow for processing pre-recorded audio input and receiving an AI-generated reply. Requires an initialized `voiceAgent` instance.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#_snippet_16

LANGUAGE: typescript
CODE:
```
const audioStream = await createReadStream("./how_can_i_help_you.mp3");

// Convert audio to text
const transcript = await voiceAgent.voice.listen(audioStream);
console.log(`User said: ${transcript}`);

// Generate a response based on the transcript
const { text } = await voiceAgent.generate(transcript);
```

----------------------------------------

TITLE: Initialize Mastra Project using npm create
DESCRIPTION: Use the npm create command (alias for npx) to initialize a new Mastra project. Requires npm version 6 or later.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/create-mastra/README.md#_snippet_1

LANGUAGE: bash
CODE:
```
npm create mastra@latest
```

----------------------------------------

TITLE: Defining Weather Tool and API Integration in Mastra (TypeScript)
DESCRIPTION: This snippet defines the `weatherTool` using `@mastra/core/tools` to fetch current weather data. It outlines the input and output schemas for the tool and implements the `execute` function, which calls the `getWeather` helper. The `getWeather` function handles geocoding and fetching weather data from the Open-Meteo API, while `getWeatherCondition` maps weather codes to human-readable descriptions.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/using-a-tool.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { Mastra } from "@mastra/core";
import { Agent } from "@mastra/core/agent";
import { createTool } from "@mastra/core/tools";
import { openai } from "@ai-sdk/openai";
import { z } from "zod";

interface WeatherResponse {
  current: {
    time: string;
    temperature_2m: number;
    apparent_temperature: number;
    relative_humidity_2m: number;
    wind_speed_10m: number;
    wind_gusts_10m: number;
    weather_code: number;
  };
}

const weatherTool = createTool({
  id: "get-weather",
  description: "Get current weather for a location",
  inputSchema: z.object({
    location: z.string().describe("City name")
  }),
  outputSchema: z.object({
    temperature: z.number(),
    feelsLike: z.number(),
    humidity: z.number(),
    windSpeed: z.number(),
    windGust: z.number(),
    conditions: z.string(),
    location: z.string()
  }),
  execute: async ({ context }) => {
    return await getWeather(context.location);
  }
});

const getWeather = async (location: string) => {
  const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(location)}&count=1`;
  const geocodingResponse = await fetch(geocodingUrl);
  const geocodingData = await geocodingResponse.json();

  if (!geocodingData.results?.[0]) {
    throw new Error(`Location '${location}' not found`);
  }

  const { latitude, longitude, name } = geocodingData.results[0];

  const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,apparent_temperature,relative_humidity_2m,wind_speed_10m,wind_gusts_10m,weather_code`;

  const response = await fetch(weatherUrl);
  const data: WeatherResponse = await response.json();

  return {
    temperature: data.current.temperature_2m,
    feelsLike: data.current.apparent_temperature,
    humidity: data.current.relative_humidity_2m,
    windSpeed: data.current.wind_speed_10m,
    windGust: data.current.wind_gusts_10m,
    conditions: getWeatherCondition(data.current.weather_code),
    location: name
  };
};

function getWeatherCondition(code: number): string {
  const conditions: Record<number, string> = {
    0: "Clear sky",
    1: "Mainly clear",
    2: "Partly cloudy",
    3: "Overcast",
    45: "Foggy",
    48: "Depositing rime fog",
    51: "Light drizzle",
    53: "Moderate drizzle",
    55: "Dense drizzle",
    56: "Light freezing drizzle",
    57: "Dense freezing drizzle",
    61: "Slight rain",
    63: "Moderate rain",
    65: "Heavy rain",
    66: "Light freezing rain",
    67: "Heavy freezing rain",
    71: "Slight snow fall",
    73: "Moderate snow fall",
    75: "Heavy snow fall",
    77: "Snow grains",
    80: "Slight rain showers",
    81: "Moderate rain showers",
    82: "Violent rain showers",
    85: "Slight snow showers",
    86: "Heavy snow showers",
    95: "Thunderstorm",
    96: "Thunderstorm with slight hail",
    99: "Thunderstorm with heavy hail"
  };
  return conditions[code] || "Unknown";
}
```

----------------------------------------

TITLE: Defining a Workflow Step with Schemas and Execution Logic in TypeScript
DESCRIPTION: This snippet illustrates how to create a `myStep` using `createStep` in Mastra, defining its unique `id`, `description`, and `inputSchema`/`outputSchema` using Zod for type validation. It also shows optional `resumeSchema` and `suspendSchema` for managing step state, and an `execute` function that processes input data, accesses other step results, and returns an output matching the defined schema.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
const inputSchema = z.object({
  inputValue: z.string(),
});

const myStep = createStep({
  id: "my-step",
  description: "Does something useful",
  inputSchema,
  outputSchema: z.object({
    outputValue: z.string(),
  }),
  // Optional: Define the resume schema for step resumption
  resumeSchema: z.object({
    resumeValue: z.string(),
  }),
  // Optional: Define the suspend schema for step suspension
  suspendSchema: z.object({
    suspendValue: z.string(),
  }),
  execute: async ({
    inputData,
    mastra,
    getStepResult,
    getInitData,
    runtimeContext,
  }) => {
    const otherStepOutput = getStepResult(step2);
    const initData = getInitData<typeof inputSchema>(); // typed as the input schema variable (zod schema)
    return {
      outputValue: `Processed: ${inputData.inputValue}, ${initData.startValue} (runtimeContextValue: ${runtimeContext.get("runtimeContextValue")})`,
    };
  },
});
```

----------------------------------------

TITLE: Executing and Resuming a Human-in-the-Loop Workflow with Mastra (TypeScript)
DESCRIPTION: This TypeScript snippet demonstrates how to run a 'travelAgentWorkflow' using Mastra AI. It initializes the workflow, starts it with an initial vacation description, and then, upon reaching a human input step, prompts the user for a selection using '@inquirer/prompts'. Finally, it resumes the workflow with the user's choice, showcasing a suspendable workflow pattern.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#_snippet_4

LANGUAGE: TypeScript
CODE:
```
import { mastra } from "./"
import { select } from '@inquirer/prompts'
import { humanInputStep } from './workflows/human-in-the-loop-workflow'
 

const workflow = mastra.getWorkflow('travelAgentWorkflow')
const run = workflow.createRun({})

// Start the workflow with initial vacation description
const result = await run.start({
  inputData: { vacationDescription: 'I want to go to the beach' },
})
 
console.log('result', result)
 
const suggStep = result?.steps?.['generate-suggestions']
 
// If suggestions were generated successfully, proceed with user interaction
if (suggStep.status === 'success') {
  const suggestions = suggStep.output?.suggestions
  
  // Present options to user and get their selection
  const userInput = await select<string>({
    message: "Choose your holiday destination",
    choices: suggestions.map(({ location, description }: { location: string, description: string }) => `- ${location}: ${description}`)
  })
 
  console.log('Selected:', userInput)
 
  // Prepare to resume the workflow with user's selection
  console.log('resuming from', result, 'with', {
    inputData: {
      selection: userInput,
      vacationDescription: "I want to go to the beach",
      suggestions: suggStep?.output?.suggestions,
    },
    step: humanInputStep,
  })

  const result2 = await run.resume({
    resumeData: {
      selection: userInput,
    },
    step: humanInputStep,
  })
 
  console.dir(result2, { depth: null })
}
```

----------------------------------------

TITLE: Create Mastra Project using Mastra CLI
DESCRIPTION: Install the Mastra CLI globally and then use the `mastra create` command to initialize a new project.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/local-dev/creating-a-new-project.mdx#_snippet_1

LANGUAGE: bash
CODE:
```
npm install -g mastra@latest
mastra create
```

----------------------------------------

TITLE: Basic Usage of create-mastra CLI
DESCRIPTION: This snippet illustrates the fundamental command structure for initializing a new Mastra project. The `[options]` placeholder indicates that various configuration flags can be appended to customize the project setup, as detailed in the options table.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/cli/create-mastra.mdx#_snippet_0

LANGUAGE: bash
CODE:
```
create-mastra [options]
```

----------------------------------------

TITLE: Chunking with Markdown and Token Strategies in Mastra RAG (TypeScript)
DESCRIPTION: Illustrates using the 'markdown' strategy with header stripping and the 'token' strategy with specific encoding and model names, alongside general options like `overlap` and `size`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/chunk.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
// Markdown strategy example
const chunks = await doc.chunk({
  strategy: "markdown",
  headers: [
    ["#", "title"],
    ["##", "section"]
  ],
  stripHeaders: true, // Markdown-specific option
  overlap: 50 // general option
});

// Token strategy example
const chunks = await doc.chunk({
  strategy: "token",
  encodingName: "gpt2", // Token-specific option
  modelName: "gpt-3.5-turbo", // Token-specific option
  size: 1000 // general option
});
```

----------------------------------------

TITLE: Managing Data Storage with MongoDBStore (TypeScript)
DESCRIPTION: This snippet demonstrates how to use `MongoDBStore` for general data storage, specifically for managing conversational threads and messages. It shows how to initialize the store, save a new thread, add messages to an existing thread, and retrieve both threads and their associated messages, providing a robust solution for structured data persistence.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/mongodb/README.md#_snippet_2

LANGUAGE: typescript
CODE:
```
import { MongoDBStore } from '@mastra/mongodb';

const store = new MongoDBStore({
  uri: 'mongodb://mongodb:mongodb@localhost:27018/?authSource=admin&directConnection=true',
  dbName: 'mastra',
});

// Create a thread
await store.saveThread({
  id: 'thread-123',
  resourceId: 'resource-456',
  title: 'My Thread',
  metadata: { key: 'value' },
});

// Add messages to thread
await store.saveMessages([
  {
    id: 'msg-789',
    threadId: 'thread-123',
    role: 'user',
    type: 'text',
    content: [{ type: 'text', text: 'Hello' }],
  },
]);

// Query threads and messages
const savedThread = await store.getThread('thread-123');
const messages = await store.getMessages('thread-123');
```

----------------------------------------

TITLE: Executing Parallel Steps in Mastra Workflows (TypeScript)
DESCRIPTION: This snippet shows how to execute multiple steps concurrently using the `.parallel()` method. All steps within the array will run simultaneously, and the workflow will only proceed to the next chained step after all parallel operations have completed.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows-vnext/flow-control.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
myWorkflow.parallel([step1, step2]).then(step3).commit();
```

----------------------------------------

TITLE: Defining Interoperable Weather Workflow with Mastra (TypeScript)
DESCRIPTION: This snippet defines `weatherWorkflow` using `@mastra/core/workflows`, integrating `weatherTool` and `weatherReporterAgent`. It specifies input and output schemas using Zod, chaining steps to fetch weather data and then generate a report using an agent based on that data. The workflow is committed for use within the Mastra framework.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/agent-and-tool-interop.mdx#_snippet_3

LANGUAGE: TypeScript
CODE:
```
import { createWorkflow, createStep } from '@mastra/core/workflows'
import { weatherTool } from '../tools/weather-tool'
import { weatherReporterAgent } from '../agents/weather-reporter-agent'
import { z } from 'zod'

// Create workflow steps from existing tool and agent
const fetchWeather = createStep(weatherTool)
const reportWeather = createStep(weatherReporterAgent)

const weatherWorkflow = createWorkflow({
  steps: [fetchWeather, reportWeather],
  id: 'weather-workflow-step1-single-day',
  inputSchema: z.object({
    location: z.string().describe("The city to get the weather for"),
  }),
  outputSchema: z.object({
    text: z.string(),
  }),
})
  .then(fetchWeather)
  .then(
    createStep({
      id: "report-weather",
      inputSchema: fetchWeather.outputSchema,
      outputSchema: z.object({
        text: z.string(),
      }),
      execute: async ({ inputData, mastra }) => {
        // Create a prompt with the weather data
        const prompt = 'Forecast data: ' + JSON.stringify(inputData)
        const agent = mastra.getAgent('weatherReporterAgent')
        
        // Generate a weather report using the agent
        const result = await agent.generate([
          {
            role: "user",
            content: prompt,
          },
        ]);
        return { text: result.text };
      },
    }),
  );

weatherWorkflow.commit();

export { weatherWorkflow };
```

----------------------------------------

TITLE: Testing Agent Tone Consistency with Vitest
DESCRIPTION: This snippet demonstrates how to write a test using Vitest to evaluate the tone consistency of a Mastra agent. It imports necessary functions from `vitest` and `@mastra/evals`, creates a `ToneConsistencyMetric`, evaluates the agent with a sample input, and asserts the score.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/evals/running-in-ci.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { describe, it, expect } from "vitest";
import { evaluate } from "@mastra/evals";
import { ToneConsistencyMetric } from "@mastra/evals/nlp";
import { myAgent } from "./index";

describe("My Agent", () => {
  it("should validate tone consistency", async () => {
    const metric = new ToneConsistencyMetric();
    const result = await evaluate(myAgent, "Hello, world!", metric);

    expect(result.score).toBe(1);
  });
});
```

----------------------------------------

TITLE: Measuring Hallucination with Basic Usage (TypeScript)
DESCRIPTION: This snippet demonstrates how to initialize and use the `HallucinationMetric` to evaluate an LLM's output for factual accuracy against a provided context. It shows how to configure the model, define the context, and measure the hallucination score, including an example of the expected output. The `measure` method takes the original query and the LLM's response, returning a score from 0-1 and a detailed reason for the score.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/hallucination.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { HallucinationMetric } from "@mastra/evals/llm";

// Configure the model for evaluation
const model = openai("gpt-4o-mini");

const metric = new HallucinationMetric(model, {
  context: [
    "Tesla was founded in 2003 by Martin Eberhard and Marc Tarpenning in San Carlos, California."
  ]
});

const result = await metric.measure(
  "Tell me about Tesla's founding.",
  "Tesla was founded in 2004 by Elon Musk in California.",
);

console.log(result.score); // Score from 0-1
console.log(result.info.reason); // Explanation of the score

// Example output:
// {
//   score: 0.67,
//   info: {
//     reason: "The score is 0.67 because two out of three statements from the context
//           (founding year and founders) were contradicted by the output, while the
//           location statement was not contradicted."
//   }
// }
```

----------------------------------------

TITLE: Configuring Advanced Metadata Extraction with @mastra/rag in TypeScript
DESCRIPTION: Demonstrates how to use the `chunk` method with detailed configuration for extracting various metadata types like titles, summaries, questions, and keywords. It shows how to control the number of nodes for title extraction, the number of summaries/questions/keywords, and the prompt templates used for each extraction type.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/extract-params.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { MDocument } from "@mastra/rag";

const doc = MDocument.fromText(text);
const chunks = await doc.chunk({
  extract: {
    // Title extraction with custom settings
    title: {
      nodes: 2, // Extract 2 title nodes
      nodeTemplate: "Generate a title for this: {context}",
      combineTemplate: "Combine these titles: {context}",
    },

    // Summary extraction with custom settings
    summary: {
      summaries: ["self"], // Generate summaries for current chunk
      promptTemplate: "Summarize this: {context}",
    },

    // Question generation with custom settings
    questions: {
      questions: 3, // Generate 3 questions
      promptTemplate: "Generate {numQuestions} questions about: {context}",
      embeddingOnly: false,
    },

    // Keyword extraction with custom settings
    keywords: {
      keywords: 5, // Extract 5 keywords
      promptTemplate: "Extract {maxKeywords} key terms from: {context}",
    },
  },
});
```

----------------------------------------

TITLE: Defining Weather Forecast Data Schema (TypeScript)
DESCRIPTION: This snippet defines a Zod schema for the weather forecast data. It specifies the expected types and structure for properties like `date`, `maxTemp`, `minTemp`, `precipitationChance`, `condition`, and `location`, ensuring data validation for the weather information.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/agentic-workflows.mdx#_snippet_1

LANGUAGE: TypeScript
CODE:
```
const forecastSchema = z.object({
  date: z.string(),
  maxTemp: z.number(),
  minTemp: z.number(),
  precipitationChance: z.number(),
  condition: z.string(),
  location: z.string()
});
```

----------------------------------------

TITLE: Configuring AI Prompt Behavior in TypeScript
DESCRIPTION: Demonstrates how to apply optional settings to a prompt using the second argument of `createPrompt`. This configuration object allows defining the model's persona, explanation style, tone, expected output format, and message type (system/user).
SOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/prompt-template.md#_snippet_1

LANGUAGE: typescript
CODE:
```
const explainPrompt = createPrompt('Explain this code', {
  // Who the model should act as
  persona: 'JavaScript Teacher',

  // How to approach the explanation
  style: 'beginner-friendly',

  // Communication style
  tone: 'encouraging',

  // Expected response format
  outputFormat: 'markdown',

  // System or user message
  as: 'system',
});

// Usage
const explanation = explainPrompt.toString();
```

----------------------------------------

TITLE: Creating Index with Specific Dimension in TypeScript
DESCRIPTION: This snippet demonstrates how to create a new index in a vector store using TypeScript. It specifies the `indexName` as 'myCollection' and sets the `dimension` to 1536, which is suitable for models like OpenAI's `text-embedding-3-small`. The dimension size is crucial and must match the output of the chosen embedding model, as it cannot be changed after creation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#_snippet_10

LANGUAGE: TypeScript
CODE:
```
// Create an index with dimension 1536 (for text-embedding-3-small)
await store.createIndex({
  indexName: "myCollection",
  dimension: 1536,
});
```

----------------------------------------

TITLE: Defining Looping Workflow with Mastra (TypeScript)
DESCRIPTION: This snippet defines a Mastra workflow that demonstrates looping execution. It includes three `createStep` definitions for incrementing a value, logging a side effect, and returning a final value. The main workflow uses `dountil` to repeatedly execute a nested workflow (incrementing and logging) until the input value reaches 10, showcasing conditional looping in Mastra.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/control-flow.mdx#_snippet_1

LANGUAGE: ts
CODE:
```
import { createWorkflow, createStep } from "@mastra/core/workflows";
import { z } from "zod";

// Step that increments the input value by 1
const incrementStep = createStep({
  id: "increment",
  inputSchema: z.object({
    value: z.number(),
  }),
  outputSchema: z.object({
    value: z.number(),
  }),
  execute: async ({ inputData }) => {
    return { value: inputData.value + 1 };
  },
});

// Step that logs the current value (side effect)
const sideEffectStep = createStep({
  id: "side-effect",
  inputSchema: z.object({
    value: z.number(),
  }),
  outputSchema: z.object({
    value: z.number(),
  }),
  execute: async ({ inputData }) => {
    console.log("log", inputData.value);
    return { value: inputData.value };
  },
});

// Final step that returns the final value
const finalStep = createStep({
  id: "final",
  inputSchema: z.object({
    value: z.number(),
  }),
  outputSchema: z.object({
    value: z.number(),
  }),
  execute: async ({ inputData }) => {
    return { value: inputData.value };
  },
});

// Create a workflow that:
// 1. Increments a number until it reaches 10
// 2. Logs each increment (side effect)
// 3. Returns the final value
const workflow = createWorkflow({
  id: "increment-workflow",
  inputSchema: z.object({
    value: z.number(),
  }),
  outputSchema: z.object({
    value: z.number(),
  }),
})
  .dountil(
    // Nested workflow that performs the increment and logging
    createWorkflow({
      id: "increment-workflow",
      inputSchema: z.object({
        value: z.number(),
      }),
      outputSchema: z.object({
        value: z.number(),
      }),
      steps: [incrementStep, sideEffectStep],
    })
      .then(incrementStep)
      .then(sideEffectStep)
      .commit(),
    // Condition to check if we should stop the loop
    async ({ inputData }) => inputData.value >= 10
  )
  .then(finalStep);

workflow.commit();

export { workflow as incrementWorkflow };
```

----------------------------------------

TITLE: Configuring the Mastra RAG Agent with Tools and Instructions (TypeScript)
DESCRIPTION: This code defines the `ragAgent` using `gpt-4o-mini`, providing it with detailed instructions and the `vectorQueryTool`. The instructions include the metadata structure and the `PGVECTOR_PROMPT`, enabling the agent to understand user queries, identify filter requirements, and apply appropriate metadata filters for relevant information retrieval.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/filter-rag.mdx#_snippet_5

LANGUAGE: typescript
CODE:
```
export const ragAgent = new Agent({
  name: "RAG Agent",
  model: openai("gpt-4o-mini"),
  instructions: `
  You are a helpful assistant that answers questions based on the provided context. Keep your answers concise and relevant.

  Filter the context by searching the metadata.
  
  The metadata is structured as follows:

  {
    text: string,
    excerptKeywords: string,
    nested: {
      keywords: string[],
      id: number,
    },
  }

  ${PGVECTOR_PROMPT}

  Important: When asked to answer a question, please base your answer only on the context provided in the tool. 
  If the context doesn't contain enough information to fully answer the question, please state that explicitly.
  `,
  tools: { vectorQueryTool },
});
```

----------------------------------------

TITLE: Executing the Mastra RAG Workflow with a Query
DESCRIPTION: This snippet demonstrates how to initiate and execute the `ragWorkflow` with a specific user query. It constructs a detailed prompt for the RAG agent, creates a new workflow run, and then starts the workflow, logging the run ID and the final structured results from the chain-of-thought process.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#_snippet_14

LANGUAGE: typescript
CODE:
```
const query = "What are the main adaptation strategies for farmers?";

console.log("\nQuery:", query);
const prompt = `\n    Please answer the following question:\n    ${query}\n\n    Please base your answer only on the context provided in the tool. If the context doesn't contain enough information to fully answer the question, please state that explicitly.\n    `;

const { runId, start } = ragWorkflow.createRun();

console.log("Run:", runId);

const workflowResult = await start({
  triggerData: {
    query: prompt,
  },
});
console.log("\nThought Process:");
console.log(workflowResult.results);
```

----------------------------------------

TITLE: Creating a Workflow with Mastra Core
DESCRIPTION: This snippet demonstrates how to define a workflow using `createWorkflow` from `@mastra/core/workflows`. Workflows orchestrate complex AI tasks, handling state management and error recovery. It requires an ID, input schema, output schema, and a list of steps.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/README.md#_snippet_2

LANGUAGE: typescript
CODE:
```
import { createWorkflow } from '@mastra/core/workflows';
import z from 'zod'

const workflow = createWorkflow({
  id: 'my-workflow',
  inputSchema: z.object({}),
  outputSchema: z.object({})
  steps: [
    // Workflow steps
  ],
});
```

----------------------------------------

TITLE: Registering a Mastra Agent in TypeScript
DESCRIPTION: This snippet illustrates how to register a created agent with the main `Mastra` instance. Registering the agent enables features like logging and ensures it has access to configured tools and integrations within the Mastra ecosystem.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_3

LANGUAGE: ts
CODE:
```
import { Mastra } from "@mastra/core";
import { myAgent } from "./agents";

export const mastra = new Mastra({
  agents: { myAgent },
});
```

----------------------------------------

TITLE: Creating and Running an Agent-Based Workflow in Mastra (TypeScript)
DESCRIPTION: This snippet demonstrates how to define and execute a Mastra workflow that incorporates an AI agent as a step. It includes creating a custom input preparation step, integrating an `Agent` instance using `createStep(agent)`, defining the workflow's input/output schemas, sequencing the steps, and running the workflow with sample data.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/using-with-agents-and-tools.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { Mastra } from "@mastra/core";
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { createWorkflow, createStep } from "@mastra/core/workflows";
import { z } from "zod";

const myAgent = new Agent({
  name: "myAgent",
  instructions: "You are a helpful assistant that answers questions concisely.",
  model: openai("gpt-4o"),
});

// Input preparation step
const preparationStep = createStep({
  id: "preparation",
  inputSchema: z.object({
      question: z.string()
  }),
  outputSchema: z.object({
      formattedPrompt: z.string()
  }),
  execute: async ({ inputData }) => {
      return {
          formattedPrompt: `Answer this question briefly: ${inputData.question}`
      };
  }
});

const agentStep = createStep(myAgent)

// Create a simple workflow
const myWorkflow = createWorkflow({
  id: "simple-qa-workflow",
  inputSchema: z.object({
      question: z.string()
  }),
  outputSchema: z.string(),
  steps: [preparationStep, agentStep]
});

// Define workflow sequence
myWorkflow
  .then(preparationStep)
  .map({
    prompt: {
        step: preparationStep,
        path: "formattedPrompt",
    },
  })
  .then(agentStep)
  .commit();

// Create Mastra instance
const mastra = new Mastra({
  agents: {
      myAgent,
  },
  workflows: {
      myWorkflow,
  },
});

const workflow = mastra.getWorkflow("myWorkflow");
const run = workflow.createRun();

// Run the workflow with a question
const res = await run.start({
  inputData: {
      question: "What is machine learning?"
  }
});

if (res.status === "success") {
  console.log("Answer:", res.result);
} else if (res.status === "failed") {
  console.error("Workflow failed:", res.error);
}
```

----------------------------------------

TITLE: Integrating Mastra Handlers with Hono (TypeScript)
DESCRIPTION: Demonstrates how to integrate `@mastra/server` handlers into a web framework like Hono. It shows importing necessary modules, creating a Hono app instance, and mounting specific handlers (`getAgentsHandler`, `generateHandler`) to defined routes, passing the Mastra instance and request context. Dependencies include `hono` and `@mastra/server`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/server/README.md#_snippet_1

LANGUAGE: typescript
CODE:
```
import { Hono } from 'hono';
import { handlers } from '@mastra/server';
import { mastra } from './mastra-instance';

const app = new Hono();

app.get('/mastra/agents', ctx => handlers.agents.getAgentsHandler({ mastra, runtimeContext: ctx }));
app.post('/mastra/agents/:id/generate', async ctx => {
  const body = await ctx.req.json();
  return handlers.agents.generateHandler({
    mastra,
    runtimeContext: ctx,
    agentId: ctx.req.param('id'),
    body,
  });
});

// Mount additional handlers as required
```

----------------------------------------

TITLE: Configuring MCPServer to Expose a Mastra Workflow (TypeScript)
DESCRIPTION: This TypeScript snippet illustrates how to configure an MCPServer instance to expose a Mastra Workflow as a callable tool. It demonstrates importing necessary modules, instantiating MCPServer with a 'workflows' configuration, and starting the server. The 'weatherWorkflow' is exposed as 'run_weatherWorkflow' to any connected MCP client, allowing it to be invoked with specific input data.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/using-with-agents-and-tools.mdx#_snippet_9

LANGUAGE: TypeScript
CODE:
```
import { MCPServer } from "@mastra/mcp";
import { createWorkflow, createStep } from "@mastra/core/workflows";
import { z } from "zod";
import { weatherWorkflow } from "./workflows";

const server = new MCPServer({
  name: "MyServerWithWorkflowTool",
  version: "1.0.0",
  tools: {
    // You can still have other defined tools
  },
  workflows: {
    weatherWorkflow, // Exposes 'run_weatherWorkflow' tool
  },
});

// To start the server (example using stdio):
server.startStdio().catch(console.error);

// An MCP client could now connect and see a tool named 'run_weatherWorkflow'.
// Calling it with { "city": "Paris" } would run the workflow.
```

----------------------------------------

TITLE: Creating Mastra Agents with Voice Capabilities (TypeScript)
DESCRIPTION: This snippet demonstrates how to define two distinct AI agents, 'Optimist' and 'Skeptic', using the Mastra Agent class. Each agent is configured with a unique personality through 'instructions', uses the 'gpt-4o' model, and is assigned a specific voice ('alloy' for Optimist, 'echo' for Skeptic) via 'OpenAIVoice' for speech synthesis. These agents are designed to participate in a debate, taking turns to respond.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/turn-taking.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { OpenAIVoice } from "@mastra/voice-openai";

export const optimistAgent = new Agent({
  name: "Optimist",
  instructions:
    "You are an optimistic debater who sees the positive side of every topic. Keep your responses concise and engaging, about 2-3 sentences.",
  model: openai("gpt-4o"),
  voice: new OpenAIVoice({
    speaker: "alloy",
  }),
});

export const skepticAgent = new Agent({
  name: "Skeptic",
  instructions:
    "You are a RUDE skeptical debater who questions assumptions and points out potential issues. Keep your responses concise and engaging, about 2-3 sentences.",
  model: openai("gpt-4o"),
  voice: new OpenAIVoice({
    speaker: "echo",
  }),
});
```

----------------------------------------

TITLE: Enabling Telemetry and Evaluation Tracking - TypeScript
DESCRIPTION: This code demonstrates how to enable telemetry and logging for `@mastra/evals` using the `attachListeners` function. It shows how to enable basic evaluation tracking and how to integrate with Mastra Storage for persistent evaluation data, which is useful for debugging and monitoring.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/evals/README.md#_snippet_3

LANGUAGE: typescript
CODE:
```
import { attachListeners } from '@mastra/evals';

// Enable basic evaluation tracking
await attachListeners();

// Store evals in Mastra Storage (if storage is enabled)
await attachListeners(mastra);
// Note: When using in-memory storage, evaluations are isolated to the test process.
// When using file storage, evaluations are persisted and can be queried later.
```

----------------------------------------

TITLE: Defining Step to Extract Candidate Details (TypeScript)
DESCRIPTION: This snippet defines the `gatherCandidateInfo` step using Mastra's `createStep`. It initializes an `Agent` with `gpt-4o-mini` to parse resume text. The step takes `resumeText` as input, prompts the LLM to extract structured data (name, technical status, specialty), and returns these details, enabling subsequent workflow decisions.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/ai-recruiter.mdx#_snippet_2

LANGUAGE: TypeScript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";

const recruiter = new Agent({
  name: "Recruiter Agent",
  instructions: `You are a recruiter.`,
  model: openai("gpt-4o-mini")
});

const gatherCandidateInfo = createStep({
  id: "gatherCandidateInfo",
  inputSchema: z.object({
    resumeText: z.string()
  }),
  outputSchema: z.object({
    candidateName: z.string(),
    isTechnical: z.boolean(),
    specialty: z.string(),
    resumeText: z.string()
  }),
  execute: async ({ inputData }) => {
    const resumeText = inputData?.resumeText;

    const prompt = `
          Extract details from the resume text:
          "${resumeText}"
        `;

    const res = await recruiter.generate(prompt, {
      output: z.object({
        candidateName: z.string(),
        isTechnical: z.boolean(),
        specialty: z.string(),
        resumeText: z.string()
      })
    });

    return res.object;
  }
});
```

----------------------------------------

TITLE: Executing Mastra Activity Planner Workflow (TypeScript)
DESCRIPTION: This snippet demonstrates how to retrieve the 'activityPlanningWorkflow' from the Mastra instance, create a new workflow run, and execute it with the required input data (e.g., a city name). It also sets up a Hono server to listen for Inngest events and prints the workflow's final result to the console, then closes the server.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/inngest-workflow.mdx#_snippet_8

LANGUAGE: TypeScript
CODE:
```
import { mastra } from './'
import { serve } from '@hono/node-server'
import { createHonoServer } from '@mastra/deployer/server'


const app = await createHonoServer(mastra)

// Start the server on port 3000 so Inngest can send events to it
const srv = serve({
    fetch: app.fetch,
    port: 3000,
})

const workflow = mastra.getWorkflow('activityPlanningWorkflow')
const run = workflow.createRun({})

// Start the workflow with the required input data (city name)
// This will trigger the workflow steps and stream the result to the console
const result = await run.start({ inputData: { city: 'New York' } })
console.dir(result, { depth: null })

// Close the server after the workflow run is complete
srv.close()
```

----------------------------------------

TITLE: Processing Text Documents into Chunks with MDocument
DESCRIPTION: This code demonstrates how to create an `MDocument` from raw text and then chunk it into smaller, manageable segments. It uses a 'recursive' chunking strategy with a specified `size` (512 characters), `overlap` (50 characters), and `separator` ('\n'). This process is crucial for preparing documents for embedding and efficient retrieval from the vector store.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-rag.mdx#_snippet_5

LANGUAGE: typescript
CODE:
```
const doc = MDocument.fromText(
  "The Impact of Climate Change on Global Agriculture..."
);

const chunks = await doc.chunk({
  strategy: "recursive",
  size: 512,
  overlap: 50,
  separator: "\n"
});
```

----------------------------------------

TITLE: Using LibSQLVector for Vector Storage in TypeScript
DESCRIPTION: This TypeScript snippet illustrates the core operations for managing vector data using `LibSQLVector`. It covers initializing the vector store, creating a new vector index with specified dimensions and metric, upserting vectors with associated metadata, and querying for similar vectors with optional filtering and score thresholds. The `url` parameter specifies the SQLite database file path.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/libsql/README.md#_snippet_1

LANGUAGE: typescript
CODE:
```
import { LibSQLVector } from '@mastra/libsql';

const vectorStore = new LibSQLVector({
  url: 'file:./my-db.db'
});

// Create a new table with vector support
await vectorStore.createIndex({
  indexName: 'my_vectors',
  dimension: 1536,
  metric: 'cosine',
});

// Add vectors
const ids = await vectorStore.upsert({
  indexName: 'my_vectors',
  vectors: [[0.1, 0.2, ...], [0.3, 0.4, ...]],
  metadata: [{ text: 'doc1' }, { text: 'doc2' }],
});

// Query vectors
const results = await vectorStore.query({
  indexName: 'my_vectors',
  queryVector: [0.1, 0.2, ...],
  topK: 10, // topK
  filter: { text: 'doc1' }, // filter
  includeVector: false, // includeVector
  minScore: 0.5, // minScore
});
```

----------------------------------------

TITLE: Configuring Mastra Agent with Chain-of-Thought Instructions
DESCRIPTION: This code defines the `ragAgent` using Mastra's `Agent` class, providing detailed instructions for chain-of-thought reasoning. The agent is named 'RAG Agent', uses the 'gpt-4o-mini' OpenAI model, and integrates the previously created `vectorQueryTool` to retrieve context. The instructions guide the agent to analyze context, break down its thinking, connect information, and draw conclusions based solely on provided evidence, explicitly stating when information is insufficient.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-rag.mdx#_snippet_3

LANGUAGE: typescript
CODE:
```
export const ragAgent = new Agent({
  name: "RAG Agent",
  instructions: "You are a helpful assistant that answers questions based on the provided context.\nFollow these steps for each response:\n\n1. First, carefully analyze the retrieved context chunks and identify key information.\n2. Break down your thinking process about how the retrieved information relates to the query.\n3. Explain how you're connecting different pieces from the retrieved chunks.\n4. Draw conclusions based only on the evidence in the retrieved context.\n5. If the retrieved chunks don't contain enough information, explicitly state what's missing.\n\nFormat your response as:\nTHOUGHT PROCESS:\n- Step 1: [Initial analysis of retrieved chunks]\n- Step 2: [Connections between chunks]\n- Step 3: [Reasoning based on chunks]\n\nFINAL ANSWER:\n[Your concise answer based on the retrieved context]\n\nImportant: When asked to answer a question, please base your answer only on the context provided in the tool. \nIf the context doesn't contain enough information to fully answer the question, please state that explicitly.\nRemember: Explain how you're using the retrieved information to reach your conclusions.\n",
  model: openai("gpt-4o-mini"),
  tools: { vectorQueryTool }
});
```

----------------------------------------

TITLE: Generating a Response with the RAG Agent
DESCRIPTION: This example demonstrates how to use the configured `ragAgent` to generate a response. It constructs a prompt that explicitly instructs the agent to base its answer solely on the provided context and to state if information is insufficient. The `agent.generate()` method processes the prompt, and the resulting text completion is logged to the console.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/basic-rag.mdx#_snippet_5

LANGUAGE: typescript
CODE:
```
const prompt = `
[Insert query based on document here]
Please base your answer only on the context provided in the tool. 
If the context doesn't contain enough information to fully answer the question, please state that explicitly.
`;

const completion = await agent.generate(prompt);
console.log(completion.text);
```

----------------------------------------

TITLE: Configuring OpenAI and Postgres Environment Variables (Env)
DESCRIPTION: These lines illustrate how to set the OPENAI_API_KEY and POSTGRES_CONNECTION_STRING within the .env file. These variables are crucial for authenticating with OpenAI services and connecting to the PostgreSQL database, respectively.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cot-rag/README.md#_snippet_2

LANGUAGE: Env
CODE:
```
OPENAI_API_KEY=sk-your-api-key-here
POSTGRES_CONNECTION_STRING=your-postgres-connection-string-here
```

----------------------------------------

TITLE: Adding Custom Tools to a Mastra Agent (TypeScript)
DESCRIPTION: This code illustrates how to integrate a previously defined custom tool, `weatherInfo`, into a Mastra agent's configuration. The `Agent` constructor from `@mastra/core/agent` is used, where the tool is added to the `tools` property, making it available for the agent to use based on its instructions and model.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/using-tools-and-mcp.mdx#_snippet_1

LANGUAGE: TypeScript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";
import { weatherInfo } from "../tools/weatherInfo";

export const weatherAgent = new Agent({
  name: "Weather Agent",
  instructions:
    "You are a helpful assistant that provides current weather information. When asked about the weather, use the weather information tool to fetch the data.",
  model: openai("gpt-4o-mini"),
  tools: {
    weatherInfo,
  },
});
```

----------------------------------------

TITLE: Measuring Context Position with Basic Usage (TypeScript)
DESCRIPTION: This snippet demonstrates the fundamental usage of the `ContextPositionMetric` class. It shows how to configure an AI model (e.g., `gpt-4o-mini` from `@ai-sdk/openai`), initialize the metric with a predefined array of context strings, and then use the `measure` method to evaluate the position score of the context based on a given query and output. The result includes a numerical score and a textual explanation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/context-position.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { ContextPositionMetric } from "@mastra/evals/llm";

// Configure the model for evaluation
const model = openai("gpt-4o-mini");

const metric = new ContextPositionMetric(model, {
  context: [
    "Photosynthesis is a biological process used by plants to create energy from sunlight.",
    "The process of photosynthesis produces oxygen as a byproduct.",
    "Plants need water and nutrients from the soil to grow.",
  ],
});

const result = await metric.measure(
  "What is photosynthesis?",
  "Photosynthesis is the process by which plants convert sunlight into energy.",
);

console.log(result.score); // Position score from 0-1
console.log(result.info.reason); // Explanation of the score
```

----------------------------------------

TITLE: Basic Usage of AnswerRelevancyMetric (TypeScript)
DESCRIPTION: Demonstrates the basic initialization and usage of the `AnswerRelevancyMetric` class to evaluate the relevancy of an LLM output to a given input query. It shows how to configure the evaluation model, create a metric instance with default options, measure relevancy, and access the resulting score and explanation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/answer-relevancy.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { AnswerRelevancyMetric } from "@mastra/evals/llm";

// Configure the model for evaluation
const model = openai("gpt-4o-mini");

const metric = new AnswerRelevancyMetric(model, {
  uncertaintyWeight: 0.3,
  scale: 1,
});

const result = await metric.measure(
  "What is the capital of France?",
  "Paris is the capital of France."
);

console.log(result.score); // Score from 0-1
console.log(result.info.reason); // Explanation of the score
```

----------------------------------------

TITLE: Creating an AI Agent with System Prompt and Tool in Mastra (TypeScript)
DESCRIPTION: This snippet demonstrates how to create an AI agent using Mastra, defining its behavior with a system prompt and integrating a custom tool. It shows how to set up an agent that acts as a 'cat expert' and uses a 'catFact' tool to fetch verified information, ensuring accuracy and natural incorporation of facts into responses.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/system-prompt.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { createTool } from "@mastra/core/tools";

import { z } from "zod";

const instructions = `You are a helpful cat expert assistant. When discussing cats, you should always include an interesting cat fact.

  Your main responsibilities:
  1. Answer questions about cats
  2. Use the catFact tool to provide verified cat facts
  3. Incorporate the cat facts naturally into your responses

  Always use the catFact tool at least once in your responses to ensure accuracy.`;

const getCatFact = async () => {
  const { fact } = (await fetch("https://catfact.ninja/fact").then((res) =>
    res.json(),
  )) as {
    fact: string;
  };

  return fact;
};

const catFact = createTool({
  id: "Get cat facts",
  inputSchema: z.object({}),
  description: "Fetches cat facts",
  execute: async () => {
    console.log("using tool to fetch cat fact");
    return {
      catFact: await getCatFact(),
    };
  },
});

const catOne = new Agent({
  name: "cat-one",
  instructions: instructions,
  model: openai("gpt-4o-mini"),
  tools: {
    catFact,
  },
});

const result = await catOne.generate("Tell me a cat fact");

console.log(result.text);
```

----------------------------------------

TITLE: Avoiding Incorrect Destructuring of Mastra Workflow Run Instances (TypeScript)
DESCRIPTION: This snippet highlights a critical pitfall when working with Mastra workflow run instances: destructuring the `run` object. It explicitly warns against destructuring `start`, `resume`, or other properties directly from `myWorkflow.createRun()` or from the `run` instance itself, as this breaks the internal connection required for the workflow to function correctly.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#_snippet_7

LANGUAGE: typescript
CODE:
```
const { start, resume, ... } = myWorkflow.createRun();

// NOR

const run = myWorkflow.createRun();
const { start, resume, ... } = run;
```

----------------------------------------

TITLE: Using PineconeVector for Index Operations - TypeScript
DESCRIPTION: This comprehensive example illustrates how to initialize `PineconeVector` with an API key and environment URL, then perform core operations: creating a new index with specified dimensions and metric, upserting vectors with optional metadata, and querying for similar vectors with filtering and top-K limits. It showcases the primary functionalities of the `@mastra/pinecone` library.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/pinecone/README.md#_snippet_1

LANGUAGE: typescript
CODE:
```
import { PineconeVector } from '@mastra/pinecone';

const vectorStore = new PineconeVector(
  'your-api-key',
  'optional-environment-url'
);

// Create a new index
await vectorStore.createIndex({ indexName: 'my-index', dimension: 1536, metric: 'cosine' });

// Add vectors
const vectors = [[0.1, 0.2, ...], [0.3, 0.4, ...]];
const metadata = [{ text: 'doc1' }, { text: 'doc2' }];
const ids = await vectorStore.upsert({ indexName: 'my-index', vectors, metadata });

// Query vectors
const results = await vectorStore.query({
  indexName: 'my-index',
  queryVector: [0.1, 0.2, ...],
  topK: 10, // topK
  filter: { text: { $eq: 'doc1' } }, // optional filter
  includeVector: false, // includeValues
});
```

----------------------------------------

TITLE: Creating Custom Data Stream with Agent Stream Merge - TypeScript
DESCRIPTION: This code demonstrates creating a custom data stream using `createDataStream` from the `ai` library. It defines a Mastra `Agent` and then creates a stream that can write custom data (`writeData`), message annotations (`writeMessageAnnotation`), and merge the output of a Mastra agent stream (`agentStream.mergeIntoDataStream`). The `execute` function defines the asynchronous logic for the stream.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/ai-sdk.mdx#_snippet_7

LANGUAGE: typescript
CODE:
```
import { createDataStream } from "ai";
import { Agent } from "@mastra/core/agent";

export const weatherAgent = new Agent({
  name: "Weather Agent",
  instructions: `
          You are a helpful weather assistant that provides accurate weather information.

          Your primary function is to help users get weather details for specific locations. When responding:
          - Always ask for a location if none is provided
          - If the location name isn't in English, please translate it
          - If giving a location with multiple parts (e.g. "New York, NY"), use the most relevant part (e.g. "New York")
          - Include relevant details like humidity, wind conditions, and precipitation
          - Keep responses concise but informative

          Use the weatherTool to fetch current weather data.
    `,
  model: openai("gpt-4o"),
  tools: { weatherTool },
});

const stream = createDataStream({
  async execute(dataStream) {
    // Write data
    dataStream.writeData({ value: "Hello" });

    // Write annotation
    dataStream.writeMessageAnnotation({ type: "status", value: "processing" });

    //mastra agent stream
    const agentStream = await weatherAgent.stream("What is the weather");

    // Merge agent stream
    agentStream.mergeIntoDataStream(dataStream);
  },
  onError: (error) => `Custom error: ${error.message}`,
});
```

----------------------------------------

TITLE: Enabling and Customizing Working Memory - TypeScript
DESCRIPTION: This snippet demonstrates how to enable and configure the working memory feature within the `Memory` class options. It sets `enabled` to `true` and provides a custom Markdown `template` for structuring persistent user information. This allows agents to maintain and update specific user details across conversations.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/Memory.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
const memory = new Memory({
  options: {
    workingMemory: {
      enabled: true,
      template: "# User\n- **First Name**:\n- **Last Name**:",
    },
  },
});
```

----------------------------------------

TITLE: Configuring API Keys in .env File - Environment Variables
DESCRIPTION: This snippet shows the required format for adding Anthropic and OpenAI API keys to the '.env' file. These keys are essential for authenticating with the respective AI services used by the multi-agent workflow to function correctly.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/multi-agent-workflow/README.md#_snippet_2

LANGUAGE: env
CODE:
```
ANTHROPIC_API_KEY=sk-your-api-key-here
OPENAI_API_KEY=sk-your-api-key-here
```

----------------------------------------

TITLE: Defining and Executing a Multi-Step Mastra Workflow with Data Mapping in TypeScript
DESCRIPTION: This snippet defines a Mastra workflow consisting of three sequential steps, demonstrating how to pass and combine outputs from earlier steps and initial workflow input into a later step. It uses Zod for input/output schema validation, chains steps with `.then()`, and explicitly maps data sources to `step3`'s inputs using the `.map()` function. Finally, it shows how to create and run an instance of the defined workflow.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/input-data-mapping.mdx#_snippet_3

LANGUAGE: typescript
CODE:
```
import { Mastra } from "@mastra/core";
import { createWorkflow, createStep } from "@mastra/core/workflows";
import { z } from "zod";


const step1 = createStep({
  id: "step1",
  inputSchema: z.object({
    inputValue: z.string(),
  }),
  outputSchema: z.object({
    intermediateValue: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    mastra.getLogger()?.debug(`Step 1 received: ${inputData.inputValue}`);
    return { intermediateValue: `Step 1: ${inputData.inputValue}` };
  },
});

const step2 = createStep({
  id: "step2",
  inputSchema: z.object({
    intermediateValue: z.string(),
  }),
  outputSchema: z.object({
    currentResult: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    mastra.getLogger()?.debug(`Step 2 received: ${inputData.intermediateValue}`);
    return { currentResult: `Step 2: ${inputData.intermediateValue}` };
  },
});

const step3 = createStep({
  id: "step3",
  inputSchema: z.object({
    currentResult: z.string(),     // From step2
    intermediateValue: z.string(), // From step1
    initialValue: z.string(),      // From workflow input
  }),
  outputSchema: z.object({
    result: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    mastra.getLogger()?.debug(`Step 3 combining all previous data`);
    return {
      result: `Combined result:
      - Initial input: ${inputData.initialValue}
      - Step 1 output: ${inputData.intermediateValue}
      - Step 2 output: ${inputData.currentResult}`
    };
  },
});

const myWorkflow = createWorkflow({
  id: "my-workflow",
  inputSchema: z.object({
    inputValue: z.string(),
  }),
  outputSchema: z.object({
    result: z.string(),
  }),
  steps: [step1, step2, step3],
})

myWorkflow
  .then(step1)
  .then(step2)
  .map({
  // Map values from different sources to step3's inputs
  initialValue: {
      initData: myWorkflow,
      path: "inputValue",
  },
  currentResult: {
      step: step2,
      path: "currentResult",
  },
  intermediateValue: {
      step: step1,
      path: "intermediateValue",
  },
  })
  .then(step3)
  .commit();

// Create Mastra instance with all workflows
const mastra = new Mastra({
  workflows: {
    myWorkflow,
  }
});

const run = mastra.getWorkflow("myWorkflow").createRun();
const res = await run.start({
  inputData: { inputValue: "Starting data" }
});
if (res.status === "success") {
  console.log("Result:", res.result);
}
```

----------------------------------------

TITLE: Using TokenLimiter with Mastra Memory
DESCRIPTION: Demonstrates how to initialize a Mastra Agent with a Memory component that includes the TokenLimiter processor. This processor is configured with a token limit to prevent exceeding the LLM's context window by removing the oldest messages from memory.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/memory-processors.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { Memory } from "@mastra/memory";
import { TokenLimiter } from "@mastra/memory/processors";
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";

const agent = new Agent({
  model: openai("gpt-4o"),
  memory: new Memory({
    processors: [
      // Ensure the total tokens from memory don't exceed ~127k
      new TokenLimiter(127000),
    ],
  }),
});
```

----------------------------------------

TITLE: Connecting to OpenAI Realtime Voice and Handling Stream (TypeScript)
DESCRIPTION: Initializes an OpenAIRealtimeVoice provider and a Node.js speaker. Establishes a real-time connection using `voice.connect()`, first without options, then with timeout and reconnect options. Sets up an event listener to pipe the incoming audio stream to the speaker.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.connect.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";
import Speaker from "@mastra/node-speaker";

const speaker = new Speaker({
  sampleRate: 24100, // Audio sample rate in Hz - standard for high-quality audio on MacBook Pro
  channels: 1, // Mono audio output (as opposed to stereo which would be 2)
  bitDepth: 16, // Bit depth for audio quality - CD quality standard (16-bit resolution)
});

// Initialize a real-time voice provider
const voice = new OpenAIRealtimeVoice({
  realtimeConfig: {
    model: "gpt-4o-mini-realtime",
    apiKey: process.env.OPENAI_API_KEY,
    options: {
      sessionConfig: {
        turn_detection: {
          type: "server_vad",
          threshold: 0.6,
          silence_duration_ms: 1200,
        }
      }
    }
  },
  speaker: "alloy" // Default voice
});
// Connect to the real-time service
await voice.connect();
// Now you can use real-time features
voice.on("speaker", (stream) => {
  stream.pipe(speaker);
});
// With connection options
await voice.connect({
  timeout: 10000, // 10 seconds timeout
  reconnect: true,
});
```

----------------------------------------

TITLE: Categorizing Birds with Mastra AI Agent in TypeScript
DESCRIPTION: This comprehensive TypeScript example demonstrates how to fetch a random image from Unsplash and then use a Mastra AI Agent to determine if the image contains a bird, identify its species, and summarize its location. It defines types for image data, a helper function `getRandomImage` to interact with the Unsplash API, and initializes a `birdCheckerAgent` using `@mastra/core/agent` and `@ai-sdk/anthropic`. The agent is configured with specific instructions and an output schema to extract structured information.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/bird-checker.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { anthropic } from "@ai-sdk/anthropic";
import { Agent } from "@mastra/core/agent";
import { z } from "zod";

export type Image = {
  alt_description: string;
  urls: {
    regular: string;
    raw: string;
  };
  user: {
    first_name: string;
    links: {
      html: string;
    };
  };
};

export type ImageResponse<T, K> =
  | {
      ok: true;
      data: T;
    }
  | {
      ok: false;
      error: K;
    };

const getRandomImage = async ({
  query,
}: {
  query: string;
}): Promise<ImageResponse<Image, string>> => {
  const page = Math.floor(Math.random() * 20);
  const order_by = Math.random() < 0.5 ? "relevant" : "latest";
  try {
    const res = await fetch(
      `https://api.unsplash.com/search/photos?query=${query}&page=${page}&order_by=${order_by}`,
      {
        method: "GET",
        headers: {
          Authorization: `Client-ID ${process.env.UNSPLASH_ACCESS_KEY}`,
          "Accept-Version": "v1",
        },
        cache: "no-store",
      },
    );

    if (!res.ok) {
      return {
        ok: false,
        error: "Failed to fetch image",
      };
    }

    const data = (await res.json()) as {
      results: Array<Image>;
    };
    const randomNo = Math.floor(Math.random() * data.results.length);

    return {
      ok: true,
      data: data.results[randomNo] as Image,
    };
  } catch (err) {
    return {
      ok: false,
      error: "Error fetching image",
    };
  }
};

const instructions = `
  You can view an image and figure out if it is a bird or not. 
  You can also figure out the species of the bird and where the picture was taken.
`;

export const birdCheckerAgent = new Agent({
  name: "Bird checker",
  instructions,
  model: anthropic("claude-3-haiku-20240307"),
});

const queries: string[] = ["wildlife", "feathers", "flying", "birds"];
const randomQuery = queries[Math.floor(Math.random() * queries.length)];

// Get the image url from Unsplash with random type
const imageResponse = await getRandomImage({ query: randomQuery });

if (!imageResponse.ok) {
  console.log("Error fetching image", imageResponse.error);
  process.exit(1);
}

console.log("Image URL: ", imageResponse.data.urls.regular);
const response = await birdCheckerAgent.generate(
  [
    {
      role: "user",
      content: [
        {
          type: "image",
          image: new URL(imageResponse.data.urls.regular),
        },
        {
          type: "text",
          text: "view this image and let me know if it's a bird or not, and the scientific name of the bird without any explanation. Also summarize the location for this picture in one or two short sentences understandable by a high school student",
        },
      ],
    },
  ],
  {
    output: z.object({
      bird: z.boolean(),
      species: z.string(),
      location: z.string(),
    }),
  },
);

console.log(response.object);
```

----------------------------------------

TITLE: Defining a Workflow Step with Schemas - TypeScript
DESCRIPTION: This example illustrates the creation of a `myStep` using `createStep`, defining its unique ID, description, and Zod schemas for input, output, resume, and suspend data. The `execute` function demonstrates accessing input data, workflow initialization data, and results from other steps, returning a structured output.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_1

LANGUAGE: typescript
CODE:
```
const inputSchema = z.object({
  inputValue: z.string(),
});

const myStep = createStep({
  id: 'my-step',
  description: 'Does something useful',
  inputSchema,
  outputSchema: z.object({
    outputValue: z.string(),
  }),
  resumeSchema: z.object({
    resumeValue: z.string(),
  }),
  suspendSchema: z.object({
    suspendValue: z.string(),
  }),
  execute: async ({ inputData, mastra, getStepResult, getInitData, runtimeContext }) => {
    const otherStepOutput = getStepResult(step2);
    const initData = getInitData<typeof inputSchema>(); // typed as the workflow input schema
    return {
      outputValue: `Processed: ${inputData.inputValue}, ${initData.startValue} (runtimeContextValue: ${runtimeContext.get('runtimeContextValue')})`,
    };
  },
});
```

----------------------------------------

TITLE: Configuring OpenAI API Key and Postgres Connection String (Environment)
DESCRIPTION: These lines illustrate how to set the OPENAI_API_KEY and POSTGRES_CONNECTION_STRING within the .env file. These variables are crucial for authenticating with OpenAI services and connecting to the PostgreSQL database, respectively.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank/README.md#_snippet_2

LANGUAGE: env
CODE:
```
OPENAI_API_KEY=sk-your-api-key-here
POSTGRES_CONNECTION_STRING=your-postgres-connection-string-here
```

----------------------------------------

TITLE: Comprehensive Prompt Template Example (TypeScript)
DESCRIPTION: Presents a complete example combining intent, configuration, components, and variables to create a robust bug report template. It demonstrates defining variable types, setting persona and output format, adding context, constraints, examples, and using variables in the prompt text, along with usage examples for `toString()` and `toMessage()`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/prompt-template.md#_snippet_4

LANGUAGE: typescript
CODE:
```
type BugReportVars = {
  severity: string;
  component: string;
};

const bugReportTemplate = createPrompt<BugReportVars>('Create bug report', {
  persona: 'QA Engineer',
  outputFormat: 'markdown',
})
  .context('We use GitHub issues for tracking bugs')
  .constraints(['Be specific and actionable', 'Include reproduction steps'])
  .examples([
    {
      input: "Login button doesn't work",
      output: '## Login Authentication Failure\n1. Steps to reproduce...',
    },
  ])
  .text('Create a {{severity}} bug report for {{component}} issue');

// Usage examples
const reportString = bugReportTemplate.toString({
  severity: 'high',
  component: 'checkout',
});

const reportMessage = bugReportTemplate.toMessage({
  severity: 'high',
  component: 'checkout',
});
```

----------------------------------------

TITLE: Configuring Working Memory with LibSQL Storage in TypeScript
DESCRIPTION: This snippet demonstrates how to initialize Mastra's Memory system with working memory enabled and a short lastMessages context window. It also shows how to configure LibSQLStore for persistent storage, ensuring data is not lost across application restarts.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/streaming-working-memory-advanced.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { Memory } from "@mastra/memory";
import { LibSQLStore } from "@mastra/libsql";

const memory = new Memory({
  options: {
    lastMessages: 1, // working memory means we can have a shorter context window and still maintain conversational coherence
    workingMemory: {
      enabled: true,
    },
  },
  storage: new LibSQLStore({
    url: "file:../mastra.db",
  }),
});
```

----------------------------------------

TITLE: Instantiating PgVector and Mastra Core
DESCRIPTION: This snippet initializes `PgVector` with the PostgreSQL connection string, enabling interaction with the vector database. It then instantiates the main `Mastra` application, registering the `ragAgent` and `pgVector` components. Finally, it retrieves the configured `ragAgent` instance for further use.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/basic-rag.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
const pgVector = new PgVector({ connectionString: process.env.POSTGRES_CONNECTION_STRING! });

export const mastra = new Mastra({
  agents: { ragAgent },
  vectors: { pgVector }
});

const agent = mastra.getAgent("ragAgent");
```

----------------------------------------

TITLE: Configuring MCPServer to Expose an Agent as a Tool (TypeScript)
DESCRIPTION: This TypeScript snippet illustrates the configuration of an MCPServer instance to expose a Mastra Agent, 'generalHelper', as a callable tool. By including the agent in the 'agents' configuration, it becomes available as 'ask_generalHelper' to MCP clients, alongside other standard tools like 'weatherInfo'.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/using-tools-and-mcp.mdx#_snippet_6

LANGUAGE: TypeScript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { MCPServer } from "@mastra/mcp";
import { openai } from "@ai-sdk/openai";
import { weatherInfo } from "../tools/weatherInfo";
import { generalHelper } from "../agents/generalHelper";

const server = new MCPServer({
  name: "My Custom Server with Agent-Tool",
  version: "1.0.0",
  tools: {
    weatherInfo,
  },
  agents: { generalHelper }, // Exposes 'ask_generalHelper' tool
});
```

----------------------------------------

TITLE: Defining Mastra Workflow and Synthesis Step in TypeScript
DESCRIPTION: This snippet defines the `activityPlanningWorkflow` using `createWorkflow`, outlining its input/output schemas and step sequence. It also includes the `execute` logic for the `synthesizeStep`, which dynamically generates a prompt based on previous activity plans and streams a response from an AI agent.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows_vNext/parallel-steps.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
  }),
  execute: async ({ inputData, mastra }) => {
    const indoorActivities = inputData?.['plan-indoor-activities']
    const outdoorActivities = inputData?.['plan-activities']
 
    const prompt = `室内アクティビティ:
      ${indoorActivities?.activities}
 
      屋外アクティビティ:
      ${outdoorActivities?.activities}
 
      雨が降る可能性があるので、必要に応じて室内アクティビティを行う準備をしておいてください。`
 
    const agent = mastra?.getAgent('synthesizeAgent')
    if (!agent) {
      throw new Error('Synthesize agent not found')
    }
 
    const response = await agent.stream([
      {
        role: "user",
        content: prompt,
      },
    ])
 
    let activitiesText = ''

    for await (const chunk of response.textStream) {
      process.stdout.write(chunk);
      activitiesText += chunk;
    }
 
    return {
      activities: activitiesText,
    };
  },
})
 
const activityPlanningWorkflow = createWorkflow({
  id: 'plan-both-workflow',
  inputSchema: z.object({
    city: z.string(),
  }),
  outputSchema: z.object({
    activities: z.string(),
  }),
  steps: [fetchWeather, planActivities, planIndoorActivities, synthesizeStep]
})
  .then(fetchWeather)
  .parallel([planActivities, planIndoorActivities])
  .then(synthesizeStep)
  .commit()
 
export { activityPlanningWorkflow }
```

----------------------------------------

TITLE: Configuring RAG Agent with Qdrant Prompt (TypeScript)
DESCRIPTION: This snippet demonstrates how to configure a RAG agent to work with Qdrant by importing `QDRANT_PROMPT` from `@mastra/qdrant` and embedding it into the agent's instructions. This prompt defines the specific query patterns and filtering syntax for Qdrant, ensuring the agent can effectively process queries and leverage the database's capabilities. It requires `@ai-sdk/openai` for the model and `@mastra/qdrant` for the prompt.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/retrieval.mdx#_snippet_10

LANGUAGE: TypeScript
CODE:
```
import { openai } from '@ai-sdk/openai';
import { QDRANT_PROMPT } from "@mastra/qdrant";

export const ragAgent = new Agent({
  name: 'RAG Agent',
  model: openai('gpt-4o-mini'),
  instructions: `
  Process queries using the provided context. Structure responses to be concise and relevant.
  ${QDRANT_PROMPT}
  `,
  tools: { vectorQueryTool },
});
```

----------------------------------------

TITLE: Importing Core Dependencies for Mastra RAG
DESCRIPTION: Details the required imports for a Mastra RAG application, including 'embed' from 'ai' for embedding generation, 'PgVector' from '@mastra/pg' for PostgreSQL vector store interaction, and 'openai' from '@ai-sdk/openai' for OpenAI model integration.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/query/hybrid-vector-search.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { embed } from "ai";
import { PgVector } from "@mastra/pg";
import { openai } from "@ai-sdk/openai";
```

----------------------------------------

TITLE: Prompt Alignment Metric Examples and Analysis (TypeScript)
DESCRIPTION: This section provides two examples of using `PromptAlignmentMetric` to evaluate LLM outputs. The first example illustrates a perfect score (1.0) when all instructions are strictly followed. The second example demonstrates a lower score (0.33) due to multiple instruction violations, such as incorrect formatting, missing punctuation, and an incorrect number of items, along with the detailed reason provided by the metric.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/prompt-alignment.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { PromptAlignmentMetric } from "@mastra/evals/llm";

// Configure the model for evaluation
const model = openai("gpt-4o-mini");

const metric = new PromptAlignmentMetric(model, {
  instructions: [
    "Use bullet points for each item",
    "Include exactly three examples",
    "End each point with a semicolon"
  ],
  scale: 1
});

const result = await metric.measure(
  "List three fruits",
  "• Apple is red and sweet;
• Banana is yellow and curved;
• Orange is citrus and round."
);

// Example output:
// {
//   score: 1.0,
//   info: {
//     reason: "The score is 1.0 because all instructions were followed exactly:
//           bullet points were used, exactly three examples were provided, and
//           each point ends with a semicolon."
//   }
// }

const result2 = await metric.measure(
  "List three fruits",
  "1. Apple
2. Banana
3. Orange and Grape"
);

// Example output:
// {
//   score: 0.33,
//   info: {
//     reason: "The score is 0.33 because: numbered lists were used instead of bullet points,
//           no semicolons were used, and four fruits were listed instead of exactly three."
//   }
// }
```

----------------------------------------

TITLE: Transcribing Audio with OpenAI STT in TypeScript
DESCRIPTION: This snippet demonstrates how to set up a Mastra AI `Agent` with OpenAI's voice provider to transcribe an audio file to text. It reads an audio stream from a local file, converts it to text using the `listen` method, and then generates a text response based on the transcript. This requires `@mastra/core/agent`, `@ai-sdk/openai`, and `@mastra/voice-openai`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#_snippet_11

LANGUAGE: typescript
CODE:
```
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';
import { OpenAIVoice } from "@mastra/voice-openai";
import { createReadStream } from 'fs';

const voiceAgent = new Agent({
name: "Voice Agent",
instructions: "You are a voice assistant that can help users with their tasks.",
model: openai("gpt-4o"),
voice: new OpenAIVoice(),
});

// Use an audio file from a URL
const audioStream = await createReadStream("./how_can_i_help_you.mp3");

// Convert audio to text
const transcript = await voiceAgent.voice.listen(audioStream);
console.log(`User said: ${transcript}`);

// Generate a response based on the transcript
const { text } = await voiceAgent.generate(transcript);
```

----------------------------------------

TITLE: Performing Basic Semantic Search with Mastra and OpenAI (TypeScript)
DESCRIPTION: This snippet demonstrates how to perform a basic semantic search using Mastra's PgVector and OpenAI embeddings. It converts a user query into an embedding, queries a PostgreSQL vector store for semantically similar chunks, and then displays the retrieved results. This process is fundamental for finding relevant information based on query meaning.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/retrieval.mdx#_snippet_0

LANGUAGE: ts
CODE:
```
import { openai } from "@ai-sdk/openai";
import { embed } from "ai";
import { PgVector } from "@mastra/pg";

// Convert query to embedding
const { embedding } = await embed({
  value: "What are the main points in the article?",
  model: openai.embedding("text-embedding-3-small"),
});

// Query vector store
const pgVector = new PgVector({ connectionString: process.env.POSTGRES_CONNECTION_STRING });
const results = await pgVector.query({
  indexName: "embeddings",
  queryVector: embedding,
  topK: 10,
});

// Display results
console.log(results);
```

----------------------------------------

TITLE: Forwarding Abort Signal to Mastra Tool (TypeScript)
DESCRIPTION: Shows how to pass an `abortSignal` when calling `agent.generate`. The signal is automatically made available in the tool's `execute` function context and can be forwarded to asynchronous operations like `fetch` to allow cancellation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-tools.mdx#_snippet_3

LANGUAGE: typescript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { createTool } from "@mastra/core/tools";
import { z } from "zod";

const agent = new Agent({
  name: "Weather agent",
  tools: {
    weather: createTool({
      id: "Get Weather Information",
      description: "Get the weather in a location",
      inputSchema: z.object({ location: z.string() }),
      execute: async ({ context: { location } }, { abortSignal }) => {
        return fetch(
          `https://api.weatherapi.com/v1/current.json?q=${location}`,
          { signal: abortSignal }, // forward the abort signal to fetch
        );
      },
    }),
  },
});

const result = await agent.generate("What is the weather in San Francisco?", {
  abortSignal: myAbortSignal, // signal that will be forwarded to tools
});
```

----------------------------------------

TITLE: Defining Activity Planner Workflow with Mastra and Inngest (TypeScript)
DESCRIPTION: This snippet defines an 'activityPlanningWorkflow' using Mastra's 'createWorkflow' function. It specifies input and output schemas and implements conditional branching logic based on 'precipitationChance' to suggest either indoor or mixed activities, integrating with external functions like 'fetchWeather', 'planIndoorActivities', and 'planActivities'.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/inngest-workflow.mdx#_snippet_6

LANGUAGE: TypeScript
CODE:
```
const activityPlanningWorkflow = createWorkflow({
  id: 'activity-planning-workflow-step2-if-else',
  inputSchema: z.object({
    city: z.string().describe('The city to get the weather for'),
  }),
  outputSchema: z.object({
    activities: z.string(),
  }),
})
  .then(fetchWeather)
  .branch([
    [
      // If precipitation chance is greater than 50%, suggest indoor activities
      async ({ inputData }) => {
        return inputData?.precipitationChance > 50
      },
      planIndoorActivities,
    ],
    [
      // Otherwise, suggest a mix of activities
      async ({ inputData }) => {
        return inputData?.precipitationChance <= 50
      },
      planActivities,
    ],
  ])
 
activityPlanningWorkflow.commit()
 
export { activityPlanningWorkflow }
```

----------------------------------------

TITLE: Implementing Chain of Thought Prompting in Mastra (TypeScript)
DESCRIPTION: This snippet demonstrates how to implement chain of thought prompting in Mastra, guiding the model to break down complex problems into a series of logical steps. By defining `thinking` steps and enabling `autoChainOfThought`, the model is encouraged to show its reasoning process, as shown in a math word problem solver example.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/examples.md#_snippet_2

LANGUAGE: typescript
CODE:
```
type WordProblemVars = {
  problem: string;
};

const mathSolver = createPrompt<WordProblemVars>('Solve word problem', {
  persona: 'Math Teacher',
  outputFormat: 'markdown',
})
  .text('Solve this word problem:\n\n{{problem}}')
  .thinking({
    autoChainOfThought: true,
    steps: [
      'Read and understand the problem',
      'Identify important information',
      'Choose the right operation',
      'Solve step by step',
      'Check the answer',
    ],
  });

// Usage example
const solution = mathSolver.toString({
  problem: 'If a store sells 12 apples per hour and is open for 8 hours, how many apples do they sell in a day?',
});
```

----------------------------------------

TITLE: Defining README Generator Workflow (TypeScript)
DESCRIPTION: This is the primary workflow definition that orchestrates the entire README generation process. It sequentially executes the 'cloneRepositoryStep' and 'selectFolderStep', then iterates over 'generateSummaryWorkflow' for each selected file, and finally combines all generated documentation using 'collateDocumentationStep'. It defines the overall input (repository URL) and output structure for the workflow.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows_vNext/array-as-input.mdx#_snippet_3

LANGUAGE: TypeScript
CODE:
```
const readmeGeneratorWorkflow = createWorkflow({
  id: "readme-generator",
  inputSchema: z.object({
    repoUrl: z.string(),
  }),
  outputSchema: z.object({
    success: z.boolean(),
    message: z.string(),
    data: z.object({
      repoUrl: z.string(),
    }),
  }),
  steps: [cloneRepositoryStep, selectFolderStep, generateSummaryWorkflow, collateDocumentationStep],
})
  .then(cloneRepositoryStep)
  .then(selectFolderStep)
  .foreach(generateSummaryWorkflow)
  .then(collateDocumentationStep)
  .commit();

export { readmeGeneratorWorkflow };
```

----------------------------------------

TITLE: Defining `planActivities` Workflow Step (TypeScript)
DESCRIPTION: The `planActivities` step takes weather data as input and suggests activities based on temperature and conditions. It defines its input and output schemas using `zod` and includes logic to recommend different activities for sunny/warm, cold, or moderate weather. This step demonstrates conditional logic within a workflow.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/using-with-agents-and-tools.mdx#_snippet_4

LANGUAGE: TypeScript
CODE:
```
const planActivities = createStep({
  id: "plan-activities",
  inputSchema: z.object({
    temperature: z.number(),
    conditions: z.string(),
    city: z.string()
  }),
  outputSchema: z.object({
    activities: z.array(z.string())
  }),
  execute: async ({ inputData }) => {
    mastra.getLogger()?.debug(`Planning activities for ${inputData.city} based on weather`);
    const activities = [];
    
    if (inputData.temperature > 20 && inputData.conditions === "Sunny") {
      activities.push("Visit the park", "Go hiking", "Have a picnic");
    } else if (inputData.temperature < 10) {
      activities.push("Visit a museum", "Go to a cafe", "Indoor shopping");
    } else {
      activities.push("Sightseeing tour", "Visit local attractions", "Try local cuisine");
    }
    return {
      activities
    };
  }
});
```

----------------------------------------

TITLE: Initializing Mastra Project with Yarn - Bash
DESCRIPTION: This command sequence initializes a new Node.js project using Yarn, installs essential development dependencies like TypeScript and tsx, and then adds core Mastra packages along with zod and @ai-sdk/openai for AI functionalities. This prepares the project environment for development.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_6

LANGUAGE: bash
CODE:
```
yarn init -y

yarn add typescript tsx @types/node mastra@latest --dev

yarn add @mastra/core@latest zod @ai-sdk/openai
```

----------------------------------------

TITLE: Adding a Tool to a Mastra Agent (TypeScript)
DESCRIPTION: Creates a Mastra `Agent` instance named `weatherAgent`. This agent is configured with specific instructions for providing weather information and is explicitly linked to the `weatherInfo` tool defined previously. It uses the `openai` model.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-tools.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";
import * as tools from "../tools/weatherInfo";

export const weatherAgent = new Agent<typeof tools>({
  name: "Weather Agent",
  instructions:
    "You are a helpful assistant that provides current weather information. When asked about the weather, use the weather information tool to fetch the data.",
  model: openai("gpt-4o-mini"),
  tools: {
    weatherInfo: tools.weatherInfo,
  },
});
```

----------------------------------------

TITLE: Initializing Mem0 Integration and Custom Tools for Mastra Agent (TypeScript)
DESCRIPTION: This snippet initializes the Mem0 integration, defines two custom tools (`mem0RememberTool` and `mem0MemorizeTool`) for memory management, and creates a Mastra `Agent` configured with these tools. It demonstrates how to integrate external memory services like Mem0 into an AI agent system, allowing the agent to explicitly save and recall information.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-with-mem0.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { Mem0Integration } from '@mastra/mem0';
import { createTool } from '@mastra/core/tools';
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

// Initialize Mem0 integration
const mem0 = new Mem0Integration({
  config: {
    apiKey: process.env.MEM0_API_KEY || '',
    user_id: 'alice', // Unique user identifier
  },
});

// Create memory tools
const mem0RememberTool = createTool({
  id: 'Mem0-remember',
  description: "Remember your agent memories that you've previously saved using the Mem0-memorize tool.",
  inputSchema: z.object({
    question: z.string().describe('Question used to look up the answer in saved memories.'),
  }),
  outputSchema: z.object({
    answer: z.string().describe('Remembered answer'),
  }),
  execute: async ({ context }) => {
    console.log(`Searching memory "${context.question}"`);
    const memory = await mem0.searchMemory(context.question);
    console.log(`\nFound memory "${memory}"\n`);

    return {
      answer: memory,
    };
  },
});

const mem0MemorizeTool = createTool({
  id: 'Mem0-memorize',
  description: 'Save information to mem0 so you can remember it later using the Mem0-remember tool.',
  inputSchema: z.object({
    statement: z.string().describe('A statement to save into memory'),
  }),
  execute: async ({ context }) => {
    console.log(`\nCreating memory "${context.statement}"\n`);
    // To reduce latency, memories can be saved async without blocking tool execution
    void mem0.createMemory(context.statement).then(() => {
      console.log(`\nMemory "${context.statement}" saved.\n`);
    });
    return { success: true };
  },
});

// Create an agent with memory tools
const mem0Agent = new Agent({
  name: 'Mem0 Agent',
  instructions: `
    You are a helpful assistant that has the ability to memorize and remember facts using Mem0.
    Use the Mem0-memorize tool to save important information that might be useful later.
    Use the Mem0-remember tool to recall previously saved information when answering questions.
  `,
  model: openai('gpt-4o'),
  tools: { mem0RememberTool, mem0MemorizeTool },
});
```

----------------------------------------

TITLE: Registering Agents and Workflows with Mastra Instance (TypeScript)
DESCRIPTION: This code initializes the `Mastra` instance, registering the previously defined `activityPlanningWorkflow` and `planningAgent`. This registration is crucial for the workflow to access the agent and for the Mastra framework to manage and execute these components. A logger is also configured for monitoring.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/conditional-branching.mdx#_snippet_7

LANGUAGE: TypeScript
CODE:
```
import { Mastra } from '@mastra/core/mastra'
import { createLogger } from '@mastra/core/logger'
import { activityPlanningWorkflow } from './workflows/conditional-workflow'
import { planningAgent } from './agents/planning-agent'
 
// Initialize Mastra with the activity planning workflow
// This enables the workflow to be executed and access the planning agent
const mastra = new Mastra({
  workflows: {
    activityPlanningWorkflow
  },
  agents: {
    planningAgent
  },
  logger: createLogger({
    name: "Mastra",
    level: "info"
  })
})
 
export { mastra }
```

----------------------------------------

TITLE: Basic Usage of ContextRelevancyMetric in TypeScript
DESCRIPTION: Demonstrates the fundamental usage of the ContextRelevancyMetric class. It shows how to initialize the metric with an LLM and context, measure the relevancy between a query and response based on the provided context, and access the resulting score and explanation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/context-relevancy.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { ContextRelevancyMetric } from "@mastra/evals/llm";

// Configure the model for evaluation
const model = openai("gpt-4o-mini");

const metric = new ContextRelevancyMetric(model, {
  context: [
    "All data is encrypted at rest and in transit",
    "Two-factor authentication is mandatory",
    "The platform supports multiple languages",
    "Our offices are located in San Francisco",
  ],
});

const result = await metric.measure(
  "What are our product's security features?",
  "Our product uses encryption and requires 2FA.",
);

console.log(result.score); // Score from 0-1
console.log(result.info.reason); // Explanation of the relevancy assessment
```

----------------------------------------

TITLE: Evaluate High Relevancy | TypeScript
DESCRIPTION: Demonstrates evaluating a query and response pair where the response is highly relevant to the query using the configured `AnswerRelevancyMetric`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/answer-relevancy.mdx#_snippet_3

LANGUAGE: typescript
CODE:
```
const query1 = "What are the health benefits of regular exercise?";
const response1 =
  "Regular exercise improves cardiovascular health, strengthens muscles, boosts metabolism, and enhances mental well-being through the release of endorphins.";

console.log("Example 1 - High Relevancy:");
console.log("Query:", query1);
console.log("Response:", response1);

const result1 = await metric.measure(query1, response1);
console.log("Metric Result:", {
  score: result1.score,
  reason: result1.info.reason,
});
// Example Output:
// Metric Result: { score: 1, reason: 'The response is highly relevant to the query. It provides a comprehensive overview of the health benefits of regular exercise.' }
```

----------------------------------------

TITLE: Implementing Do-Until Loops in Mastra Workflows (TypeScript)
DESCRIPTION: This example demonstrates the `dountil` loop in Mastra workflows. The specified step (`incrementStep`) is executed repeatedly until the provided asynchronous condition evaluates to true. Similar to `dowhile`, the `inputData` for subsequent loop iterations is the output of the loop step itself, necessitating proper input data handling.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/flow-control.mdx#_snippet_5

LANGUAGE: TypeScript
CODE:
```
// Repeat incrementStep while value is more than 10
myWorkflow
  .dountil(incrementStep, async ({ inputData }) => inputData.value >= 10)
  .then(finalStep)
  .commit();
```

----------------------------------------

TITLE: Implementing Do-While Loops in Mastra Workflows (TypeScript)
DESCRIPTION: This snippet illustrates the `dowhile` loop construct in Mastra workflows. The specified step (`incrementStep`) is executed repeatedly as long as the provided asynchronous condition evaluates to true. The `inputData` for subsequent loop iterations is the output of the loop step itself, requiring careful consideration of initial state or mapping.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/flow-control.mdx#_snippet_4

LANGUAGE: TypeScript
CODE:
```
// Repeat incrementStep while value is less than 10
myWorkflow
  .dowhile(incrementStep, async ({ inputData }) => inputData.value < 10)
  .then(finalStep)
  .commit();
```

----------------------------------------

TITLE: Initializing Mastra Memory with Upstash and Agent
DESCRIPTION: This snippet initializes the Mastra memory system using Upstash for both storage and vector search, configuring options for message recall. It then creates an AI agent (`chefAgent`) with a specific persona and integrates the initialized memory system, using OpenAI's `gpt-4o-mini` model.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-with-upstash.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { Memory } from "@mastra/memory";
import { UpstashStore, UpstashVector } from "@mastra/upstash";
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";

// Initialize memory with Upstash storage and vector search
const memory = new Memory({
  storage: new UpstashStore({
    url: process.env.UPSTASH_REDIS_REST_URL,
    token: process.env.UPSTASH_REDIS_REST_TOKEN,
  }),
  vector: new UpstashVector({
    url: process.env.UPSTASH_REDIS_REST_URL,
    token: process.env.UPSTASH_REDIS_REST_TOKEN,
  }),
  options: {
    lastMessages: 10,
    semanticRecall: {
      topK: 3,
      messageRange: 2,
    },
  },
});

// Create an agent with memory capabilities
const chefAgent = new Agent({
  name: "chefAgent",
  instructions:
    "You are Michel, a practical and experienced home chef who helps people cook great meals with whatever ingredients they have available.",
  model: openai("gpt-4o-mini"),
  memory,
});
```

----------------------------------------

TITLE: Streaming Workflow Execution in TypeScript
DESCRIPTION: This snippet demonstrates how to initiate and stream the execution of a workflow. It first creates a run instance and then calls the `stream` method with input data. The result is an iterable stream, allowing for real-time processing of workflow events as they occur.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#_snippet_9

LANGUAGE: typescript
CODE:
```
const run = myWorkflow.createRun();

// Start the workflow
const result = run.stream({ inputData: {...} });

for (const chunk of result.stream) {
  // do something
}
```

----------------------------------------

TITLE: Initializing LibSQL Storage in TypeScript
DESCRIPTION: This TypeScript snippet demonstrates how to initialize the `LibSQLStore` for both development and production environments. It shows configuring a file-based database for local development using `file:./storage.db` and a persistent database for production by referencing an environment variable `process.env.DATABASE_URL` for the connection URL.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/libsql.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { LibSQLStore } from "@mastra/libsql";

// File database (development)
const storage = new LibSQLStore({
  url: "file:./storage.db"
});

// Persistent database (production)
const storage = new LibSQLStore({
  url: process.env.DATABASE_URL
});
```

----------------------------------------

TITLE: Invoking Mastra Agent with Default Dotenv Config (TypeScript)
DESCRIPTION: This TypeScript snippet demonstrates how to initialize and invoke a Mastra agent named 'weatherAgent'. It uses `dotenv/config` to automatically load environment variables from a default `.env` file, then calls the agent to generate a response for a specific query and logs the result.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_30

LANGUAGE: typescript
CODE:
```
import "dotenv/config";

import { mastra } from "./mastra";

async function main() {
  const agent = await mastra.getAgent("weatherAgent");

  const result = await agent.generate("What is the weather in London?");

  console.log("Agent response:", result.text);
}

main();
```

----------------------------------------

TITLE: Defining Mastra Agent with Voice and Tools in TypeScript
DESCRIPTION: This TypeScript snippet defines a Mastra agent named 'mastra' with real-time voice capabilities using OpenAI, specifies the GPT-4o model, and includes a simple 'salutationTool'. The tool demonstrates how to create and integrate custom logic into the agent.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/speech-to-speech.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { createTool } from "@mastra/core/tools";
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";
import { z } from "zod";

// Have the agent do something
export const speechToSpeechServer = new Agent({
  name: "mastra",
  instructions: "You are a helpful assistant.",
  voice: new OpenAIRealtimeVoice(),
  model: openai("gpt-4o"),
  tools: {
    salutationTool: createTool({
      id: "salutationTool",
      description: "Read the result of the tool",
      inputSchema: z.object({ name: z.string() }),
      outputSchema: z.object({ message: z.string() }),
      execute: async ({ context }) => {
        return { message: `Hello ${context.name}!` };
      },
    }),
  },
});
```

----------------------------------------

TITLE: Executing Nested Workflows in Parallel - TypeScript
DESCRIPTION: This snippet demonstrates parallel execution of entire nested workflows using `.parallel()`. Both `nestedWorkflow1` and `nestedWorkflow2` run concurrently, and upon their completion, the `finalStep` is executed, receiving an object containing the outputs of both nested workflows.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_8

LANGUAGE: typescript
CODE:
```
myWorkflow.parallel([nestedWorkflow1, nestedWorkflow2]).then(finalStep).commit();
```

----------------------------------------

TITLE: Processing Latest Message with Mastra Agent (Next.js API Route)
DESCRIPTION: This Next.js API route handles incoming chat requests, extracting the latest message, `threadId`, and `resourceId` from the request body. It initializes a Mastra `Agent` with `Memory` backed by `LibSQLStore` and then streams the response from the agent using only the latest message content, relying on Mastra's memory to manage the full conversation history.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/use-chat.mdx#_snippet_1

LANGUAGE: TypeScript
CODE:
```
// app/api/chat/route.ts (Next.js Example)
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { LibSQLStore } from "@mastra/libsql";
import { openai } from "@ai-sdk/openai";
import { CoreMessage } from "@mastra/core";

const agent = new Agent({
  name: "ChatAgent",
  instructions: "You are a helpful assistant.",
  model: openai("gpt-4o"),
  memory: new Memory({
    storage: new LibSQLStore({
      url: "file:../mastra.db", // Or your database URL
    }),
  })
});

export async function POST(request: Request) {
  // Get data structured by experimental_prepareRequestBody
  const { message, threadId, resourceId }: { message: CoreMessage | null; threadId: string; resourceId: string } = await request.json();

  // Handle cases where message might be null (e.g., initial load or error)
  if (!message || !message.content) {
    // Return an appropriate response or error
    return new Response("Missing message content", { status: 400 });
  }

  // Process with memory using the single message content
  const stream = await agent.stream(message.content, {
    threadId,
    resourceId,
    // Pass other message properties if needed, e.g., role
    // messageOptions: { role: message.role }
  });

  // Return the streaming response
  return stream.toDataStreamResponse();
}
```

----------------------------------------

TITLE: Defining a Custom Tool (TypeScript)
DESCRIPTION: Defines a custom tool using `createTool` with an ID, description, input schema (using Zod), and an asynchronous execute function for implementing the tool's logic.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/openai-realtime-api/README.md#_snippet_15

LANGUAGE: TypeScript
CODE:
```
export const menuTool = createTool({
  id: 'menuTool',
  description: 'Get menu items',
  inputSchema: z
    .object({
      query: z.string(),
    })
    .required(),
  execute: async ({ context }) => {
    // Implement menu search functionality
  },
});
```

----------------------------------------

TITLE: Use rerank Function Example | Mastra RAG | TypeScript
DESCRIPTION: Demonstrates how to use the `rerank` function. It shows importing necessary modules (`openai`, `rerank`), initializing a language model, and calling `rerank` with example vector search results, a query string, the model, and optional weights and topK parameters. Requires `@ai-sdk/openai` and `@mastra/rag` dependencies.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/rerank.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { rerank } from "@mastra/rag";

const model = openai("gpt-4o-mini");

const rerankedResults = await rerank(
  vectorSearchResults,
  "How do I deploy to production?",
  model,
  {
    weights: {
      semantic: 0.5,
      vector: 0.3,
      position: 0.2,
    },
    topK: 3,
  },
);
```

----------------------------------------

TITLE: Evaluate Low Relevancy - Mastra Evals - TypeScript
DESCRIPTION: Shows evaluating context relevancy when most of the provided context information is irrelevant to the query. It initializes the `ContextRelevancyMetric` with the context and an OpenAI model, then measures the relevancy score for a given query and response, resulting in a low score due to the high proportion of irrelevant context.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-relevancy.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
const context3 = [
  "The Great Barrier Reef is in Australia.",
  "Coral reefs need warm water to survive.",
  "Marine life depends on coral reefs.",
  "The capital of Australia is Canberra.",
];

const metric3 = new ContextRelevancyMetric(openai("gpt-4o-mini"), {
  context: context3,
});

const query3 = "What is the capital of Australia?";
const response3 = "The capital of Australia is Canberra.";

console.log("Example 3 - Low Relevancy:");
console.log("Context:", context3);
console.log("Query:", query3);
console.log("Response:", response3);

const result3 = await metric3.measure(query3, response3);
console.log("Metric Result:", {
  score: result3.score,
  reason: result3.info.reason,
});
// Example Output:
// Metric Result: { score: 0.12, reason: 'The context only has one relevant piece, while most of the context is irrelevant.' }
```

----------------------------------------

TITLE: Defining the Conclusion Drawing Workflow Step
DESCRIPTION: The `drawConclusions` step utilizes the `connections` from the prior step. It instructs the RAG agent to synthesize the information and draw conclusions, strictly based on the evidence found within the retrieved context, outputting these findings as a `conclusions` string.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#_snippet_8

LANGUAGE: typescript
CODE:
```
const drawConclusions = new Step({
  id: "drawConclusions",
  outputSchema: z.object({
    conclusions: z.string(),
  }),
  execute: async ({ context, mastra }) => {
    console.log("---------------------------");
    const ragAgent = mastra?.getAgent("ragAgent");
    const evidence = context?.getStepResult<{
      connections: string;
    }>("connectPieces")?.connections;
    const conclusionPrompt = `\n        Based on the connections: ${evidence}\n\n        4. Draw conclusions based only on the evidence in the retrieved context.\n    `;

    const conclusions = await ragAgent?.generate(conclusionPrompt);
    console.log(conclusions?.text);
    return {
      conclusions: conclusions?.text ?? "",
    };
  }
});
```

----------------------------------------

TITLE: Processing Text Documents into Chunks with Mastra
DESCRIPTION: This snippet demonstrates how to create a Mastra `MDocument` from raw text and then chunk it into smaller, manageable segments. The `recursive` strategy is used with specified `size`, `overlap`, and `separator` to optimize chunking for retrieval.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
const doc1 = MDocument.fromText(`
market data shows price resistance levels.
technical charts display moving averages.
support levels guide trading decisions.
breakout patterns signal entry points.
price action determines trade timing.
`);

const chunks = await doc1.chunk({
  strategy: "recursive",
  size: 150,
  overlap: 20,
  separator: "\n"
});
```

----------------------------------------

TITLE: Configuring Memory with Custom Storage, Vector Store, and Options - TypeScript
DESCRIPTION: This example illustrates a comprehensive custom configuration for the `Memory` class. It specifies `LibSQLStore` for conversation history and `LibSQLVector` for semantic search, both pointing to local database files. Additionally, it configures `lastMessages`, `semanticRecall` parameters (`topK`, `messageRange`), and enables `workingMemory` with a custom template, providing fine-grained control over memory behavior.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/memory/Memory.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { Memory } from "@mastra/memory";
import { LibSQLStore, LibSQLVector } from "@mastra/libsql";
import { Agent } from "@mastra/core/agent";

const memory = new Memory({
  // Optional storage configuration - libsql will be used by default
  storage: new LibSQLStore({
    url: "file:./memory.db",
  }),

// Optional vector database for semantic search
  vector: new LibSQLVector({
    url: "file:./vector.db",
  }),

  // Memory configuration options
  options: {
    // Number of recent messages to include
    lastMessages: 20,

    // Semantic search configuration
    semanticRecall: {
      topK: 3, // Number of similar messages to retrieve
      messageRange: {
        // Messages to include around each result
        before: 2,
        after: 1,
      },
    },

    // Working memory configuration
    workingMemory: {
      enabled: true,
      template: "\n# User\n- First Name:\n- Last Name:\n",
    },
  },
});

const agent = new Agent({
  memory,
  ...otherOptions,
});
```

----------------------------------------

TITLE: Fetching Weather Data with Inngest and Open-Meteo (TypeScript)
DESCRIPTION: This Inngest step, 'fetch-weather', retrieves current and hourly weather forecasts for a specified city. It first uses a geocoding API to get latitude and longitude, then fetches weather data from Open-Meteo, and finally processes the raw data into a structured forecast object, including temperature, precipitation, and weather conditions.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows_vNext/inngest-workflow.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
const fetchWeather = createStep({
  id: 'fetch-weather',
  description: 'Fetches weather forecast for a given city',
  inputSchema: z.object({
    city: z.string(),
  }),
  outputSchema: forecastSchema,
  execute: async ({ inputData }) => {
    if (!inputData) {
      throw new Error('Trigger data not found')
    }

    // Get latitude and longitude for the city
    const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(inputData.city)}&count=1`
    const geocodingResponse = await fetch(geocodingUrl)
    const geocodingData = (await geocodingResponse.json()) as {
      results: { latitude: number; longitude: number; name: string }[]
    }
 
    if (!geocodingData.results?.[0]) {
      throw new Error(`Location '${inputData.city}' not found`)
    }
 
    const { latitude, longitude, name } = geocodingData.results[0]

    // Fetch weather data using the coordinates
    const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=precipitation,weathercode&timezone=auto,&hourly=precipitation_probability,temperature_2m`
    const response = await fetch(weatherUrl)
    const data = (await response.json()) as {
      current: {
        time: string
        precipitation: number
        weathercode: number
      }
      hourly: {
        precipitation_probability: number[]
        temperature_2m: number[]
      }
    }
 
    const forecast = {
      date: new Date().toISOString(),
      maxTemp: Math.max(...data.hourly.temperature_2m),
      minTemp: Math.min(...data.hourly.temperature_2m),
      condition: getWeatherCondition(data.current.weathercode),
      location: name,
      precipitationChance: data.hourly.precipitation_probability.reduce(
        (acc, curr) => Math.max(acc, curr),
        0
      ),
    }
 
    return forecast
  }
})
```

----------------------------------------

TITLE: Initializing and Using DeepgramVoice for TTS and STT
DESCRIPTION: This comprehensive example demonstrates the initialization of the `DeepgramVoice` class with configurations for both speech synthesis and transcription models. It illustrates how to retrieve a list of available speakers, generate audio from text using the `speak` method with optional speaker and speed parameters, and convert an audio stream back into text using the `listen` method.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/deepgram/README.md#_snippet_2

LANGUAGE: typescript
CODE:
```
import { DeepgramVoice } from '@mastra/voice-deepgram';

// Create voice with both speech and listening capabilities
const voice = new DeepgramVoice({
  speechModel: {
    name: 'aura-asteria-en', // Default voice
    apiKey: 'your-api-key', // Optional, can use DEEPGRAM_API_KEY env var
  },
  listeningModel: {
    name: 'nova', // Optional, specify a listening model
    apiKey: 'your-api-key', // Optional, can use DEEPGRAM_API_KEY env var
  },
  speaker: 'aura-athena-en', // Optional, specify a speaker voice
});

// List available voices
const voices = await voice.getSpeakers();

// Generate speech
const audioStream = await voice.speak('Hello from Mastra!', {
  speaker: 'aura-athena-en', // Optional: override default speaker
  speed: 1.0, // Optional: adjust speech speed
});

// Convert speech to text
const text = await voice.listen(audioStream);
```

----------------------------------------

TITLE: Adding a Custom Tool to a Mastra OpenAI Realtime Voice Provider
DESCRIPTION: This example demonstrates how to define a tool using `createTool` with input/output schemas, initialize an `OpenAIRealtimeVoice` provider, and use the `addTools` method to make the custom tool available for the voice model to call during a conversation. It shows a simple weather lookup tool.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.addTools.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";
import { createTool } from "@mastra/core/tools";
import { z } from "zod";

// Define tools
const weatherTool = createTool({
  id: "getWeather",
  description: "Get the current weather for a location",
  inputSchema: z.object({
    location: z.string().describe("The city and state, e.g. San Francisco, CA"),
  }),
  outputSchema: z.object({
    message: z.string(),
  }),
  execute: async ({ context }) => {
    // Fetch weather data from an API
    const response = await fetch(
      `https://api.weather.com?location=${encodeURIComponent(context.location)}`,
    );
    const data = await response.json();
    return {
      message: `The current temperature in ${context.location} is ${data.temperature}°F with ${data.conditions}.`,
    };
  },
});

// Initialize a real-time voice provider
const voice = new OpenAIRealtimeVoice({
  realtimeConfig: {
    model: "gpt-4o-mini-realtime",
    apiKey: process.env.OPENAI_API_KEY,
  },
});

// Add tools to the voice provider
voice.addTools({
  getWeather: weatherTool,
});

// Connect to the real-time service
await voice.connect();
```

----------------------------------------

TITLE: Trigger AI Response with voice.answer() | Mastra Voice | TypeScript
DESCRIPTION: This snippet demonstrates how to initialize a real-time voice provider using `@mastra/voice-openai-realtime`, connect to the service, set up audio output with `@mastra/node-speaker`, send user audio input using `@mastra/node-audio`, and then explicitly trigger the AI to generate a response using the `voice.answer()` method. It requires environment variables for the OpenAI API key.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.answer.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";
import { getMicrophoneStream } from "@mastra/node-audio";
import Speaker from "@mastra/node-speaker";

const speaker = new Speaker({
  sampleRate: 24100, // Audio sample rate in Hz - standard for high-quality audio on MacBook Pro
  channels: 1, // Mono audio output (as opposed to stereo which would be 2)
  bitDepth: 16, // Bit depth for audio quality - CD quality standard (16-bit resolution)
});

// Initialize a real-time voice provider
const voice = new OpenAIRealtimeVoice({
  realtimeConfig: {
    model: "gpt-4o",
    apiKey: process.env.OPENAI_API_KEY,
  },
  speaker: "alloy", // Default voice
});
// Connect to the real-time service
await voice.connect();
// Register event listener for responses
voice.on("speaker", (stream) => {
  // Handle audio response
  stream.pipe(speaker);
});
// Send user audio input
const microphoneStream = getMicrophoneStream();
await voice.send(microphoneStream);
// Trigger the AI to respond
await voice.answer();
```

----------------------------------------

TITLE: Setting Up Real-time Speech-to-Speech Agent (TypeScript)
DESCRIPTION: Configures a Mastra agent with a real-time voice provider like `OpenAIRealtimeVoice` for interactive speech conversations. It covers initializing the provider, creating the agent with tools, establishing a WebSocket connection, sending speech output, streaming microphone input, and closing the connection.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-voice.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { getMicrophoneStream } from "@mastra/node-audio";
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";
import { search, calculate } from "../tools";

// Initialize the realtime voice provider
const voice = new OpenAIRealtimeVoice({
  apiKey: process.env.OPENAI_API_KEY,
  model: "gpt-4o-mini-realtime",
  speaker: "alloy",
});

// Create an agent with speech-to-speech voice capabilities
export const agent = new Agent({
  name: "Agent",
  instructions: `You are a helpful assistant with speech-to-speech capabilities.`,
  model: openai("gpt-4o"),
  tools: {
    // Tools configured on Agent are passed to voice provider
    search,
    calculate,
  },
  voice,
});

// Establish a WebSocket connection
await agent.voice.connect();

// Start a conversation
agent.voice.speak("Hello, I'm your AI assistant!");

// Stream audio from a microphone
const microphoneStream = getMicrophoneStream();
agent.voice.send(microphoneStream);

// When done with the conversation
agent.voice.close();
```

----------------------------------------

TITLE: Implementing Conditional Branching in Mastra Workflows (TypeScript)
DESCRIPTION: This snippet demonstrates creating conditional branches using the `.branch()` method. Branch conditions are evaluated sequentially, and all matching conditions will have their associated steps executed in parallel. The outputs from all executed conditional steps are collected into an object, with step IDs as keys, and passed as input to the subsequent step in the workflow.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows-vnext/flow-control.mdx#_snippet_3

LANGUAGE: typescript
CODE:
```
myWorkflow
  .then(initialStep)
  .branch([
    [async ({ inputData }) => inputData.value > 50, highValueStep],
    [
      async ({ inputData }) => inputData.value > 10 && inputData.value <= 50,
      lowValueStep,
    ],
    [async ({ inputData }) => inputData.value <= 10, extremelyLowValueStep]
  ])
  .then(finalStep)
  .commit();
```

----------------------------------------

TITLE: Mapping Various Input Sources in Mastra Workflow (TypeScript)
DESCRIPTION: This snippet demonstrates how to use the .map() method in a Mastra workflow to explicitly map input values for a subsequent step. It shows mapping from a previous step's output, a runtime context value, a constant value, and the initial workflow input. This allows for flexible data transformation and routing between workflow steps.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/input-data-mapping.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
myWorkflow
  .then(step1)
  .map({
    transformedValue: {
      step: step1,
      path: "nestedValue",
    },
    runtimeContextValue: {
      runtimeContextPath: "runtimeContextValue",
      schema: z.number(),
    },
    constantValue: {
      value: 42,
      schema: z.number(),
    },
    initDataValue: {
      initData: myWorkflow,
      path: "startValue",
    },
  })
  .then(step2)
  .commit();
```

----------------------------------------

TITLE: Configuring Agent Memory with Mastra Core
DESCRIPTION: This snippet illustrates how to integrate `Memory` with an `Agent` in Mastra. Memory provides persistent storage for AI interactions, enabling context-aware conversations. It allows configuring options like `lastMessages` and `semanticRecall` for enhanced recall.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/README.md#_snippet_3

LANGUAGE: typescript
CODE:
```
import { Memory } from '@mastra/memory';
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';

const agent = new Agent({
  name: 'Project Manager',
  instructions: 'You are a project manager assistant.',
  model: openai('gpt-4o-mini'),
  memory: new Memory({
    options: {
      lastMessages: 20,
      semanticRecall: {
        topK: 3,
        messageRange: { before: 2, after: 1 },
      },
    },
  }),
});
```

----------------------------------------

TITLE: Create Stock Price Tool | Mastra | TypeScript
DESCRIPTION: Defines a Mastra tool (`stockPrices`) using `createTool`. This tool fetches the last day's closing stock price for a given symbol by calling an external API. It uses `zod` to define the input schema.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/stock-agent.mdx#_snippet_4

LANGUAGE: TypeScript
CODE:
```
import { createTool } from "@mastra/core/tools";
import { z } from "zod";

const getStockPrice = async (symbol: string) => {
  const data = await fetch(
    `https://mastra-stock-data.vercel.app/api/stock-data?symbol=${symbol}`,
  ).then((r) => r.json());
  return data.prices["4. close"];
};

export const stockPrices = createTool({
  id: "Get Stock Price",
  inputSchema: z.object({
    symbol: z.string(),
  }),
  description: `Fetches the last day's closing stock price for a given symbol`,
  execute: async ({ context: { symbol } }) => {
    console.log("Using tool to fetch stock price for", symbol);
    return {
      symbol,
      currentPrice: await getStockPrice(symbol),
    };
  },
});
```

----------------------------------------

TITLE: Initializing Voice Agent with Cloudflare Voice in TypeScript
DESCRIPTION: This snippet demonstrates how to initialize a Mastra AI voice agent using the Cloudflare Voice provider. It configures the agent with a GPT-4o model, generates a text response, converts the text to an audio stream using Cloudflare's TTS, and then plays the audio.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#_snippet_6

LANGUAGE: typescript
CODE:
```
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';
import { CloudflareVoice } from "@mastra/voice-cloudflare";
import { playAudio } from "@mastra/node-audio";

const voiceAgent = new Agent({
  name: "Voice Agent",
  instructions: "You are a voice assistant that can help users with their tasks.",
  model: openai("gpt-4o"),
  voice: new CloudflareVoice(),
});

const { text } = await voiceAgent.generate('What color is the sky?');

// Convert text to speech to an Audio Stream
const audioStream = await voiceAgent.voice.speak(text, {
  speaker: "default" // Optional: specify a speaker
});

playAudio(audioStream);
```

----------------------------------------

TITLE: Configuring Sarvam Voice Agent for Audio to Text in TypeScript
DESCRIPTION: This example initializes a Mastra AI `Agent` with Sarvam as the voice provider. It demonstrates how to read an audio file, convert it to text using `voiceAgent.voice.listen()`, and then generate an AI response based on the transcribed text. Dependencies include `@mastra/core/agent`, `@ai-sdk/openai`, `@mastra/voice-sarvam`, and `fs`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#_snippet_18

LANGUAGE: typescript
CODE:
```
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';
import { SarvamVoice } from "@mastra/voice-sarvam";
import { createReadStream } from 'fs';

const voiceAgent = new Agent({
name: "Voice Agent",
instructions: "You are a voice assistant that can help users with their tasks.",
model: openai("gpt-4o"),
voice: new SarvamVoice(),
});

// Use an audio file from a URL
const audioStream = await createReadStream("./how_can_i_help_you.mp3");

// Convert audio to text
const transcript = await voiceAgent.voice.listen(audioStream);
console.log(`User said: ${transcript}`);

// Generate a response based on the transcript
const { text } = await voiceAgent.generate(transcript);
```

----------------------------------------

TITLE: Configuring Memory to Retain Last Messages (TypeScript)
DESCRIPTION: This TypeScript snippet demonstrates how to configure a `Memory` instance to include a specific number of recent messages in the agent's context. By setting `lastMessages: 10` within the `options`, the agent will automatically retrieve and utilize the last 10 messages from the current thread, providing immediate conversational context.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/overview.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
const memory = new Memory({
  options: {
    lastMessages: 10
  }
});
```

----------------------------------------

TITLE: Basic Usage of GraphRAG in TypeScript
DESCRIPTION: Demonstrates the basic steps to initialize the GraphRAG class, create a graph from document chunks and embeddings, and perform a query using default parameters.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/graph-rag.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { GraphRAG } from "@mastra/rag";

const graphRag = new GraphRAG({
  dimension: 1536,
  threshold: 0.7,
});

// Create the graph from chunks and embeddings
graphRag.createGraph(documentChunks, embeddings);

// Query the graph with embedding
const results = await graphRag.query({
  query: queryEmbedding,
  topK: 10,
  randomWalkSteps: 100,
  restartProb: 0.15,
});
```

----------------------------------------

TITLE: Initializing Agent with Working Memory (TypeScript)
DESCRIPTION: Demonstrates how to enable working memory for a Mastra AI agent by configuring the `Memory` options during agent initialization. This sets up the agent to maintain persistent user-specific information across interactions, acting as an active scratchpad for the agent.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/working-memory.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { openai } from "@ai-sdk/openai";

// Create agent with working memory enabled
const agent = new Agent({
  name: "PersonalAssistant",
  instructions: "You are a helpful personal assistant.",
  model: openai("gpt-4o"),
  memory: new Memory({
    options: {
      workingMemory: {
        enabled: true,
      },
    },
  }),
});
```

----------------------------------------

TITLE: Setting OpenAI API Key in .env File (Environment)
DESCRIPTION: This line demonstrates how to set the `OPENAI_API_KEY` environment variable within the `.env` file. Users must replace `sk-your-api-key-here` with their actual OpenAI API key to enable the application's access to OpenAI services.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/using-a-tool/README.md#_snippet_2

LANGUAGE: env
CODE:
```
OPENAI_API_KEY=sk-your-api-key-here
```

----------------------------------------

TITLE: Configuring Anthropic API Key in .env (Environment)
DESCRIPTION: This line demonstrates how to set the `ANTHROPIC_API_KEY` in the `.env` file. Users must replace `sk-your-api-key-here` with their actual Anthropic API key to enable communication with the Anthropic API for agent functionality.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/bird-checker/README.md#_snippet_2

LANGUAGE: env
CODE:
```
ANTHROPIC_API_KEY=sk-your-api-key-here
```

----------------------------------------

TITLE: Defining a Multi-Step User Interaction Workflow in TypeScript
DESCRIPTION: This snippet defines a comprehensive travel agent workflow using Mastra, integrating AI-driven suggestions, human input for selection, and subsequent travel plan generation. It demonstrates the use of `createStep` for individual workflow stages and `createWorkflow` to chain them, handling input/output schemas and agent interactions.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_41

LANGUAGE: TypeScript
CODE:
```
import { createWorkflow, createStep } from '@mastra/core/workflows/vNext';

import { z } from 'zod';

const generateSuggestionsStep = createStep({
  id: 'generate-suggestions',
  inputSchema: z.object({
    vacationDescription: z.string().describe('The description of the vacation'),
  }),
  outputSchema: z.object({
    suggestions: z.array(z.string()),
    vacationDescription: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    if (!mastra) {
      throw new Error('Mastra is not initialized');
    }

    const { vacationDescription } = inputData;
    const result = await mastra.getAgent('summaryTravelAgent').generate([
      {
        role: 'user',
        content: vacationDescription,
      },
    ]);
    console.log(result.text);
    return { suggestions: JSON.parse(result.text), vacationDescription };
  },
});

const humanInputStep = createStep({
  id: 'human-input',
  inputSchema: z.object({
    suggestions: z.array(z.string()),
    vacationDescription: z.string(),
  }),
  outputSchema: z.object({
    selection: z.string().describe('The selection of the user'),
    vacationDescription: z.string(),
  }),
  resumeSchema: z.object({
    selection: z.string().describe('The selection of the user'),
  }),
  suspendSchema: z.object({
    suggestions: z.array(z.string()),
  }),
  execute: async ({ inputData, resumeData, suspend }) => {
    if (!resumeData?.selection) {
      await suspend({ suggestions: inputData?.suggestions });
      return {
        selection: '',
        vacationDescription: inputData?.vacationDescription,
      };
    }

    return {
      selection: resumeData?.selection,
      vacationDescription: inputData?.vacationDescription,
    };
  },
});

const travelPlannerStep = createStep({
  id: 'travel-planner',
  inputSchema: z.object({
    selection: z.string().describe('The selection of the user'),
    vacationDescription: z.string(),
  }),
  outputSchema: z.object({
    travelPlan: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    const travelAgent = mastra?.getAgent('travelAgent');
    if (!travelAgent) {
      throw new Error('Travel agent is not initialized');
    }

    const { selection, vacationDescription } = inputData;
    const result = await travelAgent.generate([
      { role: 'assistant', content: vacationDescription },
      { role: 'user', content: selection || '' },
    ]);
    console.log(result.text);
    return { travelPlan: result.text };
  },
});

const travelAgentWorkflow = createWorkflow({
  id: 'travel-agent-workflow-step4-suspend-resume',
  inputSchema: z.object({
    vacationDescription: z.string().describe('The description of the vacation'),
  }),
  outputSchema: z.object({
    travelPlan: z.string(),
  }),
})
  .then(generateSuggestionsStep)
  .then(humanInputStep)
  .then(travelPlannerStep);

travelAgentWorkflow.commit();
```

----------------------------------------

TITLE: Defining Research Assistant Agent with Mastra (TypeScript)
DESCRIPTION: This TypeScript snippet defines the `researchAgent` using `@mastra/core/agent`. It integrates a `createVectorQueryTool` for semantic search over paper embeddings, leveraging OpenAI's `text-embedding-3-small` model. The agent is configured with specific instructions for analyzing academic papers and uses `gpt-4o-mini` for generating responses, ensuring answers are based solely on retrieved content.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/research-assistant.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";
import { createVectorQueryTool } from "@mastra/rag";

// Create a tool for semantic search over our paper embeddings
const vectorQueryTool = createVectorQueryTool({
  vectorStoreName: "pgVector",
  indexName: "papers",
  model: openai.embedding("text-embedding-3-small"),
});

export const researchAgent = new Agent({
  name: "Research Assistant",
  instructions: `You are a helpful research assistant that analyzes academic papers and technical documents.\n    Use the provided vector query tool to find relevant information from your knowledge base, \n    and provide accurate, well-supported answers based on the retrieved content.\n    Focus on the specific content available in the tool and acknowledge if you cannot find sufficient information to answer a question.\n    Base your responses only on the content provided, not on general knowledge.`,
  model: openai("gpt-4o-mini"),
  tools: {
    vectorQueryTool,
  },
});
```

----------------------------------------

TITLE: Generating and Storing Embeddings in PGVector (TypeScript)
DESCRIPTION: This snippet generates embeddings for the processed text chunks using OpenAI's `text-embedding-3-small` model via `embedMany`. It then retrieves the `pgVector` store, creates an index with the specified dimension, and finally upserts the generated embeddings along with their original text metadata into the vector database.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/graph-rag.mdx#_snippet_6

LANGUAGE: TypeScript
CODE:
```
const { embeddings } = await embedMany({
  model: openai.embedding("text-embedding-3-small"),
  values: chunks.map((chunk) => chunk.text),
});

const vectorStore = mastra.getVector("pgVector");
await vectorStore.createIndex({
  indexName: "embeddings",
  dimension: 1536,
});
await vectorStore.upsert({
  indexName: "embeddings",
  vectors: embeddings,
  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),
});
```

----------------------------------------

TITLE: Integrating Chat with useChat Hook (TypeScript/React)
DESCRIPTION: Shows a React component using the `@ai-sdk/react` `useChat` hook to manage chat state, handle user input, submit messages, and display the conversation history, connecting to a backend API endpoint.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/ai-sdk.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
import { useChat } from '@ai-sdk/react';

export function ChatComponent() {
  const { messages, input, handleInputChange, handleSubmit } = useChat({
    api: '/path-to-your-agent-stream-api-endpoint'
  });

  return (
    <div>
      {messages.map(m => (
        <div key={m.id}>
          {m.role}: {m.content}
        </div>
      ))}
      <form onSubmit={handleSubmit}>
        <input
          value={input}
          onChange={handleInputChange}
          placeholder="Say something..."
        />
      </form>
    </div>
  );
}
```

----------------------------------------

TITLE: Evaluating Mixed Bias Response using Mastra Bias Metric (TypeScript)
DESCRIPTION: Shows how to evaluate a response containing subtle age-related stereotypes using the `BiasMetric`. It defines a query and response, measures the bias, and logs the result, illustrating a score indicating moderate bias (expected 0.7).
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/bias.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
const query2 = "How do different age groups perform at work?";
const response2 =
  "Younger workers tend to be more innovative and quick to adapt, though they can be somewhat unreliable and job-hop frequently. Older employees are generally more stable and experienced, but sometimes struggle to keep up with rapid changes in technology. Middle-aged workers often provide the best balance of skills and reliability.";

console.log("Example 2 - Mixed Bias:");
console.log("Query:", query2);
console.log("Response:", response2);

const result2 = await metric.measure(query2, response2);
console.log("Metric Result:", {
  score: result2.score,
  reason: result2.info.reason,
});
```

----------------------------------------

TITLE: Collating Generated Documentation into README in TypeScript
DESCRIPTION: This step takes an array of file paths and their generated documentation as input. It uses the `docGeneratorAgent` to combine all provided documentation into a single, comprehensive README.md file. The output is the complete README content as a string. It relies on an external `docGeneratorAgent` for the actual README generation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/array-as-input.mdx#_snippet_5

LANGUAGE: TypeScript
CODE:
```
const collateDocumentationStep = createStep({
  id: "collate_documentation",
  inputSchema: z.array(
    z.object({
      path: z.string(),
      documentation: z.string(),
    }),
  ),
  outputSchema: z.string(),
  execute: async ({ inputData }) => {
    const readme = await docGeneratorAgent.generate(
      `Generate a README.md file for the following documentation: ${inputData.map((doc) => doc.documentation).join("\n")}`,
    );

    return readme.text.toString();
  },
});
```

----------------------------------------

TITLE: Executing Chain-of-Thought Queries with Mastra Agent
DESCRIPTION: This code demonstrates how to interact with the configured `ragAgent` by sending various natural language queries. It calls `agent.generate()` for each question, expecting the agent to apply its chain-of-thought reasoning based on the retrieved context. The queries cover different aspects of the document, and the responses, including the agent's thought process, are logged to the console, showcasing the RAG system's capabilities.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-rag.mdx#_snippet_7

LANGUAGE: typescript
CODE:
```
const answerOne = await agent.generate(
  "What are the main adaptation strategies for farmers?"
);
console.log("\nQuery:", "What are the main adaptation strategies for farmers?");
console.log("Response:", answerOne.text);

const answerTwo = await agent.generate(
  "Analyze how temperature affects crop yields."
);
console.log("\nQuery:", "Analyze how temperature affects crop yields.");
console.log("Response:", answerTwo.text);

const answerThree = await agent.generate(
  "What connections can you draw between climate change and food security?"
);
console.log(
  "\nQuery:",
  "What connections can you draw between climate change and food security?"
);
console.log("Response:", answerThree.text);
```

----------------------------------------

TITLE: Generating and Storing Embeddings in PgVector
DESCRIPTION: This snippet generates vector `embeddings` for the processed text chunks using OpenAI's `text-embedding-3-small` model. It then retrieves the `pgVector` store, creates an `embeddings` index with a dimension of 1536 if it doesn't exist, and finally `upsert`s the generated embeddings along with their original text as metadata into the database.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank-rag.mdx#_snippet_6

LANGUAGE: typescript
CODE:
```
const { embeddings } = await embedMany({
  model: openai.embedding("text-embedding-3-small"),
  values: chunks.map((chunk) => chunk.text)
});

const vectorStore = mastra.getVector("pgVector");
await vectorStore.createIndex({
  indexName: "embeddings",
  dimension: 1536
});

await vectorStore.upsert({
  indexName: "embeddings",
  vectors: embeddings,
  metadata: chunks?.map((chunk: any) => ({ text: chunk.text }))
});
```

----------------------------------------

TITLE: Generate Structured Data with Zod (TypeScript)
DESCRIPTION: Illustrates how to guide the agent to generate structured output (a recipe) by providing a Zod schema. The agent's response is parsed into a JavaScript object matching the schema.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/chef-michel.mdx#_snippet_6

LANGUAGE: ts
CODE:
```
import { z } from "zod";

async function main() {
  const query =
    "I want to make lasagna, can you generate a lasagna recipe for me?";
  console.log(`Query: ${query}`);

  // Define the Zod schema
  const schema = z.object({
    ingredients: z.array(
      z.object({
        name: z.string(),
        amount: z.string(),
      }),
    ),
    steps: z.array(z.string()),
  });

  const response = await chefAgent.generate(
    [{ role: "user", content: query }],
    { output: schema },
  );
  console.log("\n👨‍🍳 Chef Michel:", response.object);
}

main();
```

----------------------------------------

TITLE: Configuring OpenAI API Key - Environment Variable
DESCRIPTION: This line demonstrates how to set the OPENAI_API_KEY in the .env file. Users must replace 'sk-your-api-key-here' with their actual OpenAI API key to authenticate API requests.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/bias/README.md#_snippet_2

LANGUAGE: env
CODE:
```
OPENAI_API_KEY=sk-your-api-key-here
```

----------------------------------------

TITLE: Setting Environment Variables for OpenAI API (Bash)
DESCRIPTION: This snippet shows how to set the OPENAI_API_KEY environment variable in a .env file. This key is required to authenticate with the OpenAI API, which is used by the Faithfulness metric for evaluation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/faithfulness.mdx#_snippet_0

LANGUAGE: bash
CODE:
```
OPENAI_API_KEY=your_api_key_here
```

----------------------------------------

TITLE: Creating `activityPlannerTool` from Workflow (TypeScript)
DESCRIPTION: This code creates a Mastra tool, `activityPlannerTool`, which encapsulates the `weatherWorkflow`. Agents can invoke this tool to get weather-specific activities. The `execute` function retrieves the `weatherWorkflow` from the Mastra instance, runs it with the provided city, and returns the resulting activities, handling potential workflow execution failures.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/using-with-agents-and-tools.mdx#_snippet_6

LANGUAGE: TypeScript
CODE:
```
const activityPlannerTool = createTool({
  id: "get-weather-specific-activities",
  description: "Get weather-specific activities for a city based on current weather conditions",
  inputSchema: z.object({
    city: z.string().describe("The city to get activities for")
  }),
  outputSchema: z.object({
    activities: z.array(z.string())
  }),
  execute: async ({ context: { city }, mastra }) => {
    mastra.getLogger()?.debug(`Tool executing for city: ${city}`);
    
    const workflow = mastra?.getWorkflow("weatherWorkflow");
    if (!workflow) {
      throw new Error("Weather workflow not found");
    }
    
    const run = workflow.createRun();
    const result = await run.start({
      inputData: {
        city: city
      }
    });
    
    if (result.status === "success") {
      return {
        activities: result.result.activities
      };
    }
    
    throw new Error(`Workflow execution failed: ${result.status}`);
  }
});
```

----------------------------------------

TITLE: Environment Setup: .env
DESCRIPTION: Configure necessary environment variables, specifically the OpenAI API key, for running the evaluation examples. This key is required for the Contextual Recall metric to interact with the specified OpenAI model.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/contextual-recall.mdx#_snippet_0

LANGUAGE: bash
CODE:
```
OPENAI_API_KEY=your_api_key_here
```

----------------------------------------

TITLE: Defining Tool using Vercel AI SDK Format | ai Package | TypeScript
DESCRIPTION: Shows how to define a tool using the `tool` function from the `@vercel/ai` package, including specifying its description, parameters with Zod, and the asynchronous `execute` function.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/tools-mcp/advanced-usage.mdx#_snippet_3

LANGUAGE: typescript
CODE:
```
import { tool } from "ai";
import { z } from "zod";

export const vercelWeatherTool = tool({
  description: "Fetches current weather using Vercel AI SDK format",
  parameters: z.object({
    city: z.string().describe("The city to get weather for"),
  }),
  execute: async ({ city }) => {
    console.log(`Fetching weather for ${city} (Vercel format tool)`);
    // Replace with actual API call
    const data = await fetch(`https://api.example.com/weather?city=${city}`);
    return data.json();
  },
});
```

----------------------------------------

TITLE: Setting OpenAI API Key in Environment File (Env)
DESCRIPTION: This line demonstrates how to add your OpenAI API key to the `.env` file. This key is essential for authenticating requests to the OpenAI API, which is used by the Mastra example.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/answer-relevancy/README.md#_snippet_2

LANGUAGE: env
CODE:
```
OPENAI_API_KEY=sk-your-api-key-here
```

----------------------------------------

TITLE: Defining an Increment Workflow Step (TypeScript)
DESCRIPTION: Defines a reusable workflow step named 'increment' using `createStep`, initialized from the Inngest client. This step takes a number as input, increments its value by one, and returns the new value, utilizing Zod for robust input and output schema validation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/inngest-workflow.mdx#_snippet_2

LANGUAGE: ts
CODE:
```
import { z } from 'zod'
import { inngest } from '../inngest'
import { init } from '@mastra/inngest'

// Initialize Inngest with Mastra, pointing to your local Inngest server
const { createWorkflow, createStep } = init(inngest)

// Step: Increment the counter value
const incrementStep = createStep({
  id: 'increment',
  inputSchema: z.object({
    value: z.number(),
  }),
  outputSchema: z.object({
    value: z.number(),
  }),
  execute: async ({ inputData }) => {
    return { value: inputData.value + 1 }
  },
})
```

----------------------------------------

TITLE: Defining and Serving Mastra Workflows and Steps with Inngest in TypeScript
DESCRIPTION: This comprehensive TypeScript example illustrates the integration of Mastra with Inngest. It shows how to initialize Inngest, define individual workflow steps with input/output schemas using Zod, construct a complex workflow with conditional execution (`dountil`), and finally configure and export the Mastra server to expose the Inngest API endpoint.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/workflows/README.md#_snippet_1

LANGUAGE: typescript
CODE:
```
import { init } from '@mastra/inngest';
import { PinoLogger } from '@mastra/loggers';
import { Inngest, serve as inngestServe } from 'inngest';
import { z } from 'zod';

const { createWorkflow, createStep } = init(
  new Inngest({
    id: 'mastra',
    baseUrl: `http://localhost:8288`, // if using local dev server
  }),
);

const incrementStep = createStep({
  id: 'increment',
  inputSchema: z.object({
    value: z.number(),
  }),
  outputSchema: z.object({
    value: z.number(),
  }),
  execute: async ({ inputData }) => {
    return { value: inputData.value + 1 };
  },
});

const sideEffectStep = createStep({
  id: 'side-effect',
  inputSchema: z.object({
    value: z.number(),
  }),
  outputSchema: z.object({
    value: z.number(),
  }),
  execute: async ({ inputData }) => {
    console.log('log', inputData.value);
    return { value: inputData.value };
  },
});

const finalStep = createStep({
  id: 'final',
  inputSchema: z.object({
    value: z.number(),
  }),
  outputSchema: z.object({
    value: z.number(),
  }),
  execute: async ({ inputData }) => {
    return { value: inputData.value };
  },
});

const workflow = createWorkflow({
  id: 'increment-workflow',
  inputSchema: z.object({
    value: z.number(),
  }),
  outputSchema: z.object({
    value: z.number(),
  }),
})
  .dountil(
    createWorkflow({
      id: 'increment-subworkflow',
      inputSchema: z.object({
        value: z.number(),
      }),
      outputSchema: z.object({
        value: z.number(),
      }),
      steps: [incrementStep, sideEffectStep],
    })
      .then(incrementStep)
      .then(sideEffectStep)
      .commit(),
    async ({ inputData }) => inputData.value >= 10,
  )
  .then(finalStep)
  .commit();

export const mastra = new Mastra({
  vnext_workflows: {
    incrementWorkflow: workflow
  },
  server: {
    host: '0.0.0.0',
    apiRoutes: [
      {
        path: '/inngest/api', // this needs to match the path in inngest dev server (or production) config
        method: 'ALL',
        createHandler: async ({ mastra }) => inngestServe({ mastra, inngest: new Inngest({ id: 'mastra', baseUrl: `http://localhost:8288` }) }),
      },
    ],
  },
  logger: new PinoLogger({
    name: 'Mastra',
    level: 'info',
  }),
});
```

----------------------------------------

TITLE: Implementing AI Debate Interface with Mastra.js in Next.js
DESCRIPTION: This Next.js component (`DebateInterface.tsx`) provides a user interface for an AI debate. It initializes the Mastra client, manages debate state (topic, turns, responses, audio playback), and orchestrates turn-based communication between two AI agents ('optimistAgent' and 'skepticAgent'). It also includes functionality to convert agent responses into speech using Mastra's voice API.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/turn-taking.mdx#_snippet_4

LANGUAGE: TypeScript
CODE:
```
"use client";

import { useState, useRef } from "react";
import { MastraClient } from "@mastra/client-js";

const mastraClient = new MastraClient({
  baseUrl: process.env.NEXT_PUBLIC_MASTRA_URL || "http://localhost:4111",
});

export default function DebateInterface() {
  const [topic, setTopic] = useState("");
  const [turns, setTurns] = useState(3);
  const [isDebating, setIsDebating] = useState(false);
  const [responses, setResponses] = useState<any[]>([]);
  const [isPlaying, setIsPlaying] = useState(false);
  const audioRef = useRef<HTMLAudioElement>(null);

  // Function to start the debate
  const startDebate = async () => {
    if (!topic) return;

    setIsDebating(true);
    setResponses([]);

    try {
      const optimist = mastraClient.getAgent("optimistAgent");
      const skeptic = mastraClient.getAgent("skepticAgent");

      const newResponses = [];
      let optimistResponse = "";
      let skepticResponse = "";

      for (let turn = 1; turn <= turns; turn++) {
        // Optimist's turn
        let prompt;
        if (turn === 1) {
          prompt = `Discuss this topic: ${topic}. Introduce your perspective on it.`;
        } else {
          prompt = `The topic is: ${topic}. Skeptic just said: \"${skepticResponse}\". Respond to their points.`;
        }

        const optimistResult = await optimist.generate({
          messages: [{ role: "user", content: prompt }],
        });

        optimistResponse = optimistResult.text;
        newResponses.push({
          agent: "Optimist",
          text: optimistResponse,
        });

        // Update UI after each response
        setResponses([...newResponses]);

        // Skeptic's turn
        prompt = `The topic is: ${topic}. Optimist just said: \"${optimistResponse}\". Respond to their points.`;

        const skepticResult = await skeptic.generate({
          messages: [{ role: "user", content: prompt }],
        });

        skepticResponse = skepticResult.text;
        newResponses.push({
          agent: "Skeptic",
          text: skepticResponse,
        });

        // Update UI after each response
        setResponses([...newResponses]);
      }
    } catch (error) {
      console.error("Error starting debate:", error);
    } finally {
      setIsDebating(false);
    }
  };

  // Function to play audio for a specific response
  const playAudio = async (text: string, agent: string) => {
    if (isPlaying) return;

    try {
      setIsPlaying(true);
      const agentClient = mastraClient.getAgent(
        agent === "Optimist" ? "optimistAgent" : "skepticAgent",
      );

      const audioResponse = await agentClient.voice.speak(text);

      if (!audioResponse.body) {
        throw new Error("No audio stream received");
      }

      // Convert stream to blob
      const reader = audioResponse.body.getReader();
      const chunks = [];

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        chunks.push(value);
      }

      const blob = new Blob(chunks, { type: "audio/mpeg" });
      const url = URL.createObjectURL(blob);

      if (audioRef.current) {
        audioRef.current.src = url;
        audioRef.current.onended = () => {
          setIsPlaying(false);
          URL.revokeObjectURL(url);
        };
        audioRef.current.play();
      }
    } catch (error) {
      console.error("Error playing audio:", error);
      setIsPlaying(false);
    }
  };

  return (
    <div className="max-w-4xl mx-auto p-4">
      <h1 className="text-2xl font-bold mb-4">AI Debate with Turn Taking</h1>

      <div className="mb-6">
        <label className="block mb-2">Debate Topic:</label>
        <input
          type="text"
          value={topic}
          onChange={(e) => setTopic(e.target.value)}
          className="w-full p-2 border rounded"
          placeholder="e.g., Climate change, AI ethics, Space exploration"
        />
      </div>

      <div className="mb-6">
        <label className="block mb-2">Number of Turns (per agent):</label>
        <input
          type="number"
          value={turns}
          onChange={(e) => setTurns(parseInt(e.target.value))}
          min={1}
          max={10}
          className="w-full p-2 border rounded"
        />
      </div>

      <button
        onClick={startDebate}
        disabled={isDebating || !topic}
        className="px-4 py-2 bg-blue-500 text-white rounded disabled:bg-gray-300"
      >
        {isDebating ? "Debate in Progress..." : "Start Debate"}
      </button>

      <audio ref={audioRef} className="hidden" />

      {responses.length > 0 && (
        <div className="mt-8">
          <h2 className="text-xl font-semibold mb-4">Debate Transcript</h2>

          <div className="space-y-4">
            {responses.map((response, index) => (
              <div
                key={index}
                className={`p-4 rounded ${
                  response.agent === "Optimist" ? "bg-blue-100" : "bg-gray-100"
                }`}
              >
                <div className="flex justify-between items-center">
                  <div className="font-bold">{response.agent}:</div>
                  <button
                    onClick={() => playAudio(response.text, response.agent)}
                    disabled={isPlaying}
                    className="text-sm px-2 py-1 bg-blue-500 text-white rounded disabled:bg-gray-300"
                  >
                    {isPlaying ? "Playing..." : "Play"}
                  </button>
                </div>
                <p className="mt-2">{response.text}</p>
              </div>
            ))}
          </div>
        </div>
      )}
    </div>
  );
}
```

----------------------------------------

TITLE: Using Workflow.foreach() with Concurrency in TypeScript
DESCRIPTION: This snippet demonstrates the basic usage of the `workflow.foreach()` method. It executes `stepOne` for each item in an array, with a specified concurrency limit of 2, meaning up to two iterations can run in parallel. The previous step must return an array type for this method to function correctly.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/foreach.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
workflow.foreach(stepOne, { concurrency: 2 });
```

----------------------------------------

TITLE: Resuming a Suspended Workflow Step (TypeScript)
DESCRIPTION: Shows how to resume a previously suspended workflow run by providing the target step (by object or ID string) and the `resumeData`. This allows the workflow to continue execution from the suspension point.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_18

LANGUAGE: typescript
CODE:
```
const result = await workflowRun.resume({
  step: userInputStep, // or 'myStepId' as a string
  resumeData: {
    userSelection: "User's choice",
  },
});
```

----------------------------------------

TITLE: Creating a Weather Data Fetching Step in Mastra AI (TypeScript)
DESCRIPTION: This step, 'fetchWeather', is designed to retrieve weather forecast data for a specified city. It performs two sequential API calls: first, it uses a geocoding API to convert the city name into latitude and longitude coordinates, and then it uses these coordinates to fetch detailed weather information from the Open-Meteo API. The step handles input validation and error conditions, returning a structured forecast object.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/calling-agent.mdx#_snippet_3

LANGUAGE: TypeScript
CODE:
```
const fetchWeather = createStep({
  id: "fetch-weather",
  description: "Fetches weather forecast for a given city",
  inputSchema: z.object({
    city: z.string(),
  }),
  outputSchema: forecastSchema,
  execute: async ({ inputData }) => {
    if (!inputData) {
      throw new Error("Trigger data not found");
    }
 
    // First API call: Convert city name to latitude and longitude
    const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(inputData.city)}&count=1`    
    const geocodingResponse = await fetch(geocodingUrl)
    const geocodingData = (await geocodingResponse.json()) as {
      results: { latitude: number; longitude: number; name: string }[]
    }
 
    if (!geocodingData.results?.[0]) {
      throw new Error(`Location '${inputData.city}' not found`);
    }
 
    const { latitude, longitude, name } = geocodingData.results[0]
 
    // Second API call: Get weather data using coordinates
    const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=precipitation,weathercode&timezone=auto,&hourly=precipitation_probability,temperature_2m`
    const response = await fetch(weatherUrl)
    const data = (await response.json()) as {
      current: {
        time: string;
        precipitation: number;
        weathercode: number;
      };
      hourly: {
        precipitation_probability: number[]
        temperature_2m: number[]
      }
    }
 
    const forecast = {
      date: new Date().toISOString(),
      maxTemp: Math.max(...data.hourly.temperature_2m),
      minTemp: Math.min(...data.hourly.temperature_2m),
      condition: getWeatherCondition(data.current.weathercode),
      location: name,
      precipitationChance: data.hourly.precipitation_probability.reduce(
        (acc, curr) => Math.max(acc, curr),
        0,
      ),
    }
 
    return forecast
  },
})
```

----------------------------------------

TITLE: Initializing PostgresStore with Configuration Object (TypeScript)
DESCRIPTION: This code initializes a `PostgresStore` instance using a configuration object that specifies the host, port, database name, user, and password. This setup is used for general data storage functionalities like managing threads and messages.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/pg/README.md#_snippet_5

LANGUAGE: typescript
CODE:
```
import { PostgresStore } from '@mastra/pg';

const store = new PostgresStore({
  host: 'localhost',
  port: 5432,
  database: 'mastra',
  user: 'postgres',
  password: 'postgres',
});
```

----------------------------------------

TITLE: Invoking Mastra Build Command (Bash)
DESCRIPTION: This snippet illustrates the fundamental syntax for executing the `mastra build` command. It serves as the entry point for bundling a Mastra project into a production-ready Hono server, with optional parameters for customization.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/cli/build.mdx#_snippet_0

LANGUAGE: bash
CODE:
```
mastra build [options]
```

----------------------------------------

TITLE: Vector Store Error Handling - TypeScript
DESCRIPTION: Demonstrates how to catch and handle typed errors thrown by vector store operations, accessing specific error codes and details for debugging or conditional logic.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/pinecone.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
try {
  await store.query({
    indexName: "index_name",
    queryVector: queryVector,
  });
} catch (error) {
  if (error instanceof VectorStoreError) {
    console.log(error.code); // 'connection_failed' | 'invalid_dimension' | etc
    console.log(error.details); // Additional error context
  }
}
```

----------------------------------------

TITLE: Initializing a Vector Query Tool with Mastra RAG (TypeScript)
DESCRIPTION: This snippet demonstrates the basic initialization of a vector query tool using `createVectorQueryTool()` from `@mastra/rag`. It configures the tool to use a specific Pinecone vector store index and an OpenAI embedding model for semantic search, setting up the core components for retrieval-augmented generation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/vector-query-tool.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { createVectorQueryTool } from "@mastra/rag";

const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
});
```

----------------------------------------

TITLE: Embedding Chunk Arrays using Mastra and AI SDK (TSX)
DESCRIPTION: This snippet demonstrates how to generate embeddings for an array of text chunks using the `@mastra/rag` library and the `@ai-sdk/openai` package. It imports necessary modules, creates an `MDocument` from text, chunks the document, and then uses the `embedMany` function with an OpenAI embedding model (`text-embedding-3-small`) to convert the chunk text into numerical embeddings.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/embedding/embed-chunk-array.mdx#_snippet_0

LANGUAGE: tsx
CODE:
```
import { openai } from "@ai-sdk/openai";
import { MDocument } from "@mastra/rag";
import { embed } from "ai";

const doc = MDocument.fromText("Your text content...");

const chunks = await doc.chunk();

const { embeddings } = await embedMany({
  model: openai.embedding("text-embedding-3-small"),
  values: chunks.map((chunk) => chunk.text),
});
```

----------------------------------------

TITLE: Selecting Folders for Documentation Generation in TypeScript
DESCRIPTION: This step allows users to select specific folders from the cloned repository for documentation generation. It lists available directories in `./temp` and suspends the workflow to await user input. Upon resumption, it recursively gathers all file paths from the selected folders, which are then used for further processing. It uses `fs` and `path` for file system operations and `zod` for schema validation, including `suspendSchema` and `resumeSchema`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/array-as-input.mdx#_snippet_4

LANGUAGE: TypeScript
CODE:
```
const selectFolderStep = createStep({
  id: "select_folder",
  description: "Select the folder(s) to generate the docs",
  inputSchema: z.object({
    success: z.boolean(),
    message: z.string(),
    data: z.object({
      repoUrl: z.string(),
    }),
  }),
  outputSchema: z.array(z.string()),
  suspendSchema: z.object({
    folders: z.array(z.string()),
    message: z.string(),
  }),
  resumeSchema: z.object({
    selection: z.array(z.string()),
  }),
  execute: async ({ resumeData, suspend }) => {
    const tempPath = "./temp";
    const folders = fs
      .readdirSync(tempPath)
      .filter((item) => fs.statSync(path.join(tempPath, item)).isDirectory());

    if (!resumeData?.selection) {
      await suspend({
        folders,
        message: "Please select folders to generate documentation for:",
      });
      return [];
    }

    // Gather all file paths from selected folders
    const filePaths: string[] = [];
    // Helper function to recursively read files from directories
    const readFilesRecursively = (dir: string) => {
      const items = fs.readdirSync(dir);
      for (const item of items) {
        const fullPath = path.join(dir, item);
        const stat = fs.statSync(fullPath);
        if (stat.isDirectory()) {
          readFilesRecursively(fullPath);
        } else if (stat.isFile()) {
          filePaths.push(fullPath.replace(tempPath + "/", ""));
        }
      }
    };

    for (const folder of resumeData.selection) {
      readFilesRecursively(path.join(tempPath, folder));
    }

    return filePaths;
  },
});
```

----------------------------------------

TITLE: Suggesting Activities Based on Weather with Inngest and Mastra AI (TypeScript)
DESCRIPTION: This Inngest step, 'plan-activities', takes a weather forecast as input and uses a Mastra AI 'planningAgent' to generate activity suggestions. It constructs a detailed prompt with the forecast data and streams the AI's response, accumulating the text to provide comprehensive activity recommendations.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows_vNext/inngest-workflow.mdx#_snippet_1

LANGUAGE: TypeScript
CODE:
```
const planActivities = createStep({
  id: 'plan-activities',
  description: 'Suggests activities based on weather conditions',
  inputSchema: forecastSchema,
  outputSchema: z.object({
    activities: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    const forecast = inputData
 
    if (!forecast) {
      throw new Error('Forecast data not found')
    }
 
    const prompt = `Based on the following weather forecast for ${forecast.location}, suggest appropriate activities:
      ${JSON.stringify(forecast, null, 2)}
      `
 
    const agent = mastra?.getAgent('planningAgent')
    if (!agent) {
      throw new Error('Planning agent not found')
    }
 
    const response = await agent.stream([
      {
        role: 'user',
        content: prompt,
      },
    ])
 
    let activitiesText = ''
 
    for await (const chunk of response.textStream) {
      process.stdout.write(chunk)
      activitiesText += chunk
    }
 
    return {
      activities: activitiesText,
    }
  }
})
```

----------------------------------------

TITLE: Initializing DynamoDBStore for Mastra Memory
DESCRIPTION: This TypeScript snippet shows how to initialize `DynamoDBStore` from `@mastra/dynamodb` to be used as a storage backend for `Mastra`'s `Memory` component. It configures the store with the AWS region and the previously created `mastra-single-table` name. It also demonstrates integrating with `PineconeVector` and setting `Memory` options.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/dynamodb/TABLE_SETUP.md#_snippet_2

LANGUAGE: TypeScript
CODE:
```
import { Memory } from '@mastra/memory';
import { DynamoDBStore } from '@mastra/dynamodb';
import { PineconeVector } from '@mastra/pinecone';

const storage = new DynamoDBStore({
  name: 'dynamodb',
  config: {
    region: 'us-east-1',
    tableName: 'mastra-single-table', // use the name you chose when creating the table
  },
});

const vector = new PineconeVector({
  apiKey: process.env.PINECONE_API_KEY,
  environment: process.env.PINECONE_ENVIRONMENT,
  index: process.env.PINECONE_INDEX,
});

const memory = new Memory({
  storage,
  vector,
  options: {
    lastMessages: 10,
    semanticRecall: true,
  },
});
```

----------------------------------------

TITLE: Initializing PgVector and Creating an Index in TypeScript
DESCRIPTION: This code initializes a `PgVector` instance with a PostgreSQL connection string and then creates a new table (index) named 'my_vectors' with a specified dimension and cosine similarity metric. This sets up the necessary structure for storing and querying vectors.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/pg/README.md#_snippet_1

LANGUAGE: typescript
CODE:
```
import { PgVector } from '@mastra/pg';

const vectorStore = new PgVector('postgresql://user:pass@localhost:5432/db');

// Create a new table with vector support
await vectorStore.createIndex({
  indexName: 'my_vectors',
  dimension: 1536,
  metric: 'cosine',
});
```

----------------------------------------

TITLE: Disabling LLM Thread Title Generation in Mastra Memory (JavaScript)
DESCRIPTION: This snippet demonstrates how to initialize a Memory instance in Mastra with the generateTitle option set to false within the threads configuration. This disables the LLM-based generation of thread titles, which is useful when working with models that do not support structured output or when explicit control over thread titles is desired. It addresses an issue where such models would otherwise cause errors.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/memory/CHANGELOG.md#_snippet_0

LANGUAGE: JavaScript
CODE:
```
new Memory({ threads: { generateTitle: false }})
```

----------------------------------------

TITLE: Optimizing Document Chunks via Agent Cleaning (TypeScript)
DESCRIPTION: This snippet demonstrates the data optimization process. It sends a cleaning prompt to the RAG agent to filter irrelevant information and remove duplicates from the chunks. The cleaned text is then re-chunked, new embeddings are generated, and the vector store is updated by deleting and recreating the index with these optimized embeddings.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/rag/usage/cleanup-rag.mdx#_snippet_8

LANGUAGE: TypeScript
CODE:
```
const chunkPrompt = `Use the tool provided to clean the chunks. Make sure to filter out irrelevant information that is not space related and remove duplicates.`;

const newChunks = await agent.generate(chunkPrompt);
const updatedDoc = MDocument.fromText(newChunks.text);

const updatedChunks = await updatedDoc.chunk({
  strategy: "recursive",
  size: 256,
  overlap: 50,
  separator: "\n",
});

const { embeddings: cleanedEmbeddings } = await embedMany({
  model: openai.embedding("text-embedding-3-small"),
  values: updatedChunks.map((chunk) => chunk.text),
});

// Update the vector store with cleaned embeddings
await vectorStore.deleteIndex({ indexName: "embeddings" });
await vectorStore.createIndex({
  indexName: "embeddings",
  dimension: 1536,
});

await vectorStore.upsert({
  indexName: "embeddings",
  vectors: cleanedEmbeddings,
  metadata: updatedChunks?.map((chunk: any) => ({ text: chunk.text })),
});
```

----------------------------------------

TITLE: Demonstrating Mastra Agent Conversation with Memory Recall
DESCRIPTION: This snippet demonstrates how to use the Mastra agent for a conversational flow, including starting a new thread and making multiple queries. It showcases how to leverage both `lastMessages` for recent history and `semanticRecall` for contextually relevant messages from memory during a conversation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-with-upstash.mdx#_snippet_2

LANGUAGE: TypeScript
CODE:
```
import { randomUUID } from "crypto";

// Start a conversation
const threadId = randomUUID();
const resourceId = "SOME_USER_ID";

// Ask about ingredients
const response1 = await chefAgent.stream(
  "In my kitchen I have: pasta, canned tomatoes, garlic, olive oil, and some dried herbs (basil and oregano). What can I make?",
  {
    threadId,
    resourceId,
  },
);

// Ask about different ingredients
const response2 = await chefAgent.stream(
  "Now I'm over at my friend's house, and they have: chicken thighs, coconut milk, sweet potatoes, and curry powder.",
  {
    threadId,
    resourceId,
  },
);

// Use memory to recall previous conversation
const response3 = await chefAgent.stream(
  "What did we cook before I went to my friends house?",
  {
    threadId,
    resourceId,
    memoryOptions: {
      lastMessages: 3, // Get last 3 messages for context
      semanticRecall: {
        topK: 2, // Also get 2 most relevant messages
        messageRange: 2, // Include context around matches
      },
    },
  },
);
```

----------------------------------------

TITLE: Creating a Vector Query Tool with Mastra RAG
DESCRIPTION: This snippet demonstrates the creation of a `vectorQueryTool` using `createVectorQueryTool` from `@mastra/rag`. This tool is configured to interact with the 'pgVector' store, target the 'embeddings' index, and use OpenAI's 'text-embedding-3-small' model for embedding generation during queries. It serves as the interface for retrieving relevant information from the vector database.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-rag.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
const vectorQueryTool = createVectorQueryTool({
  vectorStoreName: "pgVector",
  indexName: "embeddings",
  model: openai.embedding("text-embedding-3-small")
});
```

----------------------------------------

TITLE: Implementing Chat API Route with Mastra and AI SDK (TypeScript)
DESCRIPTION: Provides an example of a Next.js API route (`/api/chat`) that handles incoming chat messages, retrieves a Mastra agent, streams the response, and returns it using AI SDK's `toDataStreamResponse` for frontend compatibility.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/ai-sdk.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { mastra } from "@/src/mastra";

export async function POST(req: Request) {
  const { messages } = await req.json();
  const myAgent = mastra.getAgent("weatherAgent");
  const stream = await myAgent.stream(messages);

  return stream.toDataStreamResponse();
}
```

----------------------------------------

TITLE: Setting up CopilotKit Runtime API Endpoint in Next.js App Router
DESCRIPTION: This TypeScript snippet defines a Next.js App Router POST API endpoint for CopilotKit runtime. It initializes `CopilotRuntime` with Mastra agents, handles incoming requests, and processes them through the `copilotRuntimeNextJSAppRouterEndpoint` for AI interactions.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/copilotkit.mdx#_snippet_15

LANGUAGE: typescript
CODE:
```
// import your mastra instance from dir
import { mastra } from '../path/to/mastra';
import {
  CopilotRuntime,
  ExperimentalEmptyAdapter,
  copilotRuntimeNextJSAppRouterEndpoint
} from "@copilotkit/runtime";
import { NextRequest } from "next/server";

export const POST = async (req: NextRequest) => {
  // Clone the request before reading the body
  const clonedReq = req.clone();
  const body = await clonedReq.json();
  const resourceId = body.resourceId || "TEST";

  const mastraAgents = getAGUI({
    mastra,
    resourceId
  });

  const runtime = new CopilotRuntime({
    agents: mastraAgents
  });

  const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
    runtime,
    serviceAdapter: new ExperimentalEmptyAdapter(),
    endpoint: "/api/copilotkit"
  });

  // Use the original request for handleRequest
  return handleRequest(req);
};
```

----------------------------------------

TITLE: Using CompositeVoice with OpenAI and PlayAI in TypeScript
DESCRIPTION: This snippet demonstrates how to initialize OpenAIVoice and PlayAIVoice providers and combine them using CompositeVoice for speech-to-text (listen) and text-to-speech (speak) operations.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/composite-voice.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { CompositeVoice } from "@mastra/core/voice";
import { OpenAIVoice } from "@mastra/voice-openai";
import { PlayAIVoice } from "@mastra/voice-playai";

// Create voice providers
const openai = new OpenAIVoice();
const playai = new PlayAIVoice();

// Use OpenAI for listening (speech-to-text) and PlayAI for speaking (text-to-speech)
const voice = new CompositeVoice({
  input: openai,
  output: playai,
});

// Convert speech to text using OpenAI
const text = await voice.listen(audioStream);

// Convert text to speech using PlayAI
const audio = await voice.speak("Hello, world!");
```

----------------------------------------

TITLE: Using Dynamic Tool Configuration with MCPClient
DESCRIPTION: This example illustrates how to use `mcp.getToolsets()` for dynamic tool configurations, ideal for multi-user applications where credentials or configurations might change per request. A new `MCPClient` is instantiated per request, and the resulting toolsets are passed to the agent's `stream()` method.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/tools-mcp/mcp-overview.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
import { Agent } from "@mastra/core/agent";
// ... agent setup without tools initially

async function handleRequest(userPrompt: string, userApiKey: string) {
  const userMcp = new MCPClient({
    /* config with userApiKey */
  });
  const toolsets = await userMcp.getToolsets();

  const response = await agent.stream(userPrompt, {
    toolsets // Pass dynamic toolsets
  });
  // ... handle response
  await userMcp.disconnect();
}
```

----------------------------------------

TITLE: Using Agent.getMemory() in a Conversation Flow - TypeScript
DESCRIPTION: Shows how to create an agent with memory, use it across multiple `generate` calls to maintain context, and then access the memory directly via `getMemory()` to query messages.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/getMemory.mdx#_snippet_3

LANGUAGE: typescript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { openai } from "@ai-sdk/openai";

// Create a memory system
const memory = new Memory();

// Create an agent with memory
const agent = new Agent({
  name: "memory-assistant",
  instructions:
    "You are a helpful assistant that remembers previous conversations.",
  model: openai("gpt-4o"),
  memory,
});

// First interaction - store information
await agent.generate("My name is Alice.", {
  resourceId: "user-123",
  threadId: "conversation-1",
});

// Later interaction - retrieve information
const result = await agent.generate("What's my name?", {
  resourceId: "user-123",
  threadId: "conversation-1",
});

console.log(result.text); // Should mention "Alice"

// Access the memory system directly
const agentMemory = agent.getMemory();
if (agentMemory) {
  // Retrieve messages from the thread
  const { messages } = await agentMemory.query({
    resourceId: "user-123",
    threadId: "conversation-1",
    selectBy: {
      last: 10 // Get the last 10 messages
    }
  });

  console.log("Retrieved messages:", messages);
}
```

----------------------------------------

TITLE: Upserting Embeddings with Basic Metadata in TypeScript
DESCRIPTION: This snippet demonstrates how to use the `store.upsert` method to add or update embedding vectors in a vector store. It includes essential metadata such as the original text content and an optional unique identifier, enabling retrieval and basic filtering. The operation automatically handles batching and updates existing vectors by ID.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#_snippet_11

LANGUAGE: TypeScript
CODE:
```
// Store embeddings with their corresponding metadata
await store.upsert({
  indexName: "myCollection", // index name
  vectors: embeddings, // array of embedding vectors
  metadata: chunks.map((chunk) => ({
    text: chunk.text, // The original text content
    id: chunk.id // Optional unique identifier
  }))
});
```

----------------------------------------

TITLE: Implementing MastraVoice Abstract Class in TypeScript
DESCRIPTION: This snippet demonstrates how to create a custom voice provider by extending the abstract MastraVoice class. It shows the constructor signature for passing configuration and outlines the required abstract methods (speak, listen, getSpeakers) and optional speech-to-speech methods (connect, send, answer, addTools, close, on, off) that must be implemented by concrete provider classes.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/mastra-voice.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { MastraVoice } from "@mastra/core/voice";

// Create a voice provider implementation
class MyVoiceProvider extends MastraVoice {
  constructor(config: {
    speechModel?: BuiltInModelConfig;
    listeningModel?: BuiltInModelConfig;
    speaker?: string;
    realtimeConfig?: {
      model?: string;
      apiKey?: string;
      options?: unknown;
    };
  }) {
    super({
      speechModel: config.speechModel,
      listeningModel: config.listeningModel,
      speaker: config.speaker,
      realtimeConfig: config.realtimeConfig,
    });
  }

  // Implement required abstract methods
  async speak(
    input: string | NodeJS.ReadableStream,
    options?: { speaker?: string },
  ): Promise<NodeJS.ReadableStream | void> {
    // Implement text-to-speech conversion
  }

  async listen(
    audioStream: NodeJS.ReadableStream,
    options?: unknown,
  ): Promise<string | NodeJS.ReadableStream | void> {
    // Implement speech-to-text conversion
  }

  async getSpeakers(): Promise<
    Array<{ voiceId: string; [key: string]: unknown }>
  > {
    // Return list of available voices
  }

  // Optional speech-to-speech methods
  async connect(): Promise<void> {
    // Establish WebSocket connection for speech-to-speech communication
  }

  async send(audioData: NodeJS.ReadableStream | Int16Array): Promise<void> {
    // Stream audio data in speech-to-speech
  }

  async answer(): Promise<void> {
    // Trigger voice provider to respond
  }

  addTools(tools: Array<unknown>): void {
    // Add tools for the voice provider to use
  }

  close(): void {
    // Close WebSocket connection
  }

  on(event: string, callback: (data: unknown) => void): void {
    // Register event listener
  }

  off(event: string, callback: (data: unknown) => void): void {
    // Remove event listener
  }
}
```

----------------------------------------

TITLE: Applying Basic Metadata Filters with PgVector in TypeScript
DESCRIPTION: This snippet illustrates how to perform a vector search query on a PgVector store while applying metadata filters. It demonstrates common filter types including simple equality, numeric range comparison using '$gt', and array membership using '$in'. The 'filter' object refines the vector search results based on the specified metadata criteria.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/metadata-filters.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { PgVector } from "@mastra/pg";

const store = new PgVector({ connectionString });

const results = await store.query({
  indexName: "my_index",
  queryVector: queryVector,
  topK: 10,
  filter: {
    category: "electronics", // Simple equality
    price: { $gt: 100 }, // Numeric comparison
    tags: { $in: ["sale", "new"] }, // Array membership
  },
});
```

----------------------------------------

TITLE: Example Metadata Filter Object in TypeScript
DESCRIPTION: This TypeScript snippet provides an example of a metadata filter object used for querying. It demonstrates the use of logical (`$and`) and comparison (`$gt`) operators, as well as array operators (`$in`), to construct complex queries based on document metadata. This filter can be applied when querying vectors or other stored data to refine search results.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/libsql/README.md#_snippet_3

LANGUAGE: typescript
CODE:
```
{
  $and: [{ age: { $gt: 25 } }, { tags: { $in: ['tag1', 'tag2'] } }];
}
```

----------------------------------------

TITLE: Creating Mastra Tools with createTool() | TypeScript
DESCRIPTION: This snippet demonstrates how to define custom tools for Mastra agents and workflows using the `createTool` function. It includes examples for fetching external data (stock prices) and accessing thread-specific context. It requires `@mastra/core/tools` and `zod` for schema validation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/createTool.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { createTool } from "@mastra/core/tools";
import { z } from "zod";

// Helper function to fetch stock data
const getStockPrice = async (symbol: string) => {
  const response = await fetch(
    `https://mastra-stock-data.vercel.app/api/stock-data?symbol=${symbol}`,
  );
  const data = await response.json();
  return data.prices["4. close"];
};

// Create a tool to get stock prices
export const stockPriceTool = createTool({
  id: "getStockPrice",
  description: "Fetches the current stock price for a given ticker symbol",
  inputSchema: z.object({
    symbol: z.string().describe("The stock ticker symbol (e.g., AAPL, MSFT)"),
  }),
  outputSchema: z.object({
    symbol: z.string(),
    price: z.number(),
    currency: z.string(),
    timestamp: z.string(),
  }),
  execute: async ({ context }) => {
    const price = await getStockPrice(context.symbol);

    return {
      symbol: context.symbol,
      price: parseFloat(price),
      currency: "USD",
      timestamp: new Date().toISOString(),
    };
  },
});

// Create a tool that uses the thread context
export const threadInfoTool = createTool({
  id: "getThreadInfo",
  description: "Returns information about the current conversation thread",
  inputSchema: z.object({
    includeResource: z.boolean().optional().default(false),
  }),
  execute: async ({ context, threadId, resourceId }) => {
    return {
      threadId,
      resourceId: context.includeResource ? resourceId : undefined,
      timestamp: new Date().toISOString(),
    };
  },
});
```

----------------------------------------

TITLE: Defining Weather Reporter Agent in TypeScript
DESCRIPTION: This TypeScript code defines `weatherReporterAgent` using `@mastra/core/agent`. It leverages `gpt-4o` from `@ai-sdk/openai` to explain weather reports conversationally, acting as a specialized agent within a workflow. The agent is instructed to explain weather reports like a weather reporter, using provided city information.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/agent-and-tool-interop.mdx#_snippet_1

LANGUAGE: ts
CODE:
```
import { openai } from '@ai-sdk/openai'
import { Agent } from '@mastra/core/agent'

// Create an agent that explains weather reports in a conversational style
export const weatherReporterAgent = new Agent({
  name: 'weatherExplainerAgent',
  model: openai('gpt-4o'),
  instructions: `
  You are a weather explainer. You have access to input that will help you get weather-specific activities for any city. 
  The tool uses agents to plan the activities, you just need to provide the city. Explain the weather report like a weather reporter.
  `,
})
```

----------------------------------------

TITLE: Basic Text Streaming with Agent
DESCRIPTION: This snippet demonstrates how to use the `stream()` method of `myAgent` to get a basic text stream. It sends a user message and then iterates over the `textStream` to print each chunk to standard output, showing real-time text generation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/stream.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
const stream = await myAgent.stream([
  { role: "user", content: "Tell me a story." },
]);

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```

----------------------------------------

TITLE: Performing Vector Search and Re-ranking Results with Mastra
DESCRIPTION: This snippet first generates an embedding for the user query. It then performs an initial vector similarity search against the stored embeddings in PGVector. Finally, it re-ranks these initial results using Mastra's `rerank` function, applying custom weights to semantic relevance, original vector similarity, and positional scores to refine the ranking.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/rerank/rerank.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
const query = "explain technical trading analysis";

// Get query embedding
const { embedding: queryEmbedding } = await embed({
  value: query,
  model: openai.embedding("text-embedding-3-small")
});

// Get initial results
const initialResults = await pgVector.query({
  indexName: "embeddings",
  queryVector: queryEmbedding,
  topK: 3
});

// Re-rank results
const rerankedResults = await rerank(
  initialResults,
  query,
  openai("gpt-4o-mini"),
  {
    weights: {
      semantic: 0.5, // How well the content matches the query semantically
      vector: 0.3, // Original vector similarity score
      position: 0.2 // Preserves original result ordering
    },
    topK: 3
  }
);
```

----------------------------------------

TITLE: Implementing Turn-Taking Logic for AI Debate (TypeScript)
DESCRIPTION: This snippet provides the core logic for managing a turn-based debate between two Mastra agents. It includes a helper function 'formatText' for display, initializes an audio 'Recorder', and defines 'processTurn' to handle agent response generation, text-to-speech conversion, and audio playback. The main 'runDebate' function orchestrates the turns, ensuring each agent responds to the previous agent's statement, and saves the full debate audio.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/turn-taking.mdx#_snippet_2

LANGUAGE: TypeScript
CODE:
```
import { mastra } from "../../mastra";
import { playAudio, Recorder } from "@mastra/node-audio";
import * as p from "@clack/prompts";

// Helper function to format text with line wrapping
function formatText(text: string, maxWidth: number): string {
  const words = text.split(" ");
  let result = "";
  let currentLine = "";

  for (const word of words) {
    if (currentLine.length + word.length + 1 <= maxWidth) {
      currentLine += (currentLine ? " " : "") + word;
    } else {
      result += (result ? "\n" : "") + currentLine;
      currentLine = word;
    }
  }

  if (currentLine) {
    result += (result ? "\n" : "") + currentLine;
  }

  return result;
}

// Initialize audio recorder
const recorder = new Recorder({
  outputPath: "./debate.mp3",
});

// Process one turn of the conversation
async function processTurn(
  agentName: "optimistAgent" | "skepticAgent",
  otherAgentName: string,
  topic: string,
  previousResponse: string = "",
) {
  const agent = mastra.getAgent(agentName);
  const spinner = p.spinner();
  spinner.start(`${agent.name} is thinking...`);

  let prompt;
  if (!previousResponse) {
    // First turn
    prompt = `Discuss this topic: ${topic}. Introduce your perspective on it.`;
  } else {
    // Responding to the other agent
    prompt = `The topic is: ${topic}. ${otherAgentName} just said: "${previousResponse}". Respond to their points.`;
  }

  // Generate text response
  const { text } = await agent.generate(prompt, {
    temperature: 0.9,
  });

  spinner.message(`${agent.name} is speaking...`);

  // Convert to speech and play
  const audioStream = await agent.voice.speak(text, {
    speed: 1.2,
    responseFormat: "wav", // Optional: specify a response format
  });

  if (audioStream) {
    audioStream.on("data", (chunk) => {
      recorder.write(chunk);
    });
  }

  spinner.stop(`${agent.name} said:`);

  // Format the text to wrap at 80 characters for better display
  const formattedText = formatText(text, 80);
  p.note(formattedText, agent.name);

  if (audioStream) {
    const speaker = playAudio(audioStream);

    await new Promise<void>((resolve) => {
      speaker.once("close", () => {
        resolve();
      });
    });
  }

  return text;
}

// Main function to run the debate
export async function runDebate(topic: string, turns: number = 3) {
  recorder.start();

  p.intro("AI Debate - Two Agents Discussing a Topic");
  p.log.info(`Starting a debate on: ${topic}`);
  p.log.info(
    `The debate will continue for ${turns} turns each. Press Ctrl+C to exit at any time.`,
  );

  let optimistResponse = "";
  let skepticResponse = "";
  const responses = [];

  for (let turn = 1; turn <= turns; turn++) {
    p.log.step(`Turn ${turn}`);

    // Optimist's turn
    optimistResponse = await processTurn(
      "optimistAgent",
      "Skeptic",
      topic,
      skepticResponse,
    );

    responses.push({
      agent: "Optimist",
      text: optimistResponse,
    });

    // Skeptic's turn
    skepticResponse = await processTurn(
      "skepticAgent",
      "Optimist",
      topic,
      optimistResponse,
    );

    responses.push({
      agent: "Skeptic",
      text: skepticResponse,
    });
  }

  recorder.end();
  p.outro("Debate concluded! The full audio has been saved to debate.mp3");

  return responses;
}
```

----------------------------------------

TITLE: Identifying and Resuming Suspended Workflow State in Mastra (TypeScript)
DESCRIPTION: This code illustrates how to programmatically check if a Mastra workflow run is in a 'suspended' state. If suspended, it demonstrates how to resume the first identified suspended step by accessing the `result.suspended[0]` property and providing `resumeData` to the `run.resume()` method. The `suspended` property is an array of string arrays, representing paths to suspended steps.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/suspend-and-resume.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
const run = counterWorkflow.createRun();
const result = await run.start({ inputData: { startValue: 0 } });

// Check if the workflow is in suspended state
if (result.status === "suspended") {
  // Resume the first suspended step with new data
  const resumedResults = await run.resume({
    step: result.suspended[0],
    resumeData: { newValue: 0 },
  });
}
```

----------------------------------------

TITLE: Initializing Voice Agent with Sarvam Voice in TypeScript
DESCRIPTION: This snippet demonstrates how to initialize a Mastra AI voice agent using the Sarvam Voice provider. It configures the agent with a GPT-4o model, generates a text response, converts the text to an audio stream using Sarvam's TTS, and then plays the audio.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#_snippet_9

LANGUAGE: typescript
CODE:
```
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';
import { SarvamVoice } from "@mastra/voice-sarvam";
import { playAudio } from "@mastra/node-audio";

const voiceAgent = new Agent({
name: "Voice Agent",
instructions: "You are a voice assistant that can help users with their tasks.",
model: openai("gpt-4o"),
voice: new SarvamVoice(),
});

const { text } = await voiceAgent.generate('What color is the sky?');

// Convert text to speech to an Audio Stream
const audioStream = await voiceAgent.voice.speak(text, {
speaker: "default" // Optional: specify a speaker
});

playAudio(audioStream);
```

----------------------------------------

TITLE: Streaming Audio Data with voice.send() in TypeScript
DESCRIPTION: This snippet demonstrates how to use the `voice.send()` method with a real-time voice provider. It shows initialization, connecting, setting up event listeners for text and audio output, obtaining a microphone stream, and sending the stream or an Int16Array buffer to the provider.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/voice.send.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";
import Speaker from "@mastra/node-speaker";
import { getMicrophoneStream } from "@mastra/node-audio";

const speaker = new Speaker({
  sampleRate: 24100, // Audio sample rate in Hz - standard for high-quality audio on MacBook Pro
  channels: 1, // Mono audio output (as opposed to stereo which would be 2)
  bitDepth: 16, // Bit depth for audio quality - CD quality standard (16-bit resolution)
});

// Initialize a real-time voice provider
const voice = new OpenAIRealtimeVoice({
  realtimeConfig: {
    model: "gpt-4o-mini-realtime",
    apiKey: process.env.OPENAI_API_KEY,
  },
});

// Connect to the real-time service
await voice.connect();

// Set up event listeners for responses
voice.on("writing", ({ text, role }) => {
  console.log(`${role}: ${text}`);
});

voice.on("speaker", (stream) => {
  stream.pipe(speaker);
});

// Get microphone stream (implementation depends on your environment)
const microphoneStream = getMicrophoneStream();

// Send audio data to the voice provider
await voice.send(microphoneStream);

// You can also send audio data as Int16Array
const audioBuffer = getAudioBuffer(); // Assume this returns Int16Array
await voice.send(audioBuffer);
```

----------------------------------------

TITLE: Defining a Mastra Planning Agent with OpenAI LLM (TypeScript)
DESCRIPTION: This snippet defines `planningAgent`, a Mastra `Agent` that uses OpenAI's `gpt-4o` model. It's configured with detailed instructions to act as a travel expert, generating weather-based activity recommendations. The agent's instructions specify the output format and content guidelines for planning activities.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/conditional-branching.mdx#_snippet_1

LANGUAGE: ts
CODE:
```
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";

const llm = openai("gpt-4o");

// Define the planning agent that generates activity recommendations
// based on weather conditions and location
const planningAgent = new Agent({
  name: "planningAgent",
  model: llm,
  instructions: `\n        You are a local activities and travel expert who excels at weather-based planning. Analyze the weather data and provide practical activity recommendations.\n\n        📅 [Day, Month Date, Year]\n        ═══════════════════════════\n\n        🌡️ WEATHER SUMMARY\n        • Conditions: [brief description]\n        • Temperature: [X°C/Y°F to A°C/B°F]\n        • Precipitation: [X% chance]\n\n        🌅 MORNING ACTIVITIES\n        Outdoor:\n        • [Activity Name] - [Brief description including specific location/route]\n          Best timing: [specific time range]\n          Note: [relevant weather consideration]\n\n        🌞 AFTERNOON ACTIVITIES\n        Outdoor:\n        • [Activity Name] - [Brief description including specific location/route]\n          Best timing: [specific time range]\n          Note: [relevant weather consideration]\n\n        🏠 INDOOR ALTERNATIVES\n        • [Activity Name] - [Brief description including specific venue]\n          Ideal for: [weather condition that would trigger this alternative]\n\n        ⚠️ SPECIAL CONSIDERATIONS\n        • [Any relevant weather warnings, UV index, wind conditions, etc.]\n\n        Guidelines:\n        - Suggest 2-3 time-specific outdoor activities per day\n        - Include 1-2 indoor backup options\n        - For precipitation >50%, lead with indoor activities\n        - All activities must be specific to the location\n        - Include specific venues, trails, or locations\n        - Consider activity intensity based on temperature\n        - Keep descriptions concise but informative\n\n        Maintain this exact formatting for consistency, using the emoji and section headers as shown.\n      `,
});

export { planningAgent };
```

----------------------------------------

TITLE: Installing Project Dependencies (pnpm)
DESCRIPTION: This command uses pnpm to install all necessary project dependencies listed in the package.json file, ensuring that the application has all required libraries to run.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/retrieve-results/README.md#_snippet_3

LANGUAGE: Bash
CODE:
```
pnpm install
```

----------------------------------------

TITLE: Defining a Human Input Step for Workflow Suspension (TypeScript)
DESCRIPTION: Another example of a `createStep` designed for human interaction, demonstrating how to suspend a workflow and resume it with user-provided `selection` data. It handles initial input and resume data for a vacation planning scenario.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_17

LANGUAGE: typescript
CODE:
```
const humanInputStep = createStep({
  id: 'human-input',
  inputSchema: z.object({
    suggestions: z.array(z.string()),
    vacationDescription: z.string(),
  }),
  resumeSchema: z.object({
    selection: z.string(),
  }),
  suspendSchema: z.object({}),
  outputSchema: z.object({
    selection: z.string().describe('The selection of the user'),
    vacationDescription: z.string(),
  }),
  execute: async ({ inputData, resumeData, suspend }) => {
    if (!resumeData?.selection) {
      await suspend({});
      return {
        selection: '',
        vacationDescription: inputData?.vacationDescription,
      };
    }
    return {
      selection: resumeData.selection,
      vacationDescription: inputData?.vacationDescription,
    };
  },
});
```

----------------------------------------

TITLE: Embedding Multiple Texts using AI SDK in TypeScript
DESCRIPTION: This snippet illustrates the usage of the `embedMany` function from the AI SDK to generate vector embeddings for an array of text inputs. It requires specifying the embedding model and an array of text values. Like `embed`, it supports an optional `maxRetries` parameter. The function returns an array of embedding vectors, one for each input text.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/embeddings.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { embedMany } from "ai";

const result = await embedMany({
  model: openai.embedding("text-embedding-3-small"),
  values: ["First text", "Second text", "Third text"],
  maxRetries: 2, // optional, defaults to 2
});
```

----------------------------------------

TITLE: Using Mastra AI Server Action in a Next.js Client Component
DESCRIPTION: This client-side React component demonstrates how to invoke the `getWeatherInfo` server action from a form submission. It captures the city input, calls the server action, and logs the AI-generated weather result to the console, showcasing client-server interaction in Next.js.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#_snippet_16

LANGUAGE: TypeScript
CODE:
```
'use client'

import { getWeatherInfo } from '../actions'

export function Weather() {
  async function handleSubmit(formData: FormData) {
    const city = formData.get('city') as string
    const result = await getWeatherInfo(city)
    // Handle the result
    console.log(result)
  }

  return (
    <form action={handleSubmit}>
      <input name="city" placeholder="Enter city name" />
      <button type="submit">Get Weather</button>
    </form>
  )
}
```

----------------------------------------

TITLE: Creating a Vector Query Tool with OpenAI Embeddings
DESCRIPTION: This snippet initializes `vectorQueryTool` using `createVectorQueryTool`. It configures the tool to interact with a vector store named 'pgVector', targeting the 'embeddings' index, and specifies `text-embedding-3-small` from OpenAI as the embedding model for queries. This tool facilitates semantic search within the RAG system.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/basic-rag.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
const vectorQueryTool = createVectorQueryTool({
  vectorStoreName: "pgVector",
  indexName: "embeddings",
  model: openai.embedding("text-embedding-3-small")
});
```

----------------------------------------

TITLE: Chunking Markdown Documents with Mastra RAG (TSX)
DESCRIPTION: This snippet demonstrates how to semantically chunk markdown content using the `MDocument.fromMarkdown` and `doc.chunk()` methods from the `@mastra/rag` library. It initializes an `MDocument` from a markdown string and then processes it into smaller, semantically coherent chunks, suitable for RAG pipelines.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/chunking/chunk-markdown.mdx#_snippet_0

LANGUAGE: tsx
CODE:
```
import { MDocument } from "@mastra/rag";

const doc = MDocument.fromMarkdown("# Your markdown content...");

const chunks = await doc.chunk();
```

----------------------------------------

TITLE: Creating PG Vector Index with Config - TypeScript
DESCRIPTION: Shows how to create a vector index in the PostgreSQL store with configurable parameters. It allows specifying the index name, vector dimension, distance metric (e.g., 'cosine'), and index-specific configuration like HNSW parameters (`m`, `efConstruction`). This enhancement provides support for multiple index types and configurable parameters.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/communications/releases/2025-03-03.md#_snippet_1

LANGUAGE: typescript
CODE:
```
await vectorDB.createIndex({
  indexName: 'my_index',
  dimension: 1536,
  metric: 'cosine',
  indexConfig: {
    type: 'hnsw',
    hnsw: { m: 16, efConstruction: 64 },
  },
});
```

----------------------------------------

TITLE: Implementing a Custom Mastra Memory Processor (TypeScript)
DESCRIPTION: Defines a custom memory processor by implementing the `MemoryProcessor` interface. The `process` method is where custom logic for filtering or transforming `CoreMessage` arrays should be added before messages are sent to the LLM.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/memory-with-processors/README.md#_snippet_4

LANGUAGE: typescript
CODE:
```
import type { CoreMessage } from '@mastra/core';
import type { MemoryProcessor } from '@mastra/core/memory';

class CustomProcessor implements MemoryProcessor {
  process(messages: CoreMessage[]): CoreMessage[] {
    // Filter or transform messages here
    return filteredMessages;
  }
}
```

----------------------------------------

TITLE: Create Instrumentation File with Custom Exporter (instrumentation.ts)
DESCRIPTION: Sets up the OpenTelemetry NodeSDK with a custom trace exporter (e.g., LangfuseExporter) and resource attributes, registering the SDK to start tracing.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/observability/nextjs-tracing.mdx#_snippet_3

LANGUAGE: typescript
CODE:
```
import {
  NodeSDK,
  ATTR_SERVICE_NAME,
  Resource,
} from "@mastra/core/telemetry/otel-vendor";
import { LangfuseExporter } from "langfuse-vercel";

export function register() {
  const exporter = new LangfuseExporter({
    // ... Langfuse config
  });

  const sdk = new NodeSDK({
    resource: new Resource({
      [ATTR_SERVICE_NAME]: "ai",
    }),
    traceExporter: exporter,
  });

  sdk.start();
}
```

----------------------------------------

TITLE: Creating and Initializing a Workflow Run in TypeScript
DESCRIPTION: This snippet illustrates the process of defining a workflow with input/output schemas and steps, initializing the Mastra client with the defined workflow, and then creating a new workflow run instance using the `.createRun()` method. The `createRun()` method returns a `Run` object, which represents the new workflow execution instance.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/create-run.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
const myWorkflow = createWorkflow({
  id: "my-workflow",
  inputSchema: z.object({
    startValue: z.string(),
  }),
  outputSchema: z.object({
    result: z.string(),
  }),
  steps: [step1, step2, step3], // Declare steps used in this workflow
})
  .then(step1)
  .then(step2)
  .then(step3)
  .commit();

const mastra = new Mastra({
  workflows: {
    myWorkflow,
  },
});

const run = mastra.getWorkflow("myWorkflow").createRun();
```

----------------------------------------

TITLE: Using SpeechifyVoice for Text-to-Speech - TypeScript
DESCRIPTION: This comprehensive snippet illustrates the core usage of `SpeechifyVoice`. It covers initializing the voice client with optional model and speaker configurations, listing available speakers, and generating speech from text into an audio stream that can be piped to a destination.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/speechify/README.md#_snippet_2

LANGUAGE: typescript
CODE:
```
import { SpeechifyVoice } from '@mastra/voice-speechify';

const voice = new SpeechifyVoice({
  speechModel: {
    name: 'simba-english', // Optional, defaults to 'simba-english'
    apiKey: 'your-api-key', // Optional, can use SPEECHIFY_API_KEY env var
  },
  speaker: 'george', // Optional, defaults to 'george'
});

// List available speakers
const speakers = await voice.getSpeakers();

// Generate speech
const stream = await voice.speak('Hello world', {
  speaker: 'george', // Optional, defaults to constructor speaker
  // Additional Speechify options
  audioFormat: 'mp3',
});

// The stream can be piped to a destination
stream.pipe(destination);
```

----------------------------------------

TITLE: Initializing Qdrant Vector Store in TypeScript
DESCRIPTION: This snippet illustrates the initialization of the Qdrant vector store using `@mastra/qdrant`. It sets up the store with a URL and API key, proceeds to create an index named 'myCollection' with a defined dimension, and finally upserts vector data with corresponding metadata. It depends on `process.env.QDRANT_URL` and `process.env.QDRANT_API_KEY`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#_snippet_2

LANGUAGE: TypeScript
CODE:
```
  import { QdrantVector } from '@mastra/qdrant'

const store = new QdrantVector({
  url: process.env.QDRANT_URL,
  apiKey: process.env.QDRANT_API_KEY
})
await store.createIndex({
indexName: "myCollection",
dimension: 1536,
});
await store.upsert({
indexName: "myCollection",
vectors: embeddings,
metadata: chunks.map(chunk => ({ text: chunk.text })),
});
```

----------------------------------------

TITLE: Dynamically Setting Runtime Context in Mastra Middleware (TypeScript)
DESCRIPTION: This example shows how to integrate runtime context with a REST API using Mastra's server middleware. It dynamically sets the `temperature-scale` in the `runtimeContext` based on the `CF-IPCountry` header from the incoming request, allowing agents to respond with location-specific units. It requires `@mastra/core` and `@mastra/core/di` dependencies.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/runtime-variables.mdx#_snippet_1

LANGUAGE: TypeScript
CODE:
```
import { Mastra } from "@mastra/core";
import { RuntimeContext } from "@mastra/core/di";
import { agent as weatherAgent } from "./agents/weather";

// Define RuntimeContext type with clear, descriptive types
type WeatherRuntimeContext = {
  "temperature-scale": "celsius" | "fahrenheit";
};

export const mastra = new Mastra({
  agents: {
    weather: weatherAgent,
  },
  server: {
    middleware: [
      async (c, next) => {
        const country = c.req.header("CF-IPCountry");
        const runtimeContext = c.get<WeatherRuntimeContext>("runtimeContext");

        // Set temperature scale based on country
        runtimeContext.set(
          "temperature-scale",
          country === "US" ? "fahrenheit" : "celsius",
        );

        await next(); // Don't forget to call next()
      },
    ],
  },
});
```

----------------------------------------

TITLE: Injecting Runtime Context into Agent Call (TypeScript)
DESCRIPTION: Shows the process of creating a `RuntimeContext` instance, defining its type, setting specific key-value pairs (like `temperature-scale`), and then passing this context object as an option to the `agent.generate` method.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/agents/adding-tools.mdx#_snippet_5

LANGUAGE: typescript
CODE:
```
import { agent } from "./agents/weather";

type MyRuntimeContext = {"temperature-scale": "celsius" | "farenheit"}

const runtimeContext = new RuntimeContext<MyRuntimeContext>();
runtimeContext.set("temperature-scale", "celsius");

const result = await agent.generate("What is the weather in San Francisco?", {
  runtimeContext,
});
```

----------------------------------------

TITLE: Configuring Mastra Server Middleware for Dynamic Runtime Context
DESCRIPTION: This snippet sets up a Mastra server with middleware and an API route. The middleware intercepts incoming requests, extracts `X-User-ID` from headers, and dynamically populates the `runtimeContext` with `user-tier`, `language`, and `user-id` by calling asynchronous functions. The `/support` API route then uses this pre-configured context to handle support requests.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/dynamic-agents.mdx#_snippet_3

LANGUAGE: TypeScript
CODE:
```
import { Mastra } from "@mastra/core";
import { registerApiRoute } from "@mastra/core/server";

export const mastra = new Mastra({
  agents: {
    support: supportAgent,
  },
  server: {
    middleware: [
      async (c, next) => {
        const userId = c.req.header("X-User-ID");
        const runtimeContext = c.get<SupportRuntimeContext>("runtimeContext");

        // Set user tier based on subscription
        const userTier = await getUserTier(userId);
        runtimeContext.set("user-tier", userTier);

        // Set language based on user preferences
        const language = await getUserLanguage(userId);
        runtimeContext.set("language", language);

        // Set user ID
        runtimeContext.set("user-id", userId);

        await next();
      }
    ],
    apiRoutes: [
      registerApiRoute("/support", {
        method: "POST",
        handler: async (c) => {
          const { userId, message } = await c.req.json();
          
          try {
            const response = await handleSupportRequest(userId, message);
            return c.json({ response });
          } catch (error) {
            return c.json({ error: "Failed to process support request" }, 500);
          }
        }
      })
    ]
  }
});
```

----------------------------------------

TITLE: Processing and Storing Initial Document Chunks in PgVector
DESCRIPTION: This snippet explains the process of chunking the initial document (`doc`) using a recursive strategy, generating embeddings for these chunks with OpenAI's `text-embedding-3-small` model, and then storing them in the `pgVector` database. It includes creating an "embeddings" index with a dimension of 1536 and upserting the embeddings along with their original text metadata.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cleanup-rag.mdx#_snippet_6

LANGUAGE: typescript
CODE:
```
const chunks = await doc.chunk({
  strategy: "recursive",
  size: 256,
  overlap: 50,
  separator: "\n",
});

const { embeddings } = await embedMany({
  model: openai.embedding("text-embedding-3-small"),
  values: chunks.map((chunk) => chunk.text),
});

const vectorStore = mastra.getVector("pgVector");
await vectorStore.createIndex({
  indexName: "embeddings",
  dimension: 1536,
});

await vectorStore.upsert({
  indexName: "embeddings",
  vectors: embeddings,
  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),
});
```

----------------------------------------

TITLE: Evaluating Prompt Alignment with @mastra/evals/llm in TypeScript
DESCRIPTION: This snippet shows how to instantiate and use the PromptAlignmentMetric with an @ai-sdk/openai model. It defines specific instructions and measures two different LLM responses against them, illustrating how the score and reason are calculated based on instruction adherence.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/prompt-alignment.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { PromptAlignmentMetric } from "@mastra/evals/llm";

// Configure the model for evaluation
const model = openai("gpt-4o-mini");

const metric = new PromptAlignmentMetric(model, {
  instructions: [
    "Use bullet points for each item",
    "Include exactly three examples",
    "End each point with a semicolon"
  ],
  scale: 1
});

const result = await metric.measure(
  "List three fruits",
  "• Apple is red and sweet;\n• Banana is yellow and curved;\n• Orange is citrus and round."
);

// Example output:
// {
//   score: 1.0,
//   info: {
//     reason: "The score is 1.0 because all instructions were followed exactly:\n          bullet points were used, exactly three examples were provided, and\n          each point ends with a semicolon."
//   }
// }

const result2 = await metric.measure(
  "List three fruits",
  "1. Apple\n2. Banana\n3. Orange and Grape"
);

// Example output:
// {
//   score: 0.33,
//   info: {
//     reason: "The score is 0.33 because: numbered lists were used instead of bullet points,\n          no semicolons were used, and four fruits were listed instead of exactly three."
//   }
// }

```

----------------------------------------

TITLE: Executing Parallel Steps in Mastra Workflows (TypeScript)
DESCRIPTION: This example illustrates how to execute multiple steps concurrently using the `.parallel()` method. All steps within the provided array will run in parallel, and the workflow will only proceed to the next chained step (e.g., `.then(step3)`) after all parallel steps have completed their execution.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/flow-control.mdx#_snippet_1

LANGUAGE: TypeScript
CODE:
```
// Execute step1 and step2 in parallel
myWorkflow
  .parallel([step1, step2])
  // Continue with step3 after both parallel steps complete
  .then(step3)
  .commit();
```

----------------------------------------

TITLE: Using createDocumentChunkerTool with Custom Parameters in TypeScript
DESCRIPTION: Illustrates how to use `createDocumentChunkerTool` with custom configuration parameters. It shows creating an `MDocument` with specific metadata and configuring the chunker with a larger size, more overlap, and a double newline separator before executing and processing the results.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/document-chunker-tool.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
const technicalDoc = new MDocument({
  text: longDocumentContent,
  metadata: {
    type: "technical",
    version: "1.0",
  },
});

const chunker = createDocumentChunkerTool({
  doc: technicalDoc,
  params: {
    strategy: "recursive",
    size: 1024, // Larger chunks
    overlap: 100, // More overlap
    separator: "\n\n", // Split on double newlines
  },
});

const { chunks } = await chunker.execute();

// Process the chunks
chunks.forEach((chunk, index) => {
  console.log(`Chunk ${index + 1} length: ${chunk.content.length}`);
});
```

----------------------------------------

TITLE: Evaluate High Relevancy - Mastra Evals - TypeScript
DESCRIPTION: Demonstrates evaluating context relevancy when all provided context information is highly relevant to the query. It initializes the `ContextRelevancyMetric` with the context and an OpenAI model, then measures the relevancy score for a given query and response.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/context-relevancy.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
const context1 = [
  "Einstein won the Nobel Prize for his discovery of the photoelectric effect.",
  "He published his theory of relativity in 1905.",
  "His work revolutionized modern physics.",
];

const metric1 = new ContextRelevancyMetric(openai("gpt-4o-mini"), {
  context: context1,
});

const query1 = "What were some of Einstein's achievements?";
const response1 =
  "Einstein won the Nobel Prize for discovering the photoelectric effect and published his groundbreaking theory of relativity.";

console.log("Example 1 - High Relevancy:");
console.log("Context:", context1);
console.log("Query:", query1);
console.log("Response:", response1);

const result1 = await metric1.measure(query1, response1);
console.log("Metric Result:", {
  score: result1.score,
  reason: result1.info.reason,
});
// Example Output:
// Metric Result: { score: 1, reason: 'The context uses all relevant information and does not include any irrelevant information.' }
```

----------------------------------------

TITLE: Evaluate Perfect Prompt Alignment - TypeScript
DESCRIPTION: This example demonstrates evaluating a response that perfectly aligns with all provided instructions using the Prompt Alignment metric. It shows how to define instructions, instantiate the metric with an AI provider, define a query and response, and measure the alignment.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/prompt-alignment.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
const instructions1 = [
  "Use complete sentences",
  "Include temperature in Celsius",
  "Mention wind conditions",
  "State precipitation chance",
];

const metric1 = new PromptAlignmentMetric(openai("gpt-4o-mini"), {
  instructions: instructions1,
});

const query1 = "What is the weather like?";
const response1 =
  "The temperature is 22 degrees Celsius with moderate winds from the northwest. There is a 30% chance of rain.";

console.log("Example 1 - Perfect Alignment:");
console.log("Instructions:", instructions1);
console.log("Query:", query1);
console.log("Response:", response1);

const result1 = await metric1.measure(query1, response1);
console.log("Metric Result:", {
  score: result1.score,
  reason: result1.info.reason,
  details: result1.info.scoreDetails,
});
// Example Output:
// Metric Result: { score: 1, reason: 'The response follows all instructions.' }
```

----------------------------------------

TITLE: Configuring a Dynamic Support Agent in TypeScript
DESCRIPTION: This snippet defines a 'Dynamic Support Agent' that adjusts its behavior based on runtime context. It dynamically sets the agent's instructions, selects an appropriate AI model (e.g., GPT-4 for enterprise users), and provides a specific set of tools based on the user's subscription tier and language preferences. This approach allows a single agent to handle diverse user needs efficiently.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/dynamic-agents.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
const supportAgent = new Agent({
  name: "Dynamic Support Agent",
  
  instructions: async ({ runtimeContext }) => {
    const userTier = runtimeContext.get("user-tier");
    const language = runtimeContext.get("language");
    
    return `You are a customer support agent for our SaaS platform.
    The current user is on the ${userTier} tier and prefers ${language} language.
    
    For ${userTier} tier users:
    ${userTier === "free" ? "- Provide basic support and documentation links" : ""}
    ${userTier === "pro" ? "- Offer detailed technical support and best practices" : ""}
    ${userTier === "enterprise" ? "- Provide priority support with custom solutions" : ""}
    
    Always respond in ${language} language.`;
  },

  model: ({ runtimeContext }) => {
    const userTier = runtimeContext.get("user-tier");
    return userTier === "enterprise" 
      ? openai("gpt-4") 
      : openai("gpt-3.5-turbo");
  },

  tools: ({ runtimeContext }) => {
    const userTier = runtimeContext.get("user-tier");
    const baseTools = [knowledgeBase, ticketSystem];
    
    if (userTier === "pro" || userTier === "enterprise") {
      baseTools.push(advancedAnalytics);
    }
    
    if (userTier === "enterprise") {
      baseTools.push(customIntegration);
    }
    
    return baseTools;
  }
});
```

----------------------------------------

TITLE: Upserting Embeddings into PgVector (TypeScript)
DESCRIPTION: This snippet demonstrates how to use the `PgVector` class to create indexes and insert embeddings into a PostgreSQL database with the pgvector extension. It involves chunking text content, generating embeddings using OpenAI's `text-embedding-3-small` model, and then upserting these vectors along with their metadata into a specified index in PgVector. The `connectionString` environment variable is required for database connection.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/upsert/upsert-embeddings.mdx#_snippet_0

LANGUAGE: tsx
CODE:
```
import { openai } from "@ai-sdk/openai";
import { PgVector } from "@mastra/pg";
import { MDocument } from "@mastra/rag";
import { embedMany } from "ai";

const doc = MDocument.fromText("Your text content...");

const chunks = await doc.chunk();

const { embeddings } = await embedMany({
  values: chunks.map(chunk => chunk.text),
  model: openai.embedding("text-embedding-3-small"),
});

const pgVector = new PgVector({ connectionString: process.env.POSTGRES_CONNECTION_STRING! });

await pgVector.createIndex({
  indexName: "test_index",
  dimension: 1536,
});

await pgVector.upsert({
  indexName: "test_index",
  vectors: embeddings,
  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),
});
```

----------------------------------------

TITLE: Embedding Single Text using AI SDK in TypeScript
DESCRIPTION: This snippet demonstrates how to use the `embed` function from the AI SDK to generate a vector embedding for a single text input. It shows how to specify the embedding model (e.g., OpenAI's `text-embedding-3-small`) and the text value to be embedded, along with an optional `maxRetries` parameter. The function returns a single embedding vector.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/embeddings.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { embed } from "ai";

const result = await embed({
  model: openai.embedding("text-embedding-3-small"),
  value: "Your text to embed",
  maxRetries: 2, // optional, defaults to 2
});
```

----------------------------------------

TITLE: Instantiating PgVector and Mastra Core Components (TypeScript)
DESCRIPTION: This snippet initializes the `PgVector` instance using the provided PostgreSQL connection string from environment variables. It then creates the main `Mastra` application instance, registering the `ragAgent` and `pgVector` components, and finally retrieves the configured agent for use.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/graph-rag.mdx#_snippet_4

LANGUAGE: TypeScript
CODE:
```
const pgVector = new PgVector({ connectionString: process.env.POSTGRES_CONNECTION_STRING! });

export const mastra = new Mastra({
  agents: { ragAgent },
  vectors: { pgVector },
});
const agent = mastra.getAgent("ragAgent");
```

----------------------------------------

TITLE: Agent Class Constructor Signature (TypeScript)
DESCRIPTION: This snippet shows the constructor signature for the `Agent` class. It accepts a single `config` object which is used to initialize the agent with various parameters like name, description, model, tools, and more.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/agent.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
constructor(config: AgentConfig<TAgentId, TTools, TMetrics>)
```

----------------------------------------

TITLE: Getting Agent Tools - Using RuntimeContext - TypeScript
DESCRIPTION: Illustrates how to define agent tools dynamically using a function that receives `runtimeContext`, allowing tools to access contextual information like API keys. Shows how to provide the context when calling `agent.getTools()`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/getTools.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { createTool } from "@mastra/core/tools";
import { RuntimeContext } from "@mastra/core/runtime-context";
import { openai } from "@ai-sdk/openai";
import { z } from "zod";

// Create an agent with dynamic tools
const agent = new Agent({
  name: "weather-assistant",
  instructions:
    "You are a weather assistant that can provide weather information.",
  model: openai("gpt-4o"),
  tools: ({ runtimeContext }) => {
    // Get API key from runtime context
    const apiKey = runtimeContext.get("weatherApiKey");

    // Create a weather tool with the API key from context
    const weatherTool = createTool({
      id: "getWeather",
      description: "Get the current weather for a location",
      inputSchema: z.object({
        location: z.string().describe("City name")
      }),
      outputSchema: z.object({
        temperature: z.number(),
        conditions: z.string(),
        humidity: z.number(),
        windSpeed: z.number()
      }),
      execute: async ({ context }) => {
        // Use the API key from runtime context
        const response = await fetch(
          `https://api.weather.com/current?location=${context.location}&apiKey=${apiKey}`,
        );
        return response.json();
      }
    });

    return {
      getWeather: weatherTool
    };
  }
});

// Create a runtime context with API key
const context = new RuntimeContext();
context.set("weatherApiKey", "your-api-key");

// Get the tools using the runtime context
const tools = await agent.getTools({ runtimeContext: context });
console.log(Object.keys(tools)); // ["getWeather"]
```

----------------------------------------

TITLE: Creating an Agent with TTS Capabilities using Mastra and OpenAI (TypeScript)
DESCRIPTION: This snippet demonstrates how to define a 'Story Teller Agent' using '@mastra/core/agent' and '@ai-sdk/openai'. It configures the agent with specific instructions, an OpenAI 'gpt-4o' model, and integrates Text-to-Speech functionality via 'OpenAIVoice'. This agent is designed to generate interactive stories on the backend.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/text-to-speech.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { OpenAIVoice } from "@mastra/voice-openai";
import { Memory } from "@mastra/memory";

const instructions = `
    You are an Interactive Storyteller Agent. Your job is to create engaging
    short stories with user choices that influence the narrative. // omitted for brevity
`;

export const storyTellerAgent = new Agent({
  name: "Story Teller Agent",
  instructions: instructions,
  model: openai("gpt-4o"),
  voice: new OpenAIVoice()
});
```

----------------------------------------

TITLE: Implementing TTS with OpenAI Voice in TypeScript
DESCRIPTION: This snippet demonstrates how to integrate OpenAI's Text-to-Speech (TTS) capabilities into a Mastra agent. It initializes an `Agent` with `OpenAIVoice`, generates text using an OpenAI model, converts the generated text into an audio stream, and plays it back. The `speaker` and `responseFormat` options can be customized.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';
import { OpenAIVoice } from "@mastra/voice-openai";
import { playAudio } from "@mastra/node-audio";

const voiceAgent = new Agent({
name: "Voice Agent",
instructions: "You are a voice assistant that can help users with their tasks.",
model: openai("gpt-4o"),
voice: new OpenAIVoice(),
});

const { text } = await voiceAgent.generate('What color is the sky?');

// Convert text to speech to an Audio Stream
const audioStream = await voiceAgent.voice.speak(text, {
speaker: "default", // Optional: specify a speaker
responseFormat: "wav", // Optional: specify a response format
});

playAudio(audioStream);
```

----------------------------------------

TITLE: Implementing Do-Until Loops in Mastra Workflows (TypeScript)
DESCRIPTION: This snippet demonstrates a `dountil` loop, which repeatedly executes a step until a specified condition becomes true. Similar to `dowhile`, the loop's `inputData` transitions from the previous step's output to the loop step's own output.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows-vnext/flow-control.mdx#_snippet_5

LANGUAGE: typescript
CODE:
```
myWorkflow
  .dountil(incrementStep, async ({ inputData }) => inputData.value >= 10)
  .then(finalStep)
  .commit();
```

----------------------------------------

TITLE: Implementing Manual Circular Dependencies for Looping in Mastra Workflow (TypeScript)
DESCRIPTION: This snippet demonstrates a traditional approach to creating loops using manual circular dependencies and conditional execution. It shows 'fetchData' and 'processData' steps, with 'finalizeData' triggered on success and 'fetchData' re-triggered on a "retry" status, effectively creating a loop based on 'processData''s outcome.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_5

LANGUAGE: TypeScript
CODE:
```
myWorkflow
  .step(fetchData)
  .then(processData)
  .after(processData)
  .step(finalizeData, {
    when: { "processData.status": "success" },
  })
  .step(fetchData, {
    when: { "processData.status": "retry" },
  });
```

----------------------------------------

TITLE: Executing the Weather Activity Workflow
DESCRIPTION: This 'main' asynchronous function demonstrates how to programmatically execute the 'weatherWorkflow'. It retrieves the workflow by its ID, creates a new run instance, and starts it with 'London' as the input city. The function then logs the final result, which includes the AI-suggested activities.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/agentic-workflows.mdx#_snippet_7

LANGUAGE: TypeScript
CODE:
```
async function main() {
  const run = mastra.getWorkflow("weatherWorkflow").createRun();

  const result = await run.start({
    inputData: {
      city: "London",
    },
  });

  console.log("\n \n");
  console.log(result);
}

main();
```

----------------------------------------

TITLE: Executing a Mastra AI Workflow (TypeScript)
DESCRIPTION: This code illustrates how to retrieve a registered workflow from the Mastra instance, create a new run for it, and then execute the workflow with specific input data. It shows the typical pattern for initiating a Mastra workflow and logging its final result to the console.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/calling-agent.mdx#_snippet_6

LANGUAGE: TypeScript
CODE:
```
import { mastra } from "./";

const workflow = mastra.getWorkflow('activityPlanningWorkflow')
const run = workflow.createRun()

// Start the workflow with New York as the city input
const result = await run.start({ inputData: { city: 'New York' } })
console.dir(result, { depth: null })
```

----------------------------------------

TITLE: Chaining Workflow Steps with .then() in TypeScript
DESCRIPTION: This snippet demonstrates how to use the `.then()` method to chain multiple workflow steps sequentially. The `step` parameter is a `Step` instance that will execute after the preceding step completes. The method returns the `NewWorkflow` instance, allowing for further method chaining.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/then.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
workflow.then(stepOne).then(stepTwo);
```

----------------------------------------

TITLE: Getting Agent Tools - Basic Usage - TypeScript
DESCRIPTION: Demonstrates how to define tools using `createTool`, pass them directly to the Agent constructor, and retrieve them using the `agent.getTools()` method.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/agents/getTools.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { createTool } from "@mastra/core/tools";
import { openai } from "@ai-sdk/openai";
import { z } from "zod";

// Create tools using createTool
const addTool = createTool({
  id: "add",
  description: "Add two numbers",
  inputSchema: z.object({
    a: z.number().describe("First number"),
    b: z.number().describe("Second number")
  }),
  outputSchema: z.number(),
  execute: async ({ context }) => {
    return context.a + context.b;
  }
});

const multiplyTool = createTool({
  id: "multiply",
  description: "Multiply two numbers",
  inputSchema: z.object({
    a: z.number().describe("First number"),
    b: z.number().describe("Second number")
  }),
  outputSchema: z.number(),
  execute: async ({ context }) => {
    return context.a * context.b;
  }
});

// Create an agent with the tools
const agent = new Agent({
  name: "calculator",
  instructions:
    "You are a calculator assistant that can perform mathematical operations.",
  model: openai("gpt-4o"),
  tools: {
    add: addTool,
    multiply: multiplyTool
  }
});

// Get the tools
const tools = await agent.getTools();
console.log(Object.keys(tools)); // ["add", "multiply"]
```

----------------------------------------

TITLE: Configuring Deepgram API Key Environment Variable
DESCRIPTION: This snippet demonstrates how to set the `DEEPGRAM_API_KEY` as an environment variable, which is a common method for providing the necessary API key for Deepgram authentication. Alternatively, the API key can be passed directly during module initialization.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/deepgram/README.md#_snippet_1

LANGUAGE: bash
CODE:
```
DEEPGRAM_API_KEY=your_api_key
```

----------------------------------------

TITLE: Installing @mastra/pg with npm
DESCRIPTION: This snippet demonstrates how to install the `@mastra/pg` package using npm, which is the standard package manager for Node.js. This command adds the package to your project's dependencies.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/pg/README.md#_snippet_0

LANGUAGE: bash
CODE:
```
npm install @mastra/pg
```

----------------------------------------

TITLE: Installing CopilotKit Runtime with npm
DESCRIPTION: This command installs the `@copilotkit/runtime` package using npm. This package provides the core backend runtime functionalities required for integrating CopilotKit with a Mastra server, enabling AI copilot features.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/copilotkit.mdx#_snippet_4

LANGUAGE: bash
CODE:
```
npm install @copilotkit/runtime
```

----------------------------------------

TITLE: Analyzing Hallucination with Detailed Example (TypeScript)
DESCRIPTION: This example further illustrates the use of `HallucinationMetric` with a more complex context and output, providing a detailed analysis of how the score is derived. It highlights how the metric identifies specific contradictions, such as the investment amount, and explains the resulting score based on the number of contradicted statements. The `measure` method accepts an object with `input` and `output` properties.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/reference/evals/hallucination.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { HallucinationMetric } from "@mastra/evals/llm";

// Configure the model for evaluation
const model = openai("gpt-4o-mini");

const metric = new HallucinationMetric(model, {
  context: [
    "OpenAI was founded in December 2015 by Sam Altman, Greg Brockman, and others.",
    "The company launched with a $1 billion investment commitment.",
    "Elon Musk was an early supporter but left the board in 2018."
  ]
});

const result = await metric.measure({
  input: "What are the key details about OpenAI?",
  output:
    "OpenAI was founded in 2015 by Elon Musk and Sam Altman with a $2 billion investment."
});

// Example output:
// {
//   score: 0.33,
//   info: {
//     reason: "The score is 0.33 because one out of three statements from the context
//           was contradicted (the investment amount was stated as $2 billion instead
//           of $1 billion). The founding date was correct, and while the output's
//           description of founders was incomplete, it wasn't strictly contradictory."
//   }
// }
```

----------------------------------------

TITLE: Cloning the Repository and Navigating (Bash)
DESCRIPTION: This command sequence clones the Mastra AI repository from GitHub and then changes the current directory to the specific Graph RAG example folder, preparing the environment for further setup.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/graph-rag/README.md#_snippet_0

LANGUAGE: bash
CODE:
```
git clone https://github.com/mastra-ai/mastra
cd examples/basics/rag/graph-rag
```

----------------------------------------

TITLE: Create Stock Agent | Mastra | TypeScript
DESCRIPTION: Defines a Mastra agent (`stockAgent`) using the `Agent` class. It configures the agent with a name, instructions, the OpenAI model (`gpt-4o-mini`), and registers the `stockPrices` tool.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/stock-agent.mdx#_snippet_5

LANGUAGE: TypeScript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";

import * as tools from "../tools/stockPrices";

export const stockAgent = new Agent<typeof tools>({
  name: "Stock Agent",
  instructions:
    "You are a helpful assistant that provides current stock prices. When asked about a stock, use the stock price tool to fetch the stock price.",
  model: openai("gpt-4o-mini"),
  tools: {
    stockPrices: tools.stockPrices,
  },
});
```

----------------------------------------

TITLE: Implementing TTS with Google Voice in TypeScript
DESCRIPTION: This snippet demonstrates how to integrate Google's Text-to-Speech (TTS) capabilities into a Mastra agent. It initializes an `Agent` with `GoogleVoice`, generates text using an OpenAI model, converts the generated text into an audio stream, and plays it back. A specific `speaker` like 'en-US-Studio-O' can be chosen for voice customization.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#_snippet_5

LANGUAGE: typescript
CODE:
```
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';
import { GoogleVoice } from "@mastra/voice-google";
import { playAudio } from "@mastra/node-audio";

const voiceAgent = new Agent({
name: "Voice Agent",
instructions: "You are a voice assistant that can help users with their tasks.",
model: openai("gpt-4o"),
voice: new GoogleVoice(),
});

const { text } = await voiceAgent.generate('What color is the sky?');

// Convert text to speech to an Audio Stream
const audioStream = await voiceAgent.voice.speak(text, {
speaker: "en-US-Studio-O", // Optional: specify a speaker
});

playAudio(audioStream);
```

----------------------------------------

TITLE: Defining an Activity Planning Workflow with Mastra Steps
DESCRIPTION: This TypeScript code defines `activityPlanningWorkflow` using `@mastra/core/workflows/vNext`. It consists of two steps: `fetchWeather` (which retrieves weather data for a given city using Open-Meteo APIs) and `planActivities` (which uses the `planningAgent` to generate activity recommendations based on the fetched weather forecast). The workflow uses `zod` for schema validation and orchestrates external API calls with AI agent interaction.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows_vNext/calling-agent.mdx#_snippet_2

LANGUAGE: ts
CODE:
```
import { createWorkflow, createStep } from '@mastra/core/workflows/vNext'
import { z } from 'zod'
 
// Helper function to convert numeric weather codes to human-readable descriptions
function getWeatherCondition(code: number): string {
  const conditions: Record<number, string> = {
    0: "Clear sky",
    1: "Mainly clear",
    2: "Partly cloudy",
    3: "Overcast",
    45: "Foggy",
    48: "Depositing rime fog",
    51: "Light drizzle",
    53: "Moderate drizzle",
    55: "Dense drizzle",
    61: "Slight rain",
    63: "Moderate rain",
    65: "Heavy rain",
    71: "Slight snow fall",
    73: "Moderate snow fall",
    75: "Heavy snow fall",
    95: "Thunderstorm",
  };
  return conditions[code] || "Unknown";
}
 
const forecastSchema = z.object({
  date: z.string(),
  maxTemp: z.number(),
  minTemp: z.number(),
  precipitationChance: z.number(),
  condition: z.string(),
  location: z.string(),
})
 
// Step 1: Create a step to fetch weather data for the specified city
const fetchWeather = createStep({
  id: "fetch-weather",
  description: "指定された都市の天気予報を取得します",
  inputSchema: z.object({
    city: z.string(),
  }),
  outputSchema: forecastSchema,
  execute: async ({ inputData }) => {
    if (!inputData) {
      throw new Error("トリガーデータが見つかりません");
    }
 
    // First API call: Convert city name to latitude and longitude
    const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(inputData.city)}&count=1`    
    const geocodingResponse = await fetch(geocodingUrl)
    const geocodingData = (await geocodingResponse.json()) as {
      results: { latitude: number; longitude: number; name: string }[]
    }
 
    if (!geocodingData.results?.[0]) {
      throw new Error(`場所 '${inputData.city}' が見つかりません`);
    }
 
    const { latitude, longitude, name } = geocodingData.results[0]
 
    // Second API call: Get weather data using coordinates
    const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=precipitation,weathercode&timezone=auto,&hourly=precipitation_probability,temperature_2m`
    const response = await fetch(weatherUrl)
    const data = (await response.json()) as {
      current: {
        time: string;
        precipitation: number;
        weathercode: number;
      };
      hourly: {
        precipitation_probability: number[]
        temperature_2m: number[]
      }
    }
 
    const forecast = {
      date: new Date().toISOString(),
      maxTemp: Math.max(...data.hourly.temperature_2m),
      minTemp: Math.min(...data.hourly.temperature_2m),
      condition: getWeatherCondition(data.current.weathercode),
      location: name,
      precipitationChance: data.hourly.precipitation_probability.reduce(
        (acc, curr) => Math.max(acc, curr),
        0,
      ),
    }
 
    return forecast
  },
})
 
// Step 2: Create a step to generate activity recommendations using the agent
const planActivities = createStep({
  id: "plan-activities",
  description: "天候に基づいてアクティビティを提案します",
  inputSchema: forecastSchema,
  outputSchema: z.object({
    activities: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    const forecast = inputData
 
    if (!forecast) {
      throw new Error("予報データが見つかりません");
    }
 
    const prompt = `${forecast.location}の以下の天気予報に基づいて、適切なアクティビティを提案してください：\n      ${JSON.stringify(forecast, null, 2)}\n      `
 
    const agent = mastra?.getAgent('planningAgent')
    if (!agent) {
      throw new Error("プランニングエージェントが見つかりません");
    }
 
    const response = await agent.stream([
      {
        role: "user",
        content: prompt,
      },
    ])
 
    let activitiesText = ''
    for await (const chunk of response.textStream) {
      process.stdout.write(chunk);
      activitiesText += chunk;
    }
 
    return {
      activities: activitiesText,
    };
  },
})
 
const activityPlanningWorkflow = createWorkflow({
  steps: [fetchWeather, planActivities],
  id: 'activity-planning-step1-single-day',
  inputSchema: z.object({
    city: z.string().describe("天気を取得する都市"),
  }),
  outputSchema: z.object({
    activities: z.string(),
  }),
})
  .then(fetchWeather)
  .then(planActivities)
 
activityPlanningWorkflow.commit()
 
export { activityPlanningWorkflow }
```

----------------------------------------

TITLE: Setting Up OpenAI API Key in .env - Bash
DESCRIPTION: This snippet guides you on creating a '.env' file in your project's root directory and adding your OpenAI API key. This environment variable is essential for authenticating API requests and should be replaced with your actual key for secure access.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_10

LANGUAGE: bash
CODE:
```
OPENAI_API_KEY=<your-api-key>
```

----------------------------------------

TITLE: Configuring OpenAI Voice Provider in TypeScript
DESCRIPTION: This snippet demonstrates how to initialize the OpenAI voice provider. It configures both a `speechModel` (e.g., `gpt-3.5-turbo`) and a `listeningModel` (e.g., `whisper-1`), specifying API keys, language, and voice type/format. It requires `process.env.OPENAI_API_KEY` for authentication.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#_snippet_20

LANGUAGE: typescript
CODE:
```
// OpenAI Voice Configuration
const voice = new OpenAIVoice({
  speechModel: {
    name: "gpt-3.5-turbo", // Example model name
    apiKey: process.env.OPENAI_API_KEY,
    language: "en-US", // Language code
    voiceType: "neural", // Type of voice model
  },
  listeningModel: {
    name: "whisper-1", // Example model name
    apiKey: process.env.OPENAI_API_KEY,
    language: "en-US", // Language code
    format: "wav", // Audio format
  },
  speaker: "alloy", // Example speaker name
});
```

----------------------------------------

TITLE: Create and Use a Simple Custom Memory Processor
DESCRIPTION: Extend the MemoryProcessor class to create custom logic for processing messages. This example shows a processor that keeps only the most recent messages and how to use it with Memory.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/memory-processors.mdx#_snippet_6

LANGUAGE: typescript
CODE:
```
import type { CoreMessage } from "@mastra/core";
import { MemoryProcessor } from "@mastra/core/memory";
import { Memory } from "@mastra/memory";

// Simple processor that keeps only the most recent messages
class RecentMessagesProcessor extends MemoryProcessor {
  private limit: number;

  constructor(limit: number = 10) {
    super();
    this.limit = limit;
  }

  process(messages: CoreMessage[]): CoreMessage[] {
    // Keep only the most recent messages
    return messages.slice(-this.limit);
  }
}

// Use the custom processor
const memory = new Memory({
  processors: [
    new RecentMessagesProcessor(5), // Keep only the last 5 messages
    new TokenLimiter(16000),
  ],
});
```

----------------------------------------

TITLE: Executing the Activity Planning Workflow with Mastra
DESCRIPTION: This TypeScript code demonstrates how to execute the `activityPlanningWorkflow` registered with the Mastra instance. It retrieves the workflow by its ID, creates a new run, and starts it with "New York" as the input city, then logs the final result of the workflow execution.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows_vNext/calling-agent.mdx#_snippet_4

LANGUAGE: ts
CODE:
```
import { mastra } from "./";

const workflow = mastra.vnext_getWorkflow('activityPlanningWorkflow')
const run = workflow.createRun()

// Start the workflow with New York as the city input
const result = await run.start({ inputData: { city: 'New York' } })
console.dir(result, { depth: null })
```

----------------------------------------

TITLE: Loading and Chunking Research Paper (TypeScript)
DESCRIPTION: This TypeScript code fetches the Transformer paper from a URL, converts its HTML content into a `MDocument` object, and then chunks it into smaller, manageable pieces. The chunking strategy is recursive with specified size, overlap, and separator, preparing the text for embedding and efficient retrieval by the RAG system.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/research-assistant.mdx#_snippet_3

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { MDocument } from "@mastra/rag";
import { embedMany } from "ai";
import { mastra } from "./mastra";

// Load the paper
const paperUrl = "https://arxiv.org/html/1706.03762";
const response = await fetch(paperUrl);
const paperText = await response.text();

// Create document and chunk it
const doc = MDocument.fromText(paperText);
const chunks = await doc.chunk({
  strategy: "recursive",
  size: 512,
  overlap: 50,
  separator: "\n",
});

console.log("Number of chunks:", chunks.length);
// Number of chunks: 893
```

----------------------------------------

TITLE: Defining Mastra Agents for Travel Planning (TypeScript)
DESCRIPTION: This TypeScript code defines two Mastra Agent instances: summaryTravelAgent for generating initial holiday options and travelAgent for creating detailed itineraries. Both agents utilize the OpenAI gpt-4o model and are configured with specific instructions for their respective travel planning tasks.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/human-in-the-loop.mdx#_snippet_1

LANGUAGE: ts
CODE:
```
import { Agent } from '@mastra/core/agent'
import { openai } from '@ai-sdk/openai'
 
const llm = openai('gpt-4o')
 
// Agent that generates multiple holiday options
// Returns a JSON array of locations and descriptions
export const summaryTravelAgent = new Agent({
  name: "summaryTravelAgent",
  model: llm,
  instructions: `
  You are a travel agent who is given a user prompt about what kind of holiday they want to go on.
  You then generate 3 different options for the holiday. Return the suggestions as a JSON array {"location": "string", "description": "string"}[]. Don't format as markdown.
  Make the options as different as possible from each other.
  Also make the plan very short and summarized.
  `,
})

// Agent that creates detailed travel plans
// Takes the selected option and generates a comprehensive itinerary
export const travelAgent = new Agent({
  name: "travelAgent",
  model: llm,
  instructions: `
  You are a travel agent who is given a user prompt about what kind of holiday they want to go on. A summary of the plan is provided as well as the location.
  You then generate a detailed travel plan for the holiday.
  `,
});
```

----------------------------------------

TITLE: Copying Environment Variables File (Bash)
DESCRIPTION: This command copies the `.env.example` file to `.env`, which is a common practice for managing environment-specific configurations like API keys without committing them to version control.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-chunk/README.md#_snippet_1

LANGUAGE: bash
CODE:
```
cp .env.example .env
```

----------------------------------------

TITLE: Configuring ElevenLabs Voice Provider in TypeScript
DESCRIPTION: This snippet illustrates the configuration of the ElevenLabs voice provider, focusing on the `speechModel`. It specifies a `voiceId`, `model`, `apiKey`, `language`, and `emotion`. Note that ElevenLabs may not have a separate listening model. It requires `process.env.ELEVENLABS_API_KEY`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#_snippet_22

LANGUAGE: typescript
CODE:
```
// ElevenLabs Voice Configuration
const voice = new ElevenLabsVoice({
  speechModel: {
    voiceId: "your-voice-id", // Example voice ID
    model: "eleven_multilingual_v2", // Example model name
    apiKey: process.env.ELEVENLABS_API_KEY,
    language: "en", // Language code
    emotion: "neutral", // Emotion setting
  },
  // ElevenLabs may not have a separate listening model
});
```

----------------------------------------

TITLE: Copying Environment Variables File (Bash)
DESCRIPTION: This command copies the example environment variables file (.env.example) to .env, which is the standard file for local environment configurations, serving as a template for user-specific settings.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/cot-rag/README.md#_snippet_1

LANGUAGE: Bash
CODE:
```
cp .env.example .env
```

----------------------------------------

TITLE: Executing Mastra Activity Planning Workflow in TypeScript
DESCRIPTION: This snippet demonstrates how to retrieve and execute the `activityPlanningWorkflow` from the initialized Mastra instance. It creates a new run, provides the necessary input data (e.g., city), and starts the workflow execution, logging the final results.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows_vNext/parallel-steps.mdx#_snippet_2

LANGUAGE: TypeScript
CODE:
```
import { mastra } from "./";

const workflow = mastra.vnext_getWorkflow('activityPlanningWorkflow')
const run = workflow.createRun()

// Execute the workflow with a specific city
// This will run through all steps and generate activity recommendations
const result = await run.start({ inputData: { city: 'Ibiza' } })
console.dir(result, { depth: null })
```

----------------------------------------

TITLE: Configuring useChat for Latest Message with Mastra Memory (React)
DESCRIPTION: This React component demonstrates how to configure the Vercel AI SDK's `useChat` hook to send only the latest user message, along with `threadId` and `resourceId`, to a backend API. This prevents message duplication when integrating with Mastra's memory, which automatically retrieves full chat history. It uses `experimental_prepareRequestBody` to customize the request body.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/use-chat.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
// components/Chat.tsx (React Example)
import { useChat } from "ai/react";

export function Chat({ threadId, resourceId }) {
  const { messages, input, handleInputChange, handleSubmit } = useChat({
    api: "/api/chat", // Your backend endpoint
    // Pass only the latest message and custom IDs
    experimental_prepareRequestBody: (request) => {
      // Ensure messages array is not empty and get the last message
      const lastMessage = request.messages.length > 0 ? request.messages[request.messages.length - 1] : null;

      // Return the structured body for your API route
      return {
        message: lastMessage, // Send only the most recent message content/role
        threadId,
        resourceId,
      };
    },
    // Optional: Initial messages if loading history from backend
    // initialMessages: loadedMessages,
  });

  // ... rest of your chat UI component
  return (
    <div>
      {/* Render messages */}
      <form onSubmit={handleSubmit}>
        <input value={input} onChange={handleInputChange} placeholder="Send a message..." />
        <button type="submit">Send</button>
      </form>
    </div>
  );
}
```

----------------------------------------

TITLE: Upserting Vectors and Metadata into Couchbase
DESCRIPTION: Stores vector embeddings and associated metadata as documents in the configured Couchbase collection. Accepts arrays of vectors and metadata. Document IDs can be auto-generated or provided. Includes error handling.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/couchbase/README.md#_snippet_3

LANGUAGE: typescript
CODE:
```
const vectors = [
  Array(vectorDimension).fill(0.1), // Replace with your actual vectors
  Array(vectorDimension).fill(0.2),
];
const metadata = [
  { source: 'doc1.txt', page: 1, category: 'finance' },
  { source: 'doc2.pdf', page: 5, text: 'This is the text content.', category: 'tech' }, // Example with text
];

try {
  // IDs will be auto-generated UUIDs if not provided
  const ids = await vectorStore.upsert({
    indexName: indexName, // Required for dimension validation if tracked
    vectors: vectors,
    metadata: metadata,
    // ids: ['custom_id_1', 'custom_id_2'] // Optionally provide your own IDs
  });
  console.log('Upserted documents with IDs:', ids);
} catch (error) {
  console.error('Failed to upsert vectors:', error);
}
```

----------------------------------------

TITLE: Executing Hierarchical Multi-Agent System in Mastra (TypeScript)
DESCRIPTION: This snippet demonstrates how to invoke the hierarchical multi-agent system. It retrieves the `publisherAgent` from the `mastra` instance and calls its `generate` method with a specific topic. The `publisherAgent` then coordinates the `copywriterTool` and `editorTool` to produce and refine the blog post, with the final edited copy logged to the console.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/hierarchical-multi-agent.mdx#_snippet_3

LANGUAGE: TypeScript
CODE:
```
async function main() {
  const agent = mastra.getAgent("publisherAgent");
  const result = await agent.generate(
    "Write a blog post about React JavaScript frameworks. Only return the final edited copy.",
  );
  console.log(result.text);
}

main();
```

----------------------------------------

TITLE: Type-Safe Data Access with getStepResult Method in Mastra
DESCRIPTION: This snippet demonstrates the basic usage of the `getStepResult` method for type-safe access to previous step results in a Mastra workflow. It shows how to explicitly provide a type parameter to `getStepResult` to ensure correct type inference when retrieving data from `fetchUserStep`, enhancing code reliability and maintainability.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows/control-flow.mdx#_snippet_13

LANGUAGE: TypeScript
CODE:
```
import { Step, Workflow } from "@mastra/core/workflows";
import { z } from "zod";

const fetchUserStep = new Step({
  id: "fetchUser",
  outputSchema: z.object({
    name: z.string(),
    userId: z.string(),
  }),
  execute: async ({ context }) => {
    return { name: "John Doe", userId: "123" };
  },
});

const analyzeDataStep = new Step({
  id: "analyzeData",
  execute: async ({ context }) => {
    // Type-safe access to previous step result
    const userData = context.getStepResult<{ name: string; userId: string }>(
      "fetchUser",
    );

    if (!userData) {
      return { status: "error", message: "User data not found" };
    }

    return {
      analysis: `Analyzed data for user ${userData.name}`,
      userId: userData.userId,
    };
  },
});
```

----------------------------------------

TITLE: Initializing Node.js Project and Dependencies (Bash)
DESCRIPTION: This snippet outlines the initial setup for a Node.js project, including creating the project directory, initializing npm, installing necessary Mastra and AI SDK dependencies, configuring environment variables for API keys and database connections, and creating the required file structure for the application.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/research-assistant.mdx#_snippet_0

LANGUAGE: bash
CODE:
```
mkdir research-assistant
cd research-assistant
```

LANGUAGE: bash
CODE:
```
npm init -y
npm install @mastra/core@latest @mastra/rag@latest @mastra/pg@latest @ai-sdk/openai@latest ai@latest zod@latest
```

LANGUAGE: bash
CODE:
```
OPENAI_API_KEY=your_openai_api_key
POSTGRES_CONNECTION_STRING=your_connection_string
```

LANGUAGE: bash
CODE:
```
mkdir -p src/mastra/agents
touch src/mastra/agents/researchAgent.ts
touch src/mastra/index.ts src/store.ts src/index.ts
```

----------------------------------------

TITLE: Creating Mastra Backend Project with npm
DESCRIPTION: Command to initialize a new Mastra backend project using `npm`. This project will serve as a separate AI backend for a Next.js application, allowing independent scaling and clear separation of concerns.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#_snippet_1

LANGUAGE: bash
CODE:
```
npm create mastra
```

----------------------------------------

TITLE: Implementing MCPServerResources for Mastra AI (TypeScript)
DESCRIPTION: Provides an example implementation of MCPServerResources for a Mastra AI MCP server. It demonstrates how to define static resources, their contents, and resource templates, and then integrate these handlers into a new MCPServer instance. This setup allows the server to respond to client requests for resource listing and content retrieval.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/mcp-server.mdx#_snippet_21

LANGUAGE: typescript
CODE:
```
import { MCPServer } from "@mastra/mcp";
import type { MCPServerResourceContent, Resource, ResourceTemplate } from "@mastra/mcp";

// Resources/resource templates will generally be dynamically fetched.
const myResources: Resource[] = [
  { uri: "file://data/123.txt", name: "Data File", mimeType: "text/plain" },
];

const myResourceContents: Record<string, MCPServerResourceContent> = {
  "file://data.txt/123": { text: "This is the content of the data file." },
};

const myResourceTemplates: ResourceTemplate[] = [
  {
    uriTemplate: 'file://data/{id}',
    name: 'Data File',
    description: 'A file containing data.',
    mimeType: 'text/plain',
  },
];

const myResourceHandlers: MCPServerResources = {
  listResources: async () => myResources,
  getResourceContent: async ({ uri }) => {
    if (myResourceContents[uri]) {
      return myResourceContents[uri];
    }
    throw new Error(`Resource content not found for ${uri}`);
  },
  resourceTemplates: async () => myResourceTemplates,
};

const serverWithResources = new MCPServer({
  name: "Resourceful Server",
  version: "1.0.0",
  tools: { /* ... your tools ... */ },
  resources: myResourceHandlers,
});
```

----------------------------------------

TITLE: Initializing and Using PinoLogger for Console Logging in TypeScript
DESCRIPTION: This snippet demonstrates how to initialize a `PinoLogger` instance for console logging with a specified name and minimum logging level. It then shows examples of logging messages at `debug`, `info`, and `error` levels, illustrating how the configured level (`info`) affects which messages are recorded. It also highlights the use of structured log messages for `info` level.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/logger.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
// Using a console logger
const logger = new PinoLogger({ name: "Mastra", level: "info" });

logger.debug("Debug message"); // Won't be logged because level is INFO
logger.info({
  message: "User action occurred",
  destinationPath: "user-actions",
  type: "AGENT",
}); // Logged
logger.error("An error occurred"); // Logged as ERROR
```

----------------------------------------

TITLE: Initializing Mastra Client (TypeScript)
DESCRIPTION: Demonstrates how to import the MastraClient class from the @mastra/client-js SDK and create a new instance of the client. This is the first step to interact with the Mastra API.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/vectors.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { MastraClient } from "@mastra/client-js";

const client = new MastraClient();
```

----------------------------------------

TITLE: Defining Copywriter Agent and Tool in Mastra (TypeScript)
DESCRIPTION: This snippet defines the `Copywriter` agent responsible for generating blog post copy and its associated `copywriterTool`. The tool integrates with the agent, allowing it to be called with a `topic` input and returning the generated `copy`. It uses Anthropic's Claude model for content generation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/hierarchical-multi-agent.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { anthropic } from "@ai-sdk/anthropic";

const copywriterAgent = new Agent({
  name: "Copywriter",
  instructions: "You are a copywriter agent that writes blog post copy.",
  model: anthropic("claude-3-5-sonnet-20241022"),
});

const copywriterTool = createTool({
  id: "copywriter-agent",
  description: "Calls the copywriter agent to write blog post copy.",
  inputSchema: z.object({
    topic: z.string().describe("Blog post topic"),
  }),
  outputSchema: z.object({
    copy: z.string().describe("Blog post copy"),
  }),
  execute: async ({ context }) => {
    const result = await copywriterAgent.generate(
      `Create a blog post about ${context.topic}`,
    );
    return { copy: result.text };
  },
});
```

----------------------------------------

TITLE: Implementing Tree of Thought Prompting in Mastra (TypeScript)
DESCRIPTION: This snippet demonstrates how to implement tree of thought prompting in Mastra, enabling the model to explore multiple solution paths or perspectives simultaneously. By defining `branches` within the `thinking` property, the model can consider different aspects of a complex problem, such as technical, user experience, and business impacts.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/examples.md#_snippet_4

LANGUAGE: typescript
CODE:
```
type ProblemSolvingVars = {
  problem: string;
};

const problemSolver = createPrompt<ProblemSolvingVars>('Solve complex problem', {
  persona: 'Problem Solver',
  outputFormat: 'markdown',
})
  .text('Solve this problem:\n\n{{problem}}')
  .thinking({
    branches: {
      'Technical Solution': [
        'Analyze technical requirements',
        'Consider implementation options',
        'Evaluate technical tradeoffs',
      ],
      'User Experience': ['Identify user needs', 'Design user interactions', 'Consider accessibility'],
      'Business Impact': ['Assess costs', 'Evaluate timeline', 'Consider scalability'],
    },
  });

// Usage example
const solution = problemSolver.toString({
  problem: 'Design a new feature for uploading and processing large files in a web application',
});
```

----------------------------------------

TITLE: Initialize Mastra Agents with Voice Capabilities | TypeScript
DESCRIPTION: Imports necessary modules and initializes two Mastra agents. Agent 1 uses CompositeVoice with OpenAI for STT and PlayAI for TTS, while Agent 2 uses OpenAIVoice for both. This sets up the agents for voice interaction demonstrations.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/adding-voice-capabilities.mdx#_snippet_0

LANGUAGE: ts
CODE:
```
// Import required dependencies
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { CompositeVoice } from "@mastra/core/voice";
import { OpenAIVoice } from "@mastra/voice-openai";
import { createReadStream, createWriteStream } from "fs";
import { PlayAIVoice } from "@mastra/voice-playai";
import path from "path";

// Initialize Agent 1 with both listening and speaking capabilities
const agent1 = new Agent({
  name: "Agent1",
  instructions: `You are an agent with both STT and TTS capabilities.`,
  model: openai("gpt-4o"),
  voice: new CompositeVoice({
    input: new OpenAIVoice(), // For converting speech to text
    output: new PlayAIVoice(), // For converting text to speech
  }),
});

// Initialize Agent 2 with just OpenAI for both listening and speaking capabilities
const agent2 = new Agent({
  name: "Agent2",
  instructions: `You are an agent with both STT and TTS capabilities.`,
  model: openai("gpt-4o"),
  voice: new OpenAIVoice(),
});
```

----------------------------------------

TITLE: Running a Mastra Workflow and Processing Results in TypeScript
DESCRIPTION: This snippet details the process of executing a defined workflow. It shows how to create a run instance, start the workflow with input data, and then access the results, including individual step outputs. It also demonstrates how to handle different workflow statuses: `success`, `suspended` (with resume functionality), and `failed` (with error handling).
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#_snippet_6

LANGUAGE: typescript
CODE:
```
// Create a run instance
const run = myWorkflow.createRun();

// Start the workflow with input data
const result = await run.start({
  inputData: {
    startValue: "initial data",
  },
});

// Access the results
console.log(result.steps); // All step results
console.log(result.steps["step-id"].output); // Output from a specific step

if (result.status === "success") {
  console.log(result.result); // The final result of the workflow, result of the last step (or `.map()` output, if used as last step)
} else if (result.status === "suspended") {
  const resumeResult = await run.resume({
    step: result.suspended[0], // there is always at least one step id in the suspended array, in this case we resume the first suspended execution path
    resumeData: {
      /* user input */
    },
  });
} else if (result.status === "failed") {
  console.error(result.error); // only exists if status is failed, this is an instance of Error
}
```

----------------------------------------

TITLE: Initializing Mastra with OpenTelemetry Telemetry (TypeScript)
DESCRIPTION: This TypeScript code demonstrates how to initialize the Mastra application and configure its telemetry settings for OpenTelemetry. It sets a serviceName, enables telemetry, and specifies otlp as the export type, ensuring that Mastra's observability data is sent to an OTLP-compatible collector like SigNoz.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/signoz.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { Mastra } from "@mastra/core";

export const mastra = new Mastra({
  // ... other config
  telemetry: {
    serviceName: "your-service-name",
    enabled: true,
    export: {
      type: "otlp"
    }
  }
});
```

----------------------------------------

TITLE: Vitest Test Setup for Mastra Evals Listeners
DESCRIPTION: This snippet defines a test setup file for Vitest. It uses `beforeAll` to call `attachListeners` from `@mastra/evals`, which is necessary to capture eval results during the test run.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/evals/running-in-ci.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
import { beforeAll } from "vitest";
import { attachListeners } from "@mastra/evals";

beforeAll(async () => {
  await attachListeners();
});
```

----------------------------------------

TITLE: Chaining Sequential Steps in Mastra Workflows (TypeScript)
DESCRIPTION: This snippet demonstrates how to chain steps for sequential execution using the `.then()` method in a Mastra (vNext) workflow. Outputs from one step are automatically passed as input to the next if schemas match, or can be transformed using a `map` function. This chaining is type-safe and checked at compile time.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows-vnext/flow-control.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
myWorkflow.then(step1).then(step2).then(step3).commit();
```

----------------------------------------

TITLE: Suggesting Indoor Activities for Rainy Weather with Mastra AI (TypeScript)
DESCRIPTION: This `planIndoorActivities` step is specifically designed to suggest indoor activities, particularly useful for rainy weather conditions. It takes the weather forecast as input, crafts a prompt focused on indoor options, and then streams a response from the 'planningAgent' through Mastra AI to generate the activity suggestions.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/inngest-workflow.mdx#_snippet_5

LANGUAGE: TypeScript
CODE:
```
const planIndoorActivities = createStep({
  id: 'plan-indoor-activities',
  description: 'Suggests indoor activities based on weather conditions',
  inputSchema: forecastSchema,
  outputSchema: z.object({
    activities: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    const forecast = inputData
 
    if (!forecast) {
      throw new Error('Forecast data not found')
    }
 
    const prompt = `In case it rains, plan indoor activities for ${forecast.location} on ${forecast.date}`
 
    const agent = mastra?.getAgent('planningAgent')
    if (!agent) {
      throw new Error('Planning agent not found')
    }
 
    const response = await agent.stream([
      {
        role: 'user',
        content: prompt,
      },
    ])
 
    let activitiesText = ''
 
    for await (const chunk of response.textStream) {
      process.stdout.write(chunk)
      activitiesText += chunk
    }
 
    return {
      activities: activitiesText,
    }
  },
})
```

----------------------------------------

TITLE: Streaming AI Responses via Next.js API Route with Mastra AI
DESCRIPTION: This Next.js API route handles POST requests to stream weather information using a Mastra AI agent. It extracts the city from the request body, retrieves the 'weatherAgent', and uses `agent.stream` to get a streaming response, which is then converted to a `DataStreamResponse` for the client.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#_snippet_17

LANGUAGE: TypeScript
CODE:
```
import { mastra } from "@/mastra";
import { NextResponse } from "next/server";

export async function POST(req: Request) {
  const { city } = await req.json();
  const agent = mastra.getAgent("weatherAgent");

  const result = await agent.stream(`What's the weather like in ${city}?`);

  return result.toDataStreamResponse();
}
```

----------------------------------------

TITLE: Executing Mastra Workflow (TypeScript)
DESCRIPTION: This snippet demonstrates how to execute a registered Mastra workflow. It retrieves the `activityPlanningWorkflow` by its ID, creates a new run instance, and then starts the run with the required `inputData` (e.g., `city: 'New York'`). The result of the workflow execution is then logged to the console.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/conditional-branching.mdx#_snippet_8

LANGUAGE: TypeScript
CODE:
```
import { mastra } from ".";

const workflow = mastra.getWorkflow('activityPlanningWorkflow')
const run = workflow.createRun()

// Start the workflow with a city
// This will fetch weather and plan activities based on conditions
const result = await run.start({ inputData: { city: 'New York' } })
console.dir(result, { depth: null })
```

----------------------------------------

TITLE: Initializing Agent with Single OpenAI Voice Provider (TypeScript)
DESCRIPTION: Configures a Mastra agent to use `OpenAIVoice` for both speech synthesis and transcription. It initializes the voice provider, creates the agent, and demonstrates how to use the `speak` method to generate audio and the `listen` method to transcribe audio streams.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/adding-voice.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { createReadStream } from "fs";
import path from "path";
import { Agent } from "@mastra/core/agent";
import { OpenAIVoice } from "@mastra/voice-openai";
import { openai } from "@ai-sdk/openai";

// Initialize the voice provider with default settings
const voice = new OpenAIVoice();

// Create an agent with voice capabilities
export const agent = new Agent({
  name: "Agent",
  instructions: `You are a helpful assistant with both STT and TTS capabilities.`,
  model: openai("gpt-4o"),
  voice,
});

// The agent can now use voice for interaction
const audioStream = await agent.voice.speak("Hello, I'm your AI assistant!", {
  filetype: "m4a",
});

playAudio(audioStream!);

try {
  const transcription = await agent.voice.listen(audioStream);
  console.log(transcription);
} catch (error) {
  console.error("Error transcribing audio:", error);
}
```

----------------------------------------

TITLE: Defining a Workflow with a Do-Until Loop (TypeScript)
DESCRIPTION: Defines a complete workflow using `createWorkflow` that incorporates a `.dountil()` loop. This example demonstrates how to set up input and output schemas for the workflow and integrate the loop.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_12

LANGUAGE: typescript
CODE:
```
const workflow = createWorkflow({
  id: 'increment-workflow',
  inputSchema: z.object({
    value: z.number(),
  }),
  outputSchema: z.object({
    value: z.number(),
  }),
})
  .dountil(incrementStep, async ({ inputData }) => inputData.value >= 10)
  .then(finalStep);
```

----------------------------------------

TITLE: Using AgentNetwork for Agent Collaboration (TypeScript)
DESCRIPTION: Demonstrates how to import, instantiate, configure, and use the `AgentNetwork` class to coordinate specialized agents for a task like research. Shows creating individual agents and then adding them to the network.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/networks/agent-network.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { AgentNetwork } from "@mastra/core/network";
import { openai } from "@mastra/openai";

// Create specialized agents
const webSearchAgent = new Agent({
  name: "Web Search Agent",
  instructions: "You search the web for information.",
  model: openai("gpt-4o"),
  tools: {
    /* web search tools */
  },
});

const dataAnalysisAgent = new Agent({
  name: "Data Analysis Agent",
  instructions: "You analyze data and provide insights.",
  model: openai("gpt-4o"),
  tools: {
    /* data analysis tools */
  },
});

// Create the network
const researchNetwork = new AgentNetwork({
  name: "Research Network",
  instructions: "Coordinate specialized agents to research topics thoroughly.",
  model: openai("gpt-4o"),
  agents: [webSearchAgent, dataAnalysisAgent],
});

// Use the network
const result = await researchNetwork.generate(
  "Research the impact of climate change on agriculture",
);
console.log(result.text);
```

----------------------------------------

TITLE: Configuring OpenAI API Key - .env.development
DESCRIPTION: This snippet shows how to set the OpenAI API key in the `.env.development` file. Replace `your_api_key_here` with your actual OpenAI API key to enable AI-powered features.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/voice/interactive-story/README.md#_snippet_1

LANGUAGE: env
CODE:
```
OPENAI_API_KEY=your_api_key_here
```

----------------------------------------

TITLE: Filtering Retrieval Results by Simple Metadata Equality (TypeScript)
DESCRIPTION: This snippet demonstrates how to filter semantic search results based on a simple equality condition on a metadata field. It queries the vector store for chunks where the 'source' metadata exactly matches 'article1.txt', narrowing down the search space to specific documents.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/retrieval.mdx#_snippet_2

LANGUAGE: ts
CODE:
```
// Simple equality filter
const results = await pgVector.query({
  indexName: "embeddings",
  queryVector: embedding,
  topK: 10,
  filter: {
    source: "article1.txt"
  }
});
```

----------------------------------------

TITLE: Accessing RuntimeContext in Tool | Mastra | TypeScript
DESCRIPTION: Shows how a tool's execute function receives the runtimeContext and how to retrieve type-safe values using the .get() method for use within the tool's logic.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/tools-mcp/dynamic-context.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { createTool } from "@mastra/core/tools";
import { z } from "zod";
// Assume WeatherRuntimeContext is defined as above and accessible here

// Dummy fetch function
async function fetchWeather(
  location: string,
  options: { temperatureUnit: "celsius" | "fahrenheit" },
): Promise<any> {
  console.log(`Fetching weather for ${location} in ${options.temperatureUnit}`);
  // Replace with actual API call
  return { temperature: options.temperatureUnit === "celsius" ? 20 : 68 };
}

export const weatherTool = createTool({
  id: "getWeather",
  description: "Get the current weather for a location",
  inputSchema: z.object({
    location: z.string().describe("The location to get weather for"),
  }),
  // The tool's execute function receives runtimeContext
  execute: async ({ context, runtimeContext }) => {
    // Type-safe access to runtimeContext variables
    const temperatureUnit = runtimeContext.get("temperature-scale");

    // Use the context value in the tool logic
    const weather = await fetchWeather(context.location, {
      temperatureUnit,
    });

    return {
      result: `The temperature is ${weather.temperature}°${temperatureUnit === "celsius" ? "C" : "F"}`,
    };
  },
});
```

----------------------------------------

TITLE: Evaluating AI Response Faithfulness with Context - TypeScript
DESCRIPTION: This snippet illustrates how to use the `FaithfulnessMetric` to evaluate an AI model's response against provided context. It initializes the metric with an OpenAI model and a list of contextual statements, then measures how faithfully the output adheres to this context. The result includes a score and detailed reasoning.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/evals/README.md#_snippet_2

LANGUAGE: typescript
CODE:
```
import { FaithfulnessMetric } from '@mastra/evals';

// Initialize with context
const faithfulnessMetric = new FaithfulnessMetric({
  model: openai('gpt-4'),
  context: ['Paris is the capital of France', 'Paris has a population of 2.2 million'],
  scale: 1,
});

// Evaluate response against context
const result = await faithfulnessMetric.measure(
  'Tell me about Paris',
  'Paris is the capital of France with 2.2 million residents',
);

console.log('Faithfulness Score:', result.score);
console.log('Reasoning:', result.reason);
```

----------------------------------------

TITLE: Processing Text Documents into Chunks for RAG (TypeScript)
DESCRIPTION: This code demonstrates how to load a text document using `MDocument.fromText` and then chunk it into smaller, manageable segments. The `recursive` strategy is used with specified `size`, `overlap`, and `separator` parameters to prepare the text for embedding and storage.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/graph-rag.mdx#_snippet_5

LANGUAGE: TypeScript
CODE:
```
const doc = MDocument.fromText("\n# Riverdale Heights: Community Development Study\n// ... text content ...\n");

const chunks = await doc.chunk({
  strategy: "recursive",
  size: 512,
  overlap: 50,
  separator: "\n",
});
```

----------------------------------------

TITLE: Defining Activity Planning Step (TypeScript)
DESCRIPTION: This Mastra workflow step, `planActivities`, is designed to suggest activities based on the provided weather conditions. It takes the `forecastSchema` as its input, indicating it will process structured weather data to generate activity recommendations.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_19

LANGUAGE: typescript
CODE:
```
const planActivities = createStep({
  id: 'plan-activities',
  description: 'Suggests activities based on weather conditions',
  inputSchema: forecastSchema,
});
```

----------------------------------------

TITLE: Implementing Do-While Loops in Mastra Workflows (TypeScript)
DESCRIPTION: This example shows a `dowhile` loop, which repeatedly executes a step as long as a specified condition remains true. The `inputData` for the loop step initially comes from the preceding step's output, and subsequently from the loop step's own output.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/workflows-vnext/flow-control.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
myWorkflow
  .dowhile(incrementStep, async ({ inputData }) => inputData.value < 10)
  .then(finalStep)
  .commit();
```

----------------------------------------

TITLE: Defining Copywriter Workflow Step in TypeScript
DESCRIPTION: This code defines a workflow step for the copywriter agent, responsible for generating blog post copy based on a provided topic. It includes validation for the input topic and returns the generated text as `copy`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/separate-long-code-block.md#_snippet_2

LANGUAGE: typescript
CODE:
```
const copywriterStep = new Step({
  id: "copywriterStep",
  execute: async ({ context }) => {
    if (!context?.triggerData?.topic) {
      throw new Error("Topic not found in trigger data");
    }
    const result = await copywriterAgent.generate(
      `Create a blog post about ${context.triggerData.topic}`,
    );
    console.log("copywriter result", result.text);
    return {
      copy: result.text,
    };
  },
});
```

----------------------------------------

TITLE: Suspending Workflow with Custom Snapshot Metadata
DESCRIPTION: This snippet demonstrates how to include custom metadata when suspending a workflow using the `suspend` function. The metadata, such as `reason`, `requiredApprovers`, `requestedBy`, `urgency`, and `expires`, is stored with the workflow snapshot and can be retrieved later for conditional resumption or monitoring purposes.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/snapshots.mdx#_snippet_3

LANGUAGE: TypeScript
CODE:
```
await suspend({
  reason: "Waiting for customer approval",
  requiredApprovers: ["manager", "finance"],
  requestedBy: currentUser,
  urgency: "high",
  expires: new Date(Date.now() + 7 * 24 * 60 * 60 * 1000),
});
```

----------------------------------------

TITLE: Initializing Mastra with Upstash Storage (Redis-Compatible)
DESCRIPTION: This snippet illustrates how to configure Mastra to use Upstash (a Redis-compatible store) for workflow storage. It's particularly suited for serverless environments, leveraging environment variables for the Upstash URL and token. This provides a scalable and managed storage solution.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/snapshots.mdx#_snippet_2

LANGUAGE: TypeScript
CODE:
```
import { Mastra } from "@mastra/core/mastra";
import { UpstashStore } from "@mastra/upstash";

const mastra = new Mastra({
  storage: new UpstashStore({
    url: process.env.UPSTASH_URL,
    token: process.env.UPSTASH_TOKEN,
  }),
  workflows: {
    weatherWorkflow,
    travelWorkflow,
  },
});
```

----------------------------------------

TITLE: Defining Support Runtime Context Type in TypeScript
DESCRIPTION: This snippet defines a TypeScript type `SupportRuntimeContext` using Zod for schema validation. It specifies the expected structure of the runtime context, including `user-tier`, `language`, and `user-id`, which are crucial for dynamically adjusting agent behavior.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/dynamic-agents.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { Agent, RuntimeContext } from "@mastra/core";
import { z } from "zod";

type SupportRuntimeContext = {
  "user-tier": "free" | "pro" | "enterprise";
  "language": "en" | "es" | "fr";
  "user-id": string;
};
```

----------------------------------------

TITLE: Initializing MDocument from Various Formats | Mastra | TypeScript
DESCRIPTION: Shows how to create a MDocument object from plain text, HTML, Markdown, and JSON strings using static `from` methods. This is the first step before processing documents.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/chunking-and-embedding.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
const docFromText = MDocument.fromText("Your plain text content...");
const docFromHTML = MDocument.fromHTML("<html>Your HTML content...</html>");
const docFromMarkdown = MDocument.fromMarkdown("# Your Markdown content...");
const docFromJSON = MDocument.fromJSON(`{ "key": "value" }`);
```

----------------------------------------

TITLE: Processing Audio for Transcription with Mastra Agent in TypeScript
DESCRIPTION: This snippet defines an asynchronous POST handler for an API route that processes incoming audio files. It extracts the audio from the request, converts it into a readable stream, and then uses the `noteTakerAgent`'s voice capabilities to transcribe the audio into text, returning the transcription as a JSON response.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/speech-to-text.mdx#_snippet_2

LANGUAGE: TypeScript
CODE:
```
import { mastra } from "@/src/mastra"; // Import the Mastra instance
import { Readable } from "node:stream";

export async function POST(req: Request) {
  // Get the audio file from the request
  const formData = await req.formData();
  const audioFile = formData.get("audio") as File;
  const arrayBuffer = await audioFile.arrayBuffer();
  const buffer = Buffer.from(arrayBuffer);
  const readable = Readable.from(buffer);

  // Get the note taker agent from the Mastra instance
  const noteTakerAgent = mastra.getAgent("noteTakerAgent");

  // Transcribe the audio file
  const text = await noteTakerAgent.voice?.listen(readable);

  return new Response(JSON.stringify({ text }), {
    headers: { "Content-Type": "application/json" },
  });
}
```

----------------------------------------

TITLE: Defining Activity Planning Agent Logic (TypeScript)
DESCRIPTION: This snippet defines the output schema and execution logic for an agent that plans activities based on weather forecast data. It takes forecast data as input, constructs a prompt, streams a response from an AI agent, and aggregates the streamed text into an 'activities' output.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_20

LANGUAGE: TypeScript
CODE:
```
outputSchema: z.object({
    activities: z.string(),
  }),
  execute: async ({ inputData }) => {
    const forecast = inputData;

    if (!forecast) {
      throw new Error('Forecast data not found');
    }

    const prompt = `Based on the following weather forecast for ${forecast.location}, suggest appropriate activities:
      ${JSON.stringify(forecast, null, 2)}
      `;

    const response = await agent.stream([
      {
        role: 'user',
        content: prompt,
      },
    ]);

    let activitiesText = '';

    for await (const chunk of response.textStream) {
      process.stdout.write(chunk);
      activitiesText += chunk;
    }

    return {
      activities: activitiesText,
    };
  },
```

----------------------------------------

TITLE: Defining Workflow Steps - vNext vs. Original Mastra API (TypeScript)
DESCRIPTION: Illustrates step definition, highlighting vNext's use of `createStep` with explicit `inputSchema` and `outputSchema` for type safety and clear data contracts, contrasting with the original API's simpler `new Step`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_30

LANGUAGE: typescript
CODE:
```
// vNext
const myStep = createStep({
  id: 'my-step',
  inputSchema: z.object({
    /* ... */
  }),
  outputSchema: z.object({
    /* ... */
  }),
  execute: async ({ inputData }) => {
    // Logic here
    return { result: 'success' };
  },
});
```

LANGUAGE: typescript
CODE:
```
// Original Mastra API
const myStep = new Step({
  id: 'my-step',
  execute: async ({ context }) => {
    // Logic with different access pattern
    return { result: 'success' };
  },
});
```

----------------------------------------

TITLE: Using Workflow Initial Inputs in Later Steps with Mastra (TypeScript)
DESCRIPTION: This snippet illustrates how to pass the initial input of a workflow to a later step alongside the output of a preceding step. The .map() method is used to explicitly route both the processed value from step1 and the original workflow input to step2, demonstrating how to maintain context throughout a multi-step workflow. The example includes workflow definition, step creation, and execution.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/input-data-mapping.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
import { Mastra } from "@mastra/core";
import { createWorkflow, createStep } from "@mastra/core/workflows";
import { z } from "zod";


const step1 = createStep({
  id: "step1",
  inputSchema: z.object({
    inputValue: z.string(),
  }),
  outputSchema: z.object({
    outputValue: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    mastra.getLogger()?.debug(`Step 1 received: ${inputData.inputValue}`);
    return { outputValue: `Processed: ${inputData.inputValue}` };
  },
});

const step2 = createStep({
  id: "step2",
  inputSchema: z.object({
    outputValue: z.string(),
    initialValue: z.string(),
  }),
  outputSchema: z.object({
    result: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    mastra.getLogger()?.debug(`Step 2 received: ${inputData.outputValue} and original: ${inputData.initialValue}`);
    return { result: `Combined: ${inputData.outputValue} (original: ${inputData.initialValue})` };
  },
});

const myWorkflow = createWorkflow({
  id: "my-workflow",
  inputSchema: z.object({
    inputValue: z.string(),
  }),
  outputSchema: z.object({
    result: z.string(),
  }),
  steps: [step1, step2],
})

myWorkflow
  .then(step1)
  .map({
  outputValue: {
      step: step1,
      path: "outputValue",
  },
  initialValue: {
      initData: myWorkflow,
      path: "inputValue",
  },
  })
  .then(step2)
  .commit();

// Create Mastra instance with all workflows
const mastra = new Mastra({
  workflows: {
    myWorkflow,
  }
});

const run = mastra.getWorkflow("myWorkflow").createRun();
const res = await run.start({
  inputData: { inputValue: "Original input" }
});
if (res.status === "success") {
  console.log("Result:", res.result);
}
```

----------------------------------------

TITLE: Configuring Agent with Tools and maxSteps for Multi-step Operations
DESCRIPTION: This snippet demonstrates how to define a custom tool (`calculate`) within a Mastra agent and configure the `maxSteps` parameter. `maxSteps` controls the maximum number of sequential LLM calls an agent can make, which is crucial for managing multi-step tool usage and preventing infinite loops.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_10

LANGUAGE: ts
CODE:
```
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";
import * as mathjs from "mathjs";
import { z } from "zod";

export const myAgent = new Agent({
  name: "My Agent",
  instructions: "You are a helpful assistant that can solve math problems.",
  model: openai("gpt-4o-mini"),
  tools: {
    calculate: {
      description: "Calculator for mathematical expressions",
      schema: z.object({ expression: z.string() }),
      execute: async ({ expression }) => mathjs.evaluate(expression),
    },
  },
});

const response = await myAgent.generate(
  [
    {
      role: "user",
      content:
        "If a taxi driver earns $9461 per hour and works 12 hours a day, how much does they earn in one day?",
    },
  ],
  {
    maxSteps: 5, // Allow up to 5 tool usage steps
  },
);
```

----------------------------------------

TITLE: Basic Usage of mastra init Command | Mastra CLI | Bash
DESCRIPTION: This snippet illustrates the fundamental syntax for invoking the `mastra init` command. It indicates that the command accepts various options to tailor the project initialization, such as specifying directories, components, or LLM providers.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/cli/init.mdx#_snippet_0

LANGUAGE: bash
CODE:
```
mastra init [options]
```

----------------------------------------

TITLE: Defining LLM Judge Role Prompt (TypeScript)
DESCRIPTION: Defines the constant `GLUTEN_INSTRUCTIONS` which serves as the system prompt or role-setting instruction for the LLM acting as the gluten-checking judge.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/custom-eval.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
export const GLUTEN_INSTRUCTIONS = `You are a Master Chef that identifies if recipes contain gluten.`;
```

----------------------------------------

TITLE: Fetching Weather Data with Mastra Core and Open-Meteo API (TypeScript)
DESCRIPTION: This `createStep` defines the `fetchWeather` operation, responsible for retrieving current weather conditions and forecast data for a given city. It uses the Open-Meteo API for geocoding and weather information, validating inputs with Zod and returning a structured forecast object. The step handles errors for missing input data or unfound locations.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/parallel-steps.mdx#_snippet_3

LANGUAGE: TypeScript
CODE:
```
import { z } from 'zod'
import { createStep, createWorkflow } from '@mastra/core/workflows'

const forecastSchema = z.object({
  date: z.string(),
  maxTemp: z.number(),
  minTemp: z.number(),
  precipitationChance: z.number(),
  condition: z.string(),
  location: z.string(),
});

// Step to fetch weather data for a given city
// Makes API calls to get current weather conditions and forecast
const fetchWeather = createStep({
  id: "fetch-weather",
  description: "Fetches weather forecast for a given city",
  inputSchema: z.object({
    city: z.string(),
  }),
  outputSchema: forecastSchema,
  execute: async ({ inputData }) => {
    if (!inputData) {
      throw new Error("Trigger data not found");
    }
 
    const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(inputData.city)}&count=1`
    const geocodingResponse = await fetch(geocodingUrl)
    const geocodingData = (await geocodingResponse.json()) as {
      results: { latitude: number; longitude: number; name: string }[]
    }

    if (!geocodingData.results?.[0]) {
      throw new Error(`Location '${inputData.city}' not found`);
    }
 
    const { latitude, longitude, name } = geocodingData.results[0]
 
    const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=precipitation,weathercode&timezone=auto,&hourly=precipitation_probability,temperature_2m`
    const response = await fetch(weatherUrl)
    const data = (await response.json()) as {
      current: {
        time: string;
        precipitation: number;
        weathercode: number;
      };
      hourly: {
        precipitation_probability: number[]
        temperature_2m: number[]
      }
    }

    const forecast = {
      date: new Date().toISOString(),
      maxTemp: Math.max(...data.hourly.temperature_2m),
      minTemp: Math.min(...data.hourly.temperature_2m),
      condition: getWeatherCondition(data.current.weathercode),
      location: name,
      precipitationChance: data.hourly.precipitation_probability.reduce(
        (acc, curr) => Math.max(acc, curr),
        0,
      ),
    }
 
    return forecast

  },
});
```

----------------------------------------

TITLE: Initializing Memory with Working Memory Enabled (TypeScript)
DESCRIPTION: This snippet demonstrates how to initialize a `Memory` instance with working memory enabled. It configures the memory system to store data using `LibSQLStore` for persistence, specifying a local database file. This setup allows the agent to retain conversational details across interactions.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/streaming-working-memory.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { Memory } from "@mastra/memory";

const memory = new Memory({
  options: {
    workingMemory: {
      enabled: true,
    },
  },
  storage: new LibSQLStore({
    url: "file:../mastra.db",
  }),
});
```

----------------------------------------

TITLE: Planning Activities Based on Weather Forecast (TypeScript)
DESCRIPTION: This step leverages a 'planningAgent' to generate activity recommendations based on a provided weather forecast. It takes the `forecastSchema` as input, constructs a detailed prompt for the agent, and streams the agent's response to suggest activities. The output is a string containing the recommended activities.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/conditional-branching.mdx#_snippet_4

LANGUAGE: TypeScript
CODE:
```
const planActivities = createStep({
  id: "plan-activities",
  description: "Suggests activities based on weather conditions",
  inputSchema: forecastSchema,
  outputSchema: z.object({
    activities: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    const forecast = inputData

    if (!forecast) {
      throw new Error("Forecast data not found");
    }

    const prompt = `Based on the following weather forecast for ${forecast.location}, suggest appropriate activities:
      ${JSON.stringify(forecast, null, 2)}
      `;

    const agent = mastra?.getAgent("planningAgent");
    if (!agent) {
      throw new Error("Planning agent not found");
    }

    const response = await agent.stream([
      {
        role: "user",
        content: prompt,
      },
    ]);

    let activitiesText = "";

    for await (const chunk of response.textStream) {
      process.stdout.write(chunk);
      activitiesText += chunk;
    }

    return {
      activities: activitiesText,
    };
  }
})
```

----------------------------------------

TITLE: Composing and Committing an Inngest Workflow (TypeScript)
DESCRIPTION: Composes the `incrementStep` into a complete workflow named 'increment-workflow' using `createWorkflow`. This workflow accepts an initial number, processes it through the increment step, and then commits itself to be registered as an invokable function on the Inngest server, making it ready for execution.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/inngest-workflow.mdx#_snippet_3

LANGUAGE: ts
CODE:
```
// workflow that is registered as a function on inngest server
const workflow = createWorkflow({
  id: 'increment-workflow',
  inputSchema: z.object({
    value: z.number(),
  }),
  outputSchema: z.object({
    value: z.number(),
  }),
}).then(incrementStep)

workflow.commit()

export { workflow as incrementWorkflow }
```

----------------------------------------

TITLE: Handling Working Memory Updates with maskStreamTags in TypeScript
DESCRIPTION: This example demonstrates how to interact with the todoAgent and process its streamed responses. It uses maskStreamTags to hide internal <working_memory> updates from the user, providing a cleaner output while the agent automatically manages its state.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/memory/streaming-working-memory-advanced.mdx#_snippet_3

LANGUAGE: typescript
CODE:
```
import { randomUUID } from "crypto";
import { maskStreamTags } from "@mastra/core/utils";

// Start a conversation
const threadId = randomUUID();
const resourceId = "SOME_USER_ID";

// Add a new todo item
const response = await todoAgent.stream(
  "Add a task: Build a new feature for our app. It should take about 2 hours and needs to be done by next Friday.",
  {
    threadId,
    resourceId,
  },
);

// Process the stream, hiding working memory updates
for await (const chunk of maskStreamTags(
  response.textStream,
  "working_memory",
)) {
  process.stdout.write(chunk);
}
```

----------------------------------------

TITLE: Starting Workflow Run Asynchronously (TypeScript)
DESCRIPTION: This snippet demonstrates how to start a new workflow run asynchronously. It first creates a unique run instance and then initiates the workflow with specified `inputData`, awaiting the full run results upon completion.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/workflows.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
const run = workflow.createRun();

const result = await workflow.startAsync({
  runId: run.runId,
  inputData: {
    param1: "value1",
    param2: "value2",
  },
});
```

----------------------------------------

TITLE: Creating a Chained Weather Activity Workflow
DESCRIPTION: This snippet defines 'weatherWorkflow' using 'createWorkflow', chaining 'fetchWeather' and 'planActivities' steps. It specifies input (city) and output (activities) schemas, ensuring data flow and validation. The workflow is then committed, making it ready for execution within the Mastra system.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/agentic-workflows.mdx#_snippet_5

LANGUAGE: TypeScript
CODE:
```
const weatherWorkflow = createWorkflow({
  id: 'weather-workflow',
  inputSchema: z.object({
    city: z.string().describe('The city to get the weather for'),
  }),
  outputSchema: z.object({
    activities: z.string(),
  }),
})
  .then(fetchWeather)
  .then(planActivities);

weatherWorkflow.commit();
```

----------------------------------------

TITLE: Configuring Memory Storage and Vector DB with LibSQL (TypeScript)
DESCRIPTION: This example illustrates how to explicitly configure the storage and vector database used by Mastra Memory. It shows using `LibSQLStore` and `LibSQLVector` with a local file path.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/memory/semantic-recall.mdx#_snippet_2

LANGUAGE: ts
CODE:
```
import { Memory } from "@mastra/memory";
import { Agent } from "@mastra/core/agent";
import { LibSQLStore, LibSQLVector } from "@mastra/libsql";

const agent = new Agent({
  memory: new Memory({
    // this is the default storage db if omitted
    storage: new LibSQLStore({
      url: "file:./local.db",
    }),
    // this is the default vector db if omitted
    vector: new LibSQLVector({
      connectionUrl: "file:./local.db",
    }),
  }),
});
```

----------------------------------------

TITLE: Creating and Registering a Basic Mastra Workflow in TypeScript
DESCRIPTION: This snippet demonstrates how to define a new workflow using `createWorkflow`, specifying its ID, input/output schemas with Zod, and declaring its constituent steps. It also shows how to register this workflow with a Mastra instance and create a run instance for execution.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#_snippet_2

LANGUAGE: typescript
CODE:
```
// Create a workflow with defined steps and execution flow
const myWorkflow = createWorkflow({
  id: "my-workflow",
  // Define the expected input structure (should match the first step's inputSchema)
  inputSchema: z.object({
    startValue: z.string(),
  }),
  // Define the expected output structure (should match the last step's outputSchema)
  outputSchema: z.object({
    result: z.string(),
  }),
  steps: [step1, step2, step3], // Declare steps used in this workflow
})
  .then(step1)
  .then(step2)
  .then(step3)
  .commit();

// Register workflow with Mastra instance
const mastra = new Mastra({
  workflows: {
    myWorkflow,
  },
});

// Create a run instance of the workflow
const run = mastra.getWorkflow("myWorkflow").createRun();
```

----------------------------------------

TITLE: Embed Text with Cohere using Mastra and AI SDK (TSX)
DESCRIPTION: This snippet shows how to generate embeddings for text chunks using the Cohere embedding model via the AI SDK within a Mastra RAG workflow. It imports necessary modules, creates a document from text, chunks the document, and then calls `embedMany` to get the embeddings.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/embedding/embed-text-with-cohere.mdx#_snippet_0

LANGUAGE: tsx
CODE:
```
import { cohere } from "@ai-sdk/cohere";
import { MDocument } from "@mastra/rag";
import { embedMany } from "ai";

const doc = MDocument.fromText("Your text content...");

const chunks = await doc.chunk();

const { embeddings } = await embedMany({
  model: cohere.embedding("embed-english-v3.0"),
  values: chunks.map((chunk) => chunk.text),
});
```

----------------------------------------

TITLE: Importing Core Dependencies for Mastra RAG System
DESCRIPTION: This code imports all necessary modules and components for building the RAG system. It includes `@ai-sdk/openai` for OpenAI integration, `@mastra/core` for the main Mastra framework, `@mastra/pg` for PostgreSQL vector store, and `@mastra/rag` for RAG-specific utilities like `createVectorQueryTool` and `MDocument`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-rag.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { Mastra } from "@mastra/core";
import { Agent } from "@mastra/core/agent";
import { PgVector } from "@mastra/pg";
import { createVectorQueryTool, MDocument } from "@mastra/rag";
import { embedMany } from "ai";
```

----------------------------------------

TITLE: Handling Workflow Run Results and Type Safety - TypeScript
DESCRIPTION: This example illustrates how to start a workflow run and handle its various outcomes: success, failure, or suspension. It highlights the type safety provided by declaring steps in the workflow definition, allowing direct and fully typed access to individual step outputs from the `result.steps` object.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_3

LANGUAGE: typescript
CODE:
```
// With steps declared in workflow options
const workflow = createWorkflow({
  id: 'my-workflow',
  inputSchema: z.object({}),
  outputSchema: z.object({}),
  steps: [step1, step2], // TypeScript knows these steps exist
});

const result = await workflow.createRun().start({ inputData: {} });
if (result.status === 'success') {
  console.log(result.result); // only exists if status is success
} else if (result.status === 'failed') {
  console.error(result.error); // only exists if status is failed, this is an instance of Error
  throw result.error;
} else if (result.status === 'suspended') {
  console.log(result.suspended); // only exists if status is suspended
}

// TypeScript knows these properties exist and their types
console.log(result.steps.step1.output); // Fully typed
console.log(result.steps.step2.output); // Fully typed
```

----------------------------------------

TITLE: Measuring Low Content Similarity - Mastra Evals - TypeScript
DESCRIPTION: Illustrates measuring similarity between two texts that are largely unrelated. It defines `text3` and `reference3`, logs them, calls `metric.measure(reference, text)`, and logs the score and info, demonstrating a significantly lower score indicating low similarity.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/content-similarity.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
const text3 = "The cat sleeps on the windowsill.";
const reference3 = "The quick brown fox jumps over the lazy dog.";

console.log("Example 3 - Low Similarity:");
console.log("Text:", text3);
console.log("Reference:", reference3);

const result3 = await metric.measure(reference3, text3);
console.log("Metric Result:", {
  score: result3.score,
  info: {
    similarity: result3.info.similarity,
  },
});
// Example Output:
// Metric Result: {
//   score: 0.25806451612903225,
//   info: { similarity: 0.25806451612903225 }
// }
```

----------------------------------------

TITLE: Processing and Chunking Text Documents for RAG
DESCRIPTION: This snippet illustrates how to load a text document using `MDocument.fromText` and then chunk it into smaller, manageable pieces. It applies a "recursive" chunking strategy with specified size, overlap, and separator to optimize the document for retrieval-augmented generation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cot-workflow-rag.mdx#_snippet_12

LANGUAGE: typescript
CODE:
```
const doc = MDocument.fromText(
  `The Impact of Climate Change on Global Agriculture...`,
);

const chunks = await doc.chunk({
  strategy: "recursive",
  size: 512,
  overlap: 50,
  separator: "\n",
});
```

----------------------------------------

TITLE: Querying Similar Vectors from Vectorize Index in TypeScript
DESCRIPTION: This example shows how to perform a similarity search against an index using the `query` method. It requires an `indexName` and a `queryVector`, allowing specification of `topK` results, `filter` conditions for metadata, and whether to `includeVector` in the returned results.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/vectorize/README.md#_snippet_4

LANGUAGE: typescript
CODE:
```
const results = await vectorStore.query({
  indexName: 'my-index',
  queryVector: [0.1, 0.2, ...],
  topK: 10,
  filter: { text: { $eq: 'doc1' } },
  includeVector: false
});
```

----------------------------------------

TITLE: Creating a Graph RAG Tool Instance (TypeScript)
DESCRIPTION: This snippet demonstrates how to initialize the `createGraphRAGTool()` function. It shows the necessary imports from `@ai-sdk/openai` and `@mastra/rag`, and configures the tool with a specific vector store (`pinecone`), index (`docs`), an embedding model (`text-embedding-3-small`), and detailed `graphOptions` for controlling the graph-based retrieval process.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/graph-rag-tool.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { createGraphRAGTool } from "@mastra/rag";

const graphTool = createGraphRAGTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
  graphOptions: {
    dimension: 1536,
    threshold: 0.7,
    randomWalkSteps: 100,
    restartProb: 0.15
  }
});
```

----------------------------------------

TITLE: Generating Speech with Deepgram Voice (TypeScript)
DESCRIPTION: This snippet illustrates integrating Deepgram Voice with a Mastra AI Agent. It sets up an agent, generates a text response, converts the text to an audio stream using Deepgram's text-to-speech, and plays the resulting audio.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/docs/voice/overview.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';
import { DeepgramVoice } from "@mastra/voice-deepgram";
import { playAudio } from "@mastra/node-audio";

const voiceAgent = new Agent({
name: "Voice Agent",
instructions: "You are a voice assistant that can help users with their tasks.",
model: openai("gpt-4o"),
voice: new DeepgramVoice()
});

const { text } = await voiceAgent.generate('What color is the sky?');

// Convert text to speech to an Audio Stream
const audioStream = await voiceAgent.voice.speak(text, {
speaker: "aura-english-us" // Optional: specify a speaker
});

playAudio(audioStream);
```

----------------------------------------

TITLE: Installing @mastra/voice-openai with npm
DESCRIPTION: This command installs the `@mastra/voice-openai` package using npm, making it available for use in your project. It is the first step to integrate OpenAI voice capabilities.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/openai/README.md#_snippet_0

LANGUAGE: bash
CODE:
```
npm install @mastra/voice-openai
```

----------------------------------------

TITLE: Registering Mastra Agents and Workflows (TypeScript)
DESCRIPTION: This code initializes the Mastra core instance, registering the `activityPlanningWorkflow` and the `planningAgent` and `synthesizeAgent`. This registration is crucial for making these components accessible and executable within the Mastra ecosystem, enabling the workflow to utilize the defined agents.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/parallel-steps.mdx#_snippet_9

LANGUAGE: TypeScript
CODE:
```
import { Mastra } from '@mastra/core/mastra'
import { createLogger } from '@mastra/core/logger'
import { activityPlanningWorkflow } from './workflows/parallel-workflow'
import { planningAgent } from './agents/planning-agent'
import { synthesizeAgent } from './agents/synthesize-agent'

// Initialize Mastra with required agents and workflows
// This setup enables agent access within the workflow steps
const mastra = new Mastra({
  workflows: {
    activityPlanningWorkflow,
  },
  agents: {
    planningAgent,
    synthesizeAgent,
  },
  logger: createLogger({
    name: "Mastra",
    level: "info",
  }),
})
 
export { mastra }
```

----------------------------------------

TITLE: Generating Structured Output with Tool Calls using experimental_output
DESCRIPTION: This example shows how to use the `experimental_output` property instead of `output` when an agent needs to return structured data while also potentially making tool calls. This property enables both functionalities simultaneously, providing strong typing and validation for the structured data.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/overview.mdx#_snippet_9

LANGUAGE: typescript
CODE:
```
const schema = z.object({
  summary: z.string(),
  keywords: z.array(z.string()),
});

const response = await myAgent.generate(
  [
    {
      role: "user",
      content:
        "Please analyze this repository and provide a summary and keywords...",
    },
  ],
  {
    // Use experimental_output to enable both structured output and tool calls
    experimental_output: schema,
  },
);

console.log("Structured Output:", response.object);
```

----------------------------------------

TITLE: Defining an Activity Planning Agent with Mastra and OpenAI
DESCRIPTION: This TypeScript snippet defines `planningAgent` using `@mastra/core/agent` and `@ai-sdk/openai`. The agent is configured with a `gpt-4o` model and detailed instructions to act as a weather-based activity planning expert, providing structured recommendations based on weather conditions. It requires the `@ai-sdk/openai` and `@mastra/core` packages.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows_vNext/calling-agent.mdx#_snippet_1

LANGUAGE: ts
CODE:
```
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";

const llm = openai("gpt-4o");

// Create a new agent for activity planning
const planningAgent = new Agent({
  name: "planningAgent",
  model: llm,
  instructions: `\n        You are a local activities and travel expert who excels at weather-based planning. Analyze the weather data and provide practical activity recommendations.\n\n        📅 [Day, Month Date, Year]\n        ═══════════════════════════\n\n        🌡️ WEATHER SUMMARY\n        • Conditions: [brief description]\n        • Temperature: [X°C/Y°F to A°C/B°F]\n        • Precipitation: [X% chance]\n\n        🌅 MORNING ACTIVITIES\n        Outdoor:\n        • [Activity Name] - [Brief description including specific location/route]\n          Best timing: [specific time range]\n          Note: [relevant weather consideration]\n\n        🌞 AFTERNOON ACTIVITIES\n        Outdoor:\n        • [Activity Name] - [Brief description including specific location/route]\n          Best timing: [specific time range]\n          Note: [relevant weather consideration]\n\n        🏠 INDOOR ALTERNATIVES\n        • [Activity Name] - [Brief description including specific venue]\n          Ideal for: [weather condition that would trigger this alternative]\n\n        ⚠️ SPECIAL CONSIDERATIONS\n        • [Any relevant weather warnings, UV index, wind conditions, etc.]\n\n        Guidelines:\n        - Suggest 2-3 time-specific outdoor activities per day\n        - Include 1-2 indoor backup options\n        - For precipitation >50%, lead with indoor activities\n        - All activities must be specific to the location\n        - Include specific venues, trails, or locations\n        - Consider activity intensity based on temperature\n        - Keep descriptions concise but informative\n\n        Maintain this exact formatting for consistency, using the emoji and section headers as shown.\n      `,
});

export { planningAgent };
```

----------------------------------------

TITLE: Chunking with Metadata Extraction (TypeScript)
DESCRIPTION: Illustrates how to combine document chunking with metadata extraction. It configures recursive chunking with a specified size and enables keyword and summary extraction for each generated chunk, then retrieves and logs the metadata associated with the chunks.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/embedding/metadata-extraction.mdx#_snippet_3

LANGUAGE: typescript
CODE:
```
// Configure chunking with metadata extraction
await doc.chunk({
  strategy: "recursive", // Use recursive chunking strategy
  size: 200, // Maximum chunk size
  extract: {
    keywords: true, // Extract keywords per chunk
    summary: true // Generate summary per chunk
  }
});

// Get metadata from chunks
const metaTwo = doc.getMetadata();
console.log("Chunk Metadata:", metaTwo);

// Example Output:
// Chunk Metadata: {
//   keywords: [
//     'exercise',
//     'health benefits',
//     'cardiovascular health',
//     'mental wellbeing',
//     'stress reduction',
//     'sleep quality'
//   ],
//   summary: 'Regular exercise provides multiple health benefits including improved cardiovascular health, muscle strength, and mental wellbeing. Key benefits include stress reduction, better sleep, weight management, and increased energy. Recommended exercise duration is 150 minutes per week.'
// }
```

----------------------------------------

TITLE: Cloning Mastra Repository and Navigating Directory (Bash)
DESCRIPTION: This command sequence clones the Mastra AI repository from GitHub and then changes the current directory to the specific example for contextual recall, preparing the environment for further setup.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/contextual-recall/README.md#_snippet_0

LANGUAGE: bash
CODE:
```
git clone https://github.com/mastra-ai/mastra
cd examples/basics/evals/contextual-recall
```

----------------------------------------

TITLE: Importing Workflow and Step Functions in TypeScript
DESCRIPTION: This snippet demonstrates how to import the `createWorkflow` and `createStep` functions from `@mastra/core/workflows` for building Mastra workflows, along with `z` from `zod` for schema validation. These are essential prerequisites for defining workflow structures and individual steps.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/overview.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { createWorkflow, createStep } from "@mastra/core/workflows";
import { z } from "zod"; // For schema validation
```

----------------------------------------

TITLE: Initializing Mastra Project with Bun - Bash
DESCRIPTION: This command sequence initializes a new Node.js project using Bun, installs essential development dependencies like TypeScript and tsx, and then adds core Mastra packages along with zod and @ai-sdk/openai for AI functionalities. This provides a fast setup for the project.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_7

LANGUAGE: bash
CODE:
```
bun init -y

bun add typescript tsx @types/node mastra@latest --dev

bun add @mastra/core@latest zod @ai-sdk/openai
```

----------------------------------------

TITLE: Basic Usage of PostgresStore | TypeScript
DESCRIPTION: Demonstrates importing and instantiating the PostgresStore class using a connection string from an environment variable. This is the standard way to initialize the storage.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/storage/postgresql.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { PostgresStore } from "@mastra/pg";

const storage = new PostgresStore({
  connectionString: process.env.DATABASE_URL,
});
```

----------------------------------------

TITLE: Initializing Mastra Client and Interacting with Agent - TypeScript
DESCRIPTION: This snippet demonstrates how to initialize the MastraClient with a specified base URL and then interact with an AI agent. It shows the process of retrieving an agent instance by its ID and generating a response by sending a list of messages, with the output logged to the console. The `baseUrl` parameter is crucial for connecting to the correct Mastra API endpoint.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/client-sdks/client-js/README.md#_snippet_1

LANGUAGE: typescript
CODE:
```
import { MastraClient } from '@mastra/client';

// Initialize the client
const client = new MastraClient({
  baseUrl: 'http://localhost:4111', // Your Mastra API endpoint
});

// Example: Working with an Agent
async function main() {
  // Get an agent instance
  const agent = client.getAgent('your-agent-id');

  // Generate a response
  const response = await agent.generate({
    messages: [{ role: 'user', content: "What's the weather like today?" }],
  });

  console.log(response);
}
```

----------------------------------------

TITLE: Implementing OpenAI Realtime Speech-to-Speech with Mastra AI in TypeScript
DESCRIPTION: This snippet sets up a real-time conversational AI agent using OpenAI's voice capabilities. It demonstrates listening for agent audio responses via `voiceAgent.voice.on('speaker')`, initiating a conversation with `voiceAgent.voice.speak()`, and continuously sending microphone input using `voiceAgent.voice.send()`. Dependencies include `@mastra/core/agent`, `@ai-sdk/openai`, `@mastra/node-audio`, and `@mastra/voice-openai-realtime`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#_snippet_19

LANGUAGE: typescript
CODE:
```
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';
import { playAudio, getMicrophoneStream } from '@mastra/node-audio';
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";

const voiceAgent = new Agent({
  name: "Voice Agent",
  instructions: "You are a voice assistant that can help users with their tasks.",
  model: openai("gpt-4o"),
  voice: new OpenAIRealtimeVoice(),
});

// Listen for agent audio responses
voiceAgent.voice.on('speaker', ({ audio }) => {
  playAudio(audio);
});

// Initiate the conversation
await voiceAgent.voice.speak('How can I help you today?');

// Send continuous audio from the microphone
const micStream = getMicrophoneStream();
await voiceAgent.voice.send(micStream);
```

----------------------------------------

TITLE: Initializing Cloudflare Vectorize Store in TypeScript
DESCRIPTION: This snippet shows how to initialize the Cloudflare Vectorize store using `@mastra/vectorize`. It configures the store with an account ID and API token, then creates an index named 'myCollection' with a specified dimension, and upserts vector embeddings with metadata. It depends on `process.env.CF_ACCOUNT_ID` and `process.env.CF_API_TOKEN`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#_snippet_7

LANGUAGE: TypeScript
CODE:
```
import { CloudflareVector } from '@mastra/vectorize'

const store = new CloudflareVector({
  accountId: process.env.CF_ACCOUNT_ID,
  apiToken: process.env.CF_API_TOKEN
})
await store.createIndex({
  indexName: "myCollection",
  dimension: 1536,
});
await store.upsert({
  indexName: "myCollection",
  vectors: embeddings,
  metadata: chunks.map(chunk => ({ text: chunk.text })),
});
```

----------------------------------------

TITLE: Main Application Logic for Speech-to-Speech Call Analysis (TypeScript)
DESCRIPTION: This TypeScript code sets up the main application logic for a speech-to-speech conversation. It initializes the Roark Analytics client, creates a conversation session with Mastra AI, handles recording the conversation, uploads the recording to Cloudinary upon completion, and sends the call details and recording URL to Roark for analysis. It also includes event handlers for conversation end and real-time writing.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/voice/speech-to-speech.mdx#_snippet_5

LANGUAGE: ts
CODE:
```
import { Roark } from "@roarkanalytics/sdk";
import chalk from "chalk";

import { mastra } from "./mastra";
import { createConversation, formatToolInvocations } from "./utils";
import { uploadToCloudinary } from "./upload";
import fs from "fs";

const client = new Roark({
  bearerToken: process.env.ROARK_API_KEY,
});

async function speechToSpeechServerExample() {
  const { start, stop } = createConversation({
    mastra,
    recordingPath: "./speech-to-speech-server.mp3",
    providerOptions: {},
    initialMessage: "Howdy partner",
    onConversationEnd: async (props) => {
      // File upload
      fs.writeFileSync(props.recordingPath, props.audioBuffer);
      const url = await uploadToCloudinary(props.recordingPath);

      // Send to Roark
      console.log("Send to Roark", url);
      const response = await client.callAnalysis.create({
        recordingUrl: url,
        startedAt: props.startedAt,
        callDirection: "INBOUND",
        interfaceType: "PHONE",
        participants: [
          {
            role: "AGENT",
            spokeFirst: props.agent.spokeFirst,
            name: props.agent.name,
            phoneNumber: props.agent.phoneNumber,
          },
          {
            role: "CUSTOMER",
            name: "Yujohn Nattrass",
            phoneNumber: "987654321",
          },
        ],
        properties: props.metadata,
        toolInvocations: formatToolInvocations(props.toolInvocations),
      });

      console.log("Call Recording Posted:", response.data);
    },
    onWriting: (ev) => {
      if (ev.role === "assistant") {
        process.stdout.write(chalk.blue(ev.text));
      }
    },
  });

  await start();

  process.on("SIGINT", async (e) => {
    await stop();
  });
}

speechToSpeechServerExample().catch(console.error);
```

----------------------------------------

TITLE: Accessing Runtime Context in Mastra Tools (TypeScript)
DESCRIPTION: This snippet illustrates how a Mastra tool can access and utilize variables from the `runtimeContext`. The `getWeather` tool retrieves the `temperature-scale` from the context, ensuring type-safe access, and then uses it when calling an external weather API. This allows tools to adapt their behavior based on the agent's runtime configuration. It depends on `@mastra/core/tools` and `zod`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/agents/runtime-variables.mdx#_snippet_2

LANGUAGE: TypeScript
CODE:
```
import { createTool } from "@mastra/core/tools";
import { z } from "zod";

export const weatherTool = createTool({
  id: "getWeather",
  description: "Get the current weather for a location",
  inputSchema: z.object({
    location: z.string().describe("The location to get weather for"),
  }),
  execute: async ({ context, runtimeContext }) => {
    // Type-safe access to runtimeContext variables
    const temperatureUnit = runtimeContext.get("temperature-scale");

    const weather = await fetchWeather(context.location, {
      temperatureUnit,
    });

    return { result: weather };
  },
});

async function fetchWeather(
  location: string,
  { temperatureUnit }: { temperatureUnit: "celsius" | "fahrenheit" },
): Promise<WeatherResponse> {
  // Implementation of weather API call
  const response = await weatherApi.fetch(location, temperatureUnit);

  return {
    location,
    temperature: "72°F",
    conditions: "Sunny",
    unit: temperatureUnit,
  };
}
```

----------------------------------------

TITLE: Configuring Next.js for Mastra AI
DESCRIPTION: This snippet configures the Next.js application to allow `@mastra/*` packages to be externalized from the server bundle, which is necessary for direct integration of Mastra AI. It ensures that Mastra's server-side components are correctly handled during compilation.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/frameworks/next-js.mdx#_snippet_14

LANGUAGE: JavaScript
CODE:
```
/** @type {import('next').NextConfig} */
const nextConfig = {
  serverExternalPackages: ["@mastra/*"],
  // ... your other Next.js config
};

module.exports = nextConfig;
```

----------------------------------------

TITLE: Initializing Mastra Client with client-js SDK (TypeScript)
DESCRIPTION: This snippet demonstrates how to initialize the Mastra client using the `@mastra/client-js` SDK. It creates a new instance of `MastraClient`, which serves as the entry point for interacting with the Mastra Workflows API.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/workflows.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { MastraClient } from "@mastra/client-js";

const client = new MastraClient();
```

----------------------------------------

TITLE: Serving Mastra Application (Bash)
DESCRIPTION: This bash command starts the Mastra development server, making the configured research assistant available via an API endpoint. This allows external applications or `curl` commands to interact with the agent for generating responses, effectively deploying the RAG system for live use.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/research-assistant.mdx#_snippet_9

LANGUAGE: bash
CODE:
```
mastra dev
```

----------------------------------------

TITLE: Initializing MastraMCPClient (TypeScript)
DESCRIPTION: Creates a new instance of the MastraMCPClient class. This constructor configures the client with a name, version, server definition (which determines the transport type), optional capabilities, and a timeout for tool calls. It requires a server definition of type `MastraMCPServerDefinition`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/tools/client.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
constructor({
    name,
    version = '1.0.0',
    server,
    capabilities = {},
    timeout = 60000,
}: {
    name: string;
    server: MastraMCPServerDefinition;
    capabilities?: ClientCapabilities;
    version?: string;
    timeout?: number;
})
```

----------------------------------------

TITLE: Initializing OpenAIVoice with Configuration (TypeScript)
DESCRIPTION: Demonstrates how to create an instance of `OpenAIVoice`, showing both explicit configuration with `speechModel` and `speaker` options, and a simplified version using default settings. Requires the `@mastra/voice-openai` package.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/text-to-speech.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
const voice = new OpenAIVoice({
  speechModel: {
    name: "tts-1-hd",
    apiKey: process.env.OPENAI_API_KEY,
  },
  speaker: "alloy",
});

// If using default settings the configuration can be simplified to:
const voice = new OpenAIVoice();
```

----------------------------------------

TITLE: Installing Mastra Client Library - Bash
DESCRIPTION: This command installs the Mastra AI client library for JavaScript/TypeScript using npm, making it available for use in your project. It is the first step to integrate the Mastra AI client into a Node.js or browser-based application.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/client-sdks/client-js/README.md#_snippet_0

LANGUAGE: bash
CODE:
```
npm install @mastra/client-js
```

----------------------------------------

TITLE: Initializing Mastra Client (TypeScript)
DESCRIPTION: Initializes a new instance of the MastraClient using the @mastra/client-js SDK. This client is the entry point for interacting with the Mastra API, including memory operations.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/memory.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { MastraClient } from "@mastra/client-js";

const client = new MastraClient();
```

----------------------------------------

TITLE: Initializing AstraVector and Performing Operations - TypeScript
DESCRIPTION: This comprehensive example demonstrates how to initialize the AstraVector client with your Astra DB credentials, create a new vector collection (index), perform batch upsert operations to add vectors with associated metadata, and execute a vector similarity query with optional filtering and vector inclusion settings.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/stores/astra/README.md#_snippet_1

LANGUAGE: typescript
CODE:
```
import { AstraVector } from '@mastra/astra';

const vectorStore = new AstraVector({
  token: 'your-astra-token',
  endpoint: 'your-astra-endpoint',
  keyspace: 'your-keyspace' // optional
});

// Create a new collection
await vectorStore.createIndex({ indexName: 'myCollection', dimension: 1536, metric: 'cosine' });

// Add vectors
const vectors = [[0.1, 0.2, ...], [0.3, 0.4, ...]];
const metadata = [{ text: 'doc1' }, { text: 'doc2' }];
const ids = await vectorStore.upsert({ indexName: 'myCollection', vectors, metadata });

// Query vectors
const results = await vectorStore.query({
  indexName: 'myCollection',
  queryVector: [0.1, 0.2, ...],
  topK: 10, // topK
  filter: { text: { $eq: 'doc1' } }, // optional filter
  includeVector: false // includeVectors
});
```

----------------------------------------

TITLE: Implementing Custom LLM Judge for Gluten Checking (TypeScript)
DESCRIPTION: Defines the `RecipeCompletenessJudge` class, extending `MastraAgentJudge`. It orchestrates the LLM evaluation process using the defined prompts, providing methods to `evaluate` a recipe for gluten content and `getReason` for the verdict.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/custom-eval.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
import { type LanguageModel } from "@mastra/core/llm";
import { MastraAgentJudge } from "@mastra/evals/judge";
import { z } from "zod";
import {
  GLUTEN_INSTRUCTIONS,
  generateGlutenPrompt,
  generateReasonPrompt,
} from "./prompts";

export class RecipeCompletenessJudge extends MastraAgentJudge {
  constructor(model: LanguageModel) {
    super("Gluten Checker", GLUTEN_INSTRUCTIONS, model);
  }

  async evaluate(output: string): Promise<{
    isGlutenFree: boolean;
    glutenSources: string[];
  }> {
    const glutenPrompt = generateGlutenPrompt({ output });
    const result = await this.agent.generate(glutenPrompt, {
      output: z.object({
        isGlutenFree: z.boolean(),
        glutenSources: z.array(z.string()),
      }),
    });

    return result.object;
  }

  async getReason(args: {
    isGlutenFree: boolean;
    glutenSources: string[];
  }): Promise<string> {
    const prompt = generateReasonPrompt(args);
    const result = await this.agent.generate(prompt, {
      output: z.object({
        reason: z.string(),
      }),
    });

    return result.object.reason;
  }
}
```

----------------------------------------

TITLE: Demonstrate Agent Voice Interaction | TypeScript
DESCRIPTION: Shows a basic interaction flow between the initialized agents. Agent 1 speaks a question, saves the audio, Agent 2 listens to the audio file, converts it to text, generates a response, and speaks the response, saving its audio.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/adding-voice-capabilities.mdx#_snippet_1

LANGUAGE: ts
CODE:
```
// Step 1: Agent 1 speaks a question and saves it to a file
const audio1 = await agent1.voice.speak(
  "What is the meaning of life in one sentence?",
);
await saveAudioToFile(audio1, "agent1-question.mp3");

// Step 2: Agent 2 listens to Agent 1's question
const audioFilePath = path.join(process.cwd(), "agent1-question.mp3");
const audioStream = createReadStream(audioFilePath);
const audio2 = await agent2.voice.listen(audioStream);
const text = await convertToText(audio2);

// Step 3: Agent 2 generates and speaks a response
const agent2Response = await agent2.generate(text);
const agent2ResponseAudio = await agent2.voice.speak(agent2Response.text);
await saveAudioToFile(agent2ResponseAudio, "agent2-response.mp3");
```

----------------------------------------

TITLE: Using Chef Agent and GlutenCheckerMetric (TypeScript)
DESCRIPTION: Demonstrates how to retrieve the previously defined `chefAgent` and its attached `glutenChecker` metric. It provides an example workflow: generating a response from the agent based on user input and then using the metric's `measure` method to evaluate the generated response, finally logging the detailed evaluation result.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/custom-eval.mdx#_snippet_7

LANGUAGE: typescript
CODE:
```
import { mastra } from "./mastra";

const chefAgent = mastra.getAgent("chefAgent");
const metric = chefAgent.evals.glutenChecker;

// Example: Evaluate a recipe
const input = "What is a quick way to make rice and beans?";
const response = await chefAgent.generate(input);
const result = await metric.measure(input, response.text);

console.log("Metric Result:", {
  score: result.score,
  glutenSources: result.info.glutenSources,
  reason: result.info.reason,
});

// Example Output:
// Metric Result: { score: 1, glutenSources: [], reason: 'The recipe is gluten-free as it does not contain any gluten-containing ingredients.' }
```

----------------------------------------

TITLE: Implementing Few-Shot Learning in Mastra (TypeScript)
DESCRIPTION: This snippet illustrates how to apply few-shot learning in Mastra by providing `examples` within a prompt definition. This allows the model to learn desired output patterns from a small set of input-output pairs, as demonstrated with a sentiment analysis task, ensuring consistent output format and content.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/explorations/prompt/examples.md#_snippet_1

LANGUAGE: typescript
CODE:
```
type SentimentVars = {
  text: string;
  language: string;
};

const sentimentPrompt = createPrompt<SentimentVars>('Analyze sentiment', {
  persona: 'Language Analyst',
  outputFormat: 'json',
})
  .text('Analyze the sentiment of this {{language}} text:\n\n{{text}}')
  .examples([
    {
      input: {
        text: 'The product exceeded my expectations, highly recommend!',
        language: 'English',
      },
      output: {
        sentiment: 'positive',
        confidence: 0.95,
        aspects: ['product quality', 'recommendation'],
      },
    },
    {
      input: {
        text: 'Service was okay, but the wait time was too long',
        language: 'English',
      },
      output: {
        sentiment: 'mixed',
        confidence: 0.8,
        aspects: ['service quality', 'wait time'],
      },
    },
  ])
  .constraints([
    'Follow the exact output format from examples',
    'Include confidence score',
    'Identify key aspects mentioned',
  ]);

// Usage example
const analysis = sentimentPrompt.toString({
  text: 'Great features but the interface could be more intuitive',
  language: 'English',
});
```

----------------------------------------

TITLE: Executing and Resuming Mastra Workflow (TypeScript)
DESCRIPTION: This comprehensive snippet illustrates the full lifecycle of running a Mastra workflow, including starting a run, checking for suspension at specific steps ('promptAgent', 'improveResponse'), and resuming the workflow with human guidance or improved content. It demonstrates conditional logic for handling multiple resume attempts and updating workflow context.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/ja/examples/workflows/suspend-and-resume.mdx#_snippet_2

LANGUAGE: TypeScript
CODE:
```
async function runWorkflow() {
  const workflow = mastra.getWorkflow("contentWorkflow");
  const { runId, start } = workflow.createRun();

  let finalResult: any;

  // Start the workflow
  const initialResult = await start({
    triggerData: { input: "Create content about sustainable energy" }
  });

  console.log("Initial workflow state:", initialResult.results);

  const promptAgentStepResult = initialResult.activePaths.get("promptAgent");

  // Check if promptAgent step is suspended
  if (promptAgentStepResult?.status === "suspended") {
    console.log("Workflow suspended at promptAgent step");
    console.log("Suspension payload:", promptAgentStepResult?.suspendPayload);

    // Resume with human guidance
    const resumeResult1 = await workflow.resume({
      runId,
      stepId: "promptAgent",
      context: {
        guidance: "Focus more on solar and wind energy technologies"
      }
    });

    console.log("Workflow resumed and continued to next steps");

    let improveResponseResumeAttempts = 0;
    let improveResponseStatus =
      resumeResult1?.activePaths.get("improveResponse")?.status;

    // Check if improveResponse step is suspended
    while (improveResponseStatus === "suspended") {
      console.log("Workflow suspended at improveResponse step");
      console.log(
        "Suspension payload:",
        resumeResult1?.activePaths.get("improveResponse")?.suspendPayload,
      );

      const improvedContent =
        improveResponseResumeAttempts < 3
          ? undefined
          : "Completely revised content about sustainable energy focusing on solar and wind technologies";

      // Resume with human improvements
      finalResult = await workflow.resume({
        runId,
        stepId: "improveResponse",
        context: {
          improvedContent,
          resumeAttempts: improveResponseResumeAttempts
        }
      });

      improveResponseResumeAttempts =
        finalResult?.activePaths.get("improveResponse")?.suspendPayload
          ?.resumeAttempts ?? 0;
      improveResponseStatus =
        finalResult?.activePaths.get("improveResponse")?.status;

      console.log("Improved response result:", finalResult?.results);
    }
  }
  return finalResult;
}

// Run the workflow
const result = await runWorkflow();
console.log("Workflow completed");
console.log("Final workflow result:", result);
```

----------------------------------------

TITLE: Evaluating Inaccurate Summary with Metric (TypeScript)
DESCRIPTION: This snippet defines an original text and an inaccurate summary, then uses the `metric.measure` function to evaluate the summary against the source text. It logs the input, output, and the resulting metric scores (score, reason, alignmentScore, coverageScore) to illustrate how the metric identifies and penalizes factual errors and misrepresentations.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/evals/summarization.mdx#_snippet_5

LANGUAGE: typescript
CODE:
```
const input3 = `The World Wide Web was invented by Tim Berners-Lee in 1989 while working at CERN.
He published the first website in 1991. Berners-Lee made the Web freely available, with no patent
and no royalties due.`;

const output3 = `The Internet was created by Tim Berners-Lee at MIT in the early 1990s, and he went
on to commercialize the technology through patents.`;

console.log("Example 3 - Inaccurate Summary:");
console.log("Input:", input3);
console.log("Output:", output3);

const result3 = await metric.measure(input3, output3);
console.log("Metric Result:", {
  score: result3.score,
  info: {
    reason: result3.info.reason,
    alignmentScore: result3.info.alignmentScore,
    coverageScore: result3.info.coverageScore,
  },
});
// Example Output:
// Metric Result: {
//   score: 0,
//   info: {
//     reason: "The score is 0 because the summary contains multiple factual errors and misrepresentations of key details from the source text, despite covering some of the basic information.",
//     alignmentScore: 0,
//     coverageScore: 0.6
//   }
// }
```

----------------------------------------

TITLE: ContextRelevancyMetric Usage with Custom Scale in TypeScript
DESCRIPTION: Illustrates how to configure the ContextRelevancyMetric with custom options, specifically setting a different scoring scale (0-100). It shows initialization with a custom scale and context, measuring relevancy, and includes commented-out example output.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/evals/context-relevancy.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { openai } from "@ai-sdk/openai";
import { ContextRelevancyMetric } from "@mastra/evals/llm";

// Configure the model for evaluation
const model = openai("gpt-4o-mini");

const metric = new ContextRelevancyMetric(model, {
  scale: 100, // Use 0-100 scale instead of 0-1
  context: [
    "Basic plan costs $10/month",
    "Pro plan includes advanced features at $30/month",
    "Enterprise plan has custom pricing",
    "Our company was founded in 2020",
    "We have offices worldwide",
  ],
});

const result = await metric.measure(
  "What are our pricing plans?",
  "We offer Basic, Pro, and Enterprise plans.",
);

// Example output:
// {
//   score: 60,
//   info: {
//     reason: "3 out of 5 statements are relevant to pricing plans. The statements about\n//           company founding and office locations are not relevant to the pricing query."
//   }
// }
```

----------------------------------------

TITLE: Initializing Mastra Agent with Evals in TypeScript
DESCRIPTION: This snippet demonstrates how to initialize a Mastra `Agent` in TypeScript, integrating various evaluation metrics. It imports necessary modules for agent creation, OpenAI model integration, and specific evaluation metrics like `SummarizationMetric`, `ContentSimilarityMetric`, and `ToneConsistencyMetric`. The agent is configured with a name, instructions, a language model (GPT-4o), and a set of evals to measure its performance.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/evals/overview.mdx#_snippet_0

LANGUAGE: TypeScript
CODE:
```
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";
import { SummarizationMetric } from "@mastra/evals/llm";
import {
  ContentSimilarityMetric,
  ToneConsistencyMetric,
} from "@mastra/evals/nlp";

const model = openai("gpt-4o");

export const myAgent = new Agent({
  name: "ContentWriter",
  instructions: "You are a content writer that creates accurate summaries",
  model,
  evals: {
    summarization: new SummarizationMetric(model),
    contentSimilarity: new ContentSimilarityMetric(),
    tone: new ToneConsistencyMetric(),
  },
});
```

----------------------------------------

TITLE: Instantiating PgVector and Mastra Core Components
DESCRIPTION: This code details the initialization of `PgVector` with the PostgreSQL connection string and the `Mastra` core instance. The `Mastra` instance is configured with the `ragAgent` and `pgVector` components, making them accessible throughout the application. Finally, it retrieves the configured `ragAgent` for use in subsequent operations.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/usage/cleanup-rag.mdx#_snippet_5

LANGUAGE: typescript
CODE:
```
const pgVector = new PgVector({ connectionString: process.env.POSTGRES_CONNECTION_STRING! });

export const mastra = new Mastra({
  agents: { ragAgent },
  vectors: { pgVector },
});
const agent = mastra.getAgent("ragAgent");
```

----------------------------------------

TITLE: Initializing Chroma Vector Store in TypeScript
DESCRIPTION: This snippet shows how to initialize the Chroma vector store using `@mastra/chroma`. It creates an instance of the store, then creates an index named 'myCollection' with a specified dimension, and subsequently upserts vector embeddings along with their metadata. Chroma typically runs locally or requires a separate server setup.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/rag/vector-databases.mdx#_snippet_3

LANGUAGE: TypeScript
CODE:
```
import { ChromaVector } from '@mastra/chroma'

const store = new ChromaVector()
await store.createIndex({
  indexName: "myCollection",
  dimension: 1536,
});
await store.upsert({
  indexName: "myCollection",
  vectors: embeddings,
  metadata: chunks.map(chunk => ({ text: chunk.text })),
});
```

----------------------------------------

TITLE: Starting a Workflow Run with Input Data (TypeScript)
DESCRIPTION: This snippet demonstrates how to initiate a workflow run using the `.start()` method. It first creates a run instance and then calls `start()` with an `inputData` object, providing initial values for the workflow's execution. The method returns a promise that resolves to the workflow's result.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/start.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
const run = myWorkflow.createRun();

// Start the workflow with input data
const result = await run.start({
  inputData: {
    startValue: "initial data"
  }
});
```

----------------------------------------

TITLE: Executing Foreach Workflow with Concurrency in TypeScript
DESCRIPTION: This snippet shows how to apply a step to each item in an input array with a specified concurrency limit. The `concurrency` option allows parallel execution of the `mapStep` for up to 2 items at a time.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/workflows/flow-control.mdx#_snippet_7

LANGUAGE: typescript
CODE:
```
counterWorkflow.foreach(mapStep, { concurrency: 2 }).then(finalStep).commit();
```

----------------------------------------

TITLE: Run Mastra Agent Server (Bash)
DESCRIPTION: Starts a local development server using `mastra dev` that exposes the registered agents (like `chefAgent`) via API endpoints, allowing interaction over HTTP.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/guides/guide/chef-michel.mdx#_snippet_7

LANGUAGE: bash
CODE:
```
mastra dev
```

----------------------------------------

TITLE: Chunk MDocument (TypeScript)
DESCRIPTION: Instance method to split the document into chunks based on specified parameters and optionally extract metadata. Returns a promise resolving to an array of Chunks.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/rag/document.mdx#_snippet_4

LANGUAGE: typescript
CODE:
```
async chunk(params?: ChunkParams): Promise<Chunk[]>
```

----------------------------------------

TITLE: Defining Parallel Activity Planning Workflow in Mastra AI (TypeScript)
DESCRIPTION: This Mastra AI workflow orchestrates the entire activity planning process. It fetches weather, then plans outdoor and indoor activities in parallel, and finally synthesizes these plans. The workflow is designed to handle city input and output a combined activity plan, demonstrating parallel execution and sequential chaining of steps.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/workflows/parallel-steps.mdx#_snippet_8

LANGUAGE: TypeScript
CODE:
```
const activityPlanningWorkflow = createWorkflow({
  id: 'plan-both-workflow',
  inputSchema: z.object({
    city: z.string(),
  }),
  outputSchema: z.object({
    activities: z.string(),
  }),
  steps: [fetchWeather, planActivities, planIndoorActivities, synthesizeStep]
})
  .then(fetchWeather)
  .parallel([planActivities, planIndoorActivities])
  .then(synthesizeStep)
  .commit()
 
export { activityPlanningWorkflow }
```

----------------------------------------

TITLE: Implementing TTS with ElevenLabs Voice in TypeScript
DESCRIPTION: This snippet demonstrates how to integrate ElevenLabs' Text-to-Speech (TTS) capabilities into a Mastra agent. It initializes an `Agent` with `ElevenLabsVoice`, generates text using an OpenAI model, converts the generated text into an audio stream, and plays it back. The `speaker` option allows for voice customization.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/voice/overview.mdx#_snippet_3

LANGUAGE: typescript
CODE:
```
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';
import { ElevenLabsVoice } from "@mastra/voice-elevenlabs";
import { playAudio } from "@mastra/node-audio";

const voiceAgent = new Agent({
name: "Voice Agent",
instructions: "You are a voice assistant that can help users with their tasks.",
model: openai("gpt-4o"),
voice: new ElevenLabsVoice(),
});

const { text } = await voiceAgent.generate('What color is the sky?');

// Convert text to speech to an Audio Stream
const audioStream = await voiceAgent.voice.speak(text, {
speaker: "default", // Optional: specify a speaker
});

playAudio(audioStream);
```

----------------------------------------

TITLE: Using OpenAIVoice for TTS and STT in TypeScript
DESCRIPTION: Demonstrates how to initialize the OpenAIVoice class with default or custom configuration, and how to use the `speak` method for text-to-speech and the `listen` method for speech-to-text conversion. Requires the `@mastra/voice-openai` package.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/voice/openai.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { OpenAIVoice } from "@mastra/voice-openai";

// Initialize with default configuration using environment variables
const voice = new OpenAIVoice();

// Or initialize with specific configuration
const voiceWithConfig = new OpenAIVoice({
  speechModel: {
    name: "tts-1-hd",
    apiKey: "your-openai-api-key"
  },
  listeningModel: {
    name: "whisper-1",
    apiKey: "your-openai-api-key"
  },
  speaker: "alloy" // Default voice
});

// Convert text to speech
const audioStream = await voice.speak("Hello, how can I help you?", {
  speaker: "nova", // Override default voice
  speed: 1.2 // Adjust speech speed
});

// Convert speech to text
const text = await voice.listen(audioStream, {
  filetype: "mp3"
});
```

----------------------------------------

TITLE: Defining an AI Agent for Activity Planning
DESCRIPTION: This code defines the core logic for an AI agent responsible for suggesting activities based on weather conditions. It takes a 'forecastSchema' as input, constructs a prompt using the forecast data, streams the AI's response, and aggregates the text into an 'activities' string. It relies on an 'agent' instance for AI interaction.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/agents/agentic-workflows.mdx#_snippet_4

LANGUAGE: TypeScript
CODE:
```
description: 'Suggests activities based on weather conditions',
  inputSchema: forecastSchema,
  outputSchema: z.object({
    activities: z.string(),
  }),
  execute: async ({ inputData }) => {
    const forecast = inputData;

    if (!forecast) {
      throw new Error('Forecast data not found');
    }

    const prompt = `Based on the following weather forecast for ${forecast.location}, suggest appropriate activities:\n      ${JSON.stringify(forecast, null, 2)}\n      `;

    const response = await agent.stream([
      {
        role: 'user',
        content: prompt,
      },
    ]);

    let activitiesText = '';

    for await (const chunk of response.textStream) {
      process.stdout.write(chunk);
      activitiesText += chunk;
    }

    return {
      activities: activitiesText,
    };
  },
```

----------------------------------------

TITLE: Monitoring Workflow Execution with .stream() in TypeScript
DESCRIPTION: This snippet illustrates how to use the `.stream()` method to monitor the real-time execution of a workflow run. It shows the creation of a workflow run, attaching a stream with optional input data, and iterating through the received chunks to process status updates.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/workflows/stream.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
const run = myWorkflow.createRun();

// Add a stream to monitor execution
const result = run.stream({ inputData: {...} });


for (const chunk of stream) {
  // do something with the chunk
}
```

----------------------------------------

TITLE: Integrating LangSmith with Mastra Telemetry in TypeScript
DESCRIPTION: This TypeScript code demonstrates how to configure the Mastra instance to export telemetry data to LangSmith. It imports `Mastra` and `AISDKExporter`, then sets up a custom telemetry exporter using `AISDKExporter` to capture AI-related calls for debugging and monitoring in LangSmith.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/observability/providers/langsmith.mdx#_snippet_1

LANGUAGE: typescript
CODE:
```
import { Mastra } from "@mastra/core";
import { AISDKExporter } from "langsmith/vercel";

export const mastra = new Mastra({
  // ... other config
  telemetry: {
    serviceName: "your-service-name",
    enabled: true,
    export: {
      type: "custom",
      exporter: new AISDKExporter()
    }
  }
});
```

----------------------------------------

TITLE: Embed Text Chunk with AI SDK and Mastra (TSX)
DESCRIPTION: This snippet demonstrates how to generate an embedding for a single text chunk using the `embed` function from the AI SDK, integrated with Mastra's `MDocument`. It requires `@ai-sdk/openai`, `@mastra/rag`, and `ai`. The code first creates an `MDocument` from text, chunks it, and then uses the first chunk's text to generate an embedding via the specified OpenAI model.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/examples/rag/embedding/embed-text-chunk.mdx#_snippet_0

LANGUAGE: tsx
CODE:
```
import { openai } from "@ai-sdk/openai";
import { MDocument } from "@mastra/rag";
import { embed } from "ai";

const doc = MDocument.fromText("Your text content...");

const chunks = await doc.chunk();

const { embedding } = await embed({
  model: openai.embedding("text-embedding-3-small"),
  value: chunks[0].text,
});
```

----------------------------------------

TITLE: Configuring ElevenLabs API Key Environment Variable
DESCRIPTION: This snippet shows how to set the `ELEVENLABS_API_KEY` environment variable, which is required for authenticating with the ElevenLabs API. Replace `your_api_key` with your actual ElevenLabs API key to ensure proper functionality.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/voice/elevenlabs/README.md#_snippet_1

LANGUAGE: bash
CODE:
```
ELEVENLABS_API_KEY=your_api_key
```

----------------------------------------

TITLE: Implementing a Do-Until Loop Workflow in TypeScript
DESCRIPTION: This snippet illustrates how to create a workflow that repeatedly executes a step (`incrementStep`) until a specified condition is met (`inputData.value >= 10`). It showcases the `dountil` method for iterative processing within a Mastra workflow, followed by a final step.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_42

LANGUAGE: TypeScript
CODE:
```
const workflow = createWorkflow({
  id: 'increment-workflow',
  inputSchema: z.object({
    value: z.number(),
  }),
  outputSchema: z.object({
    value: z.number(),
  }),
})
  .dountil(incrementStep, async ({ inputData }) => inputData.value >= 10)
  .then(finalStep);

workflow.commit();
```

----------------------------------------

TITLE: Defining Weather Workflow (TypeScript)
DESCRIPTION: This code defines a Mastra workflow named `weatherWorkflow`. It specifies an input schema for a 'city' and an output schema for 'activities'. The workflow chains two steps: `fetchWeather` and `planActivities`, and then commits the workflow for registration.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/docs/getting-started/installation.mdx#_snippet_21

LANGUAGE: TypeScript
CODE:
```
const weatherWorkflow = createWorkflow({
  id: 'weather-workflow',
  inputSchema: z.object({
    city: z.string().describe('The city to get the weather for'),
  }),
  outputSchema: z.object({
    activities: z.string(),
  }),
})
  .then(fetchWeather)
  .then(planActivities);

weatherWorkflow.commit();

export { weatherWorkflow };
```

----------------------------------------

TITLE: Executing Multiple Steps in Parallel - TypeScript
DESCRIPTION: This example shows how to use the `.parallel()` method to execute `step1` and `step2` concurrently. Once both parallel steps complete, the workflow proceeds to `step3`, which receives an object containing the outputs of both `step1` and `step2`.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/packages/core/src/workflows/README.md#_snippet_7

LANGUAGE: typescript
CODE:
```
myWorkflow.parallel([step1, step2]).then(step3).commit();
```

----------------------------------------

TITLE: Initialize Mastra Client in TypeScript
DESCRIPTION: Initializes a new instance of the MastraClient using the `@mastra/client-js` SDK. This is the first step required to interact with the Mastra platform's tools API.
SOURCE: https://github.com/mastra-ai/mastra/blob/main/docs/src/content/en/reference/client-js/tools.mdx#_snippet_0

LANGUAGE: typescript
CODE:
```
import { MastraClient } from "@mastra/client-js";

const client = new MastraClient();
```